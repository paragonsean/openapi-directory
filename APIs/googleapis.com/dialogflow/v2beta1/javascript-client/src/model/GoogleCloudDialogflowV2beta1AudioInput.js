/**
 * Dialogflow API
 * Builds conversational interfaces (for example, chatbots, and voice-powered apps and devices).
 *
 * The version of the OpenAPI document: v2beta1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import GoogleCloudDialogflowV2beta1InputAudioConfig from './GoogleCloudDialogflowV2beta1InputAudioConfig';

/**
 * The GoogleCloudDialogflowV2beta1AudioInput model module.
 * @module model/GoogleCloudDialogflowV2beta1AudioInput
 * @version v2beta1
 */
class GoogleCloudDialogflowV2beta1AudioInput {
    /**
     * Constructs a new <code>GoogleCloudDialogflowV2beta1AudioInput</code>.
     * Represents the natural language speech audio to be processed.
     * @alias module:model/GoogleCloudDialogflowV2beta1AudioInput
     */
    constructor() { 
        
        GoogleCloudDialogflowV2beta1AudioInput.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>GoogleCloudDialogflowV2beta1AudioInput</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/GoogleCloudDialogflowV2beta1AudioInput} obj Optional instance to populate.
     * @return {module:model/GoogleCloudDialogflowV2beta1AudioInput} The populated <code>GoogleCloudDialogflowV2beta1AudioInput</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new GoogleCloudDialogflowV2beta1AudioInput();

            if (data.hasOwnProperty('audio')) {
                obj['audio'] = ApiClient.convertToType(data['audio'], 'Blob');
            }
            if (data.hasOwnProperty('config')) {
                obj['config'] = GoogleCloudDialogflowV2beta1InputAudioConfig.constructFromObject(data['config']);
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>GoogleCloudDialogflowV2beta1AudioInput</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>GoogleCloudDialogflowV2beta1AudioInput</code>.
     */
    static validateJSON(data) {
        // validate the optional field `config`
        if (data['config']) { // data not null
          GoogleCloudDialogflowV2beta1InputAudioConfig.validateJSON(data['config']);
        }

        return true;
    }


}



/**
 * Required. The natural language speech audio to be processed. A single request can contain up to 1 minute of speech audio data. The transcribed text cannot contain more than 256 bytes for virtual agent interactions.
 * @member {Blob} audio
 */
GoogleCloudDialogflowV2beta1AudioInput.prototype['audio'] = undefined;

/**
 * @member {module:model/GoogleCloudDialogflowV2beta1InputAudioConfig} config
 */
GoogleCloudDialogflowV2beta1AudioInput.prototype['config'] = undefined;






export default GoogleCloudDialogflowV2beta1AudioInput;

