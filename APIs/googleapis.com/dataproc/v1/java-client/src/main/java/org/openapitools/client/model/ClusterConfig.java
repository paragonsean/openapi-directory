/*
 * Cloud Dataproc API
 * Manages Hadoop-based clusters and jobs on Google Cloud Platform.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.openapitools.client.model.AutoscalingConfig;
import org.openapitools.client.model.AuxiliaryNodeGroup;
import org.openapitools.client.model.DataprocMetricConfig;
import org.openapitools.client.model.EncryptionConfig;
import org.openapitools.client.model.EndpointConfig;
import org.openapitools.client.model.GceClusterConfig;
import org.openapitools.client.model.GkeClusterConfig;
import org.openapitools.client.model.InstanceGroupConfig;
import org.openapitools.client.model.LifecycleConfig;
import org.openapitools.client.model.MetastoreConfig;
import org.openapitools.client.model.NodeInitializationAction;
import org.openapitools.client.model.SecurityConfig;
import org.openapitools.client.model.SoftwareConfig;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * The cluster config.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:49:50.925918-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class ClusterConfig {
  public static final String SERIALIZED_NAME_AUTOSCALING_CONFIG = "autoscalingConfig";
  @SerializedName(SERIALIZED_NAME_AUTOSCALING_CONFIG)
  private AutoscalingConfig autoscalingConfig;

  public static final String SERIALIZED_NAME_AUXILIARY_NODE_GROUPS = "auxiliaryNodeGroups";
  @SerializedName(SERIALIZED_NAME_AUXILIARY_NODE_GROUPS)
  private List<AuxiliaryNodeGroup> auxiliaryNodeGroups = new ArrayList<>();

  public static final String SERIALIZED_NAME_CONFIG_BUCKET = "configBucket";
  @SerializedName(SERIALIZED_NAME_CONFIG_BUCKET)
  private String configBucket;

  public static final String SERIALIZED_NAME_DATAPROC_METRIC_CONFIG = "dataprocMetricConfig";
  @SerializedName(SERIALIZED_NAME_DATAPROC_METRIC_CONFIG)
  private DataprocMetricConfig dataprocMetricConfig;

  public static final String SERIALIZED_NAME_ENCRYPTION_CONFIG = "encryptionConfig";
  @SerializedName(SERIALIZED_NAME_ENCRYPTION_CONFIG)
  private EncryptionConfig encryptionConfig;

  public static final String SERIALIZED_NAME_ENDPOINT_CONFIG = "endpointConfig";
  @SerializedName(SERIALIZED_NAME_ENDPOINT_CONFIG)
  private EndpointConfig endpointConfig;

  public static final String SERIALIZED_NAME_GCE_CLUSTER_CONFIG = "gceClusterConfig";
  @SerializedName(SERIALIZED_NAME_GCE_CLUSTER_CONFIG)
  private GceClusterConfig gceClusterConfig;

  public static final String SERIALIZED_NAME_GKE_CLUSTER_CONFIG = "gkeClusterConfig";
  @SerializedName(SERIALIZED_NAME_GKE_CLUSTER_CONFIG)
  private GkeClusterConfig gkeClusterConfig;

  public static final String SERIALIZED_NAME_INITIALIZATION_ACTIONS = "initializationActions";
  @SerializedName(SERIALIZED_NAME_INITIALIZATION_ACTIONS)
  private List<NodeInitializationAction> initializationActions = new ArrayList<>();

  public static final String SERIALIZED_NAME_LIFECYCLE_CONFIG = "lifecycleConfig";
  @SerializedName(SERIALIZED_NAME_LIFECYCLE_CONFIG)
  private LifecycleConfig lifecycleConfig;

  public static final String SERIALIZED_NAME_MASTER_CONFIG = "masterConfig";
  @SerializedName(SERIALIZED_NAME_MASTER_CONFIG)
  private InstanceGroupConfig masterConfig;

  public static final String SERIALIZED_NAME_METASTORE_CONFIG = "metastoreConfig";
  @SerializedName(SERIALIZED_NAME_METASTORE_CONFIG)
  private MetastoreConfig metastoreConfig;

  public static final String SERIALIZED_NAME_SECONDARY_WORKER_CONFIG = "secondaryWorkerConfig";
  @SerializedName(SERIALIZED_NAME_SECONDARY_WORKER_CONFIG)
  private InstanceGroupConfig secondaryWorkerConfig;

  public static final String SERIALIZED_NAME_SECURITY_CONFIG = "securityConfig";
  @SerializedName(SERIALIZED_NAME_SECURITY_CONFIG)
  private SecurityConfig securityConfig;

  public static final String SERIALIZED_NAME_SOFTWARE_CONFIG = "softwareConfig";
  @SerializedName(SERIALIZED_NAME_SOFTWARE_CONFIG)
  private SoftwareConfig softwareConfig;

  public static final String SERIALIZED_NAME_TEMP_BUCKET = "tempBucket";
  @SerializedName(SERIALIZED_NAME_TEMP_BUCKET)
  private String tempBucket;

  public static final String SERIALIZED_NAME_WORKER_CONFIG = "workerConfig";
  @SerializedName(SERIALIZED_NAME_WORKER_CONFIG)
  private InstanceGroupConfig workerConfig;

  public ClusterConfig() {
  }

  public ClusterConfig autoscalingConfig(AutoscalingConfig autoscalingConfig) {
    this.autoscalingConfig = autoscalingConfig;
    return this;
  }

  /**
   * Get autoscalingConfig
   * @return autoscalingConfig
   */
  @javax.annotation.Nullable
  public AutoscalingConfig getAutoscalingConfig() {
    return autoscalingConfig;
  }

  public void setAutoscalingConfig(AutoscalingConfig autoscalingConfig) {
    this.autoscalingConfig = autoscalingConfig;
  }


  public ClusterConfig auxiliaryNodeGroups(List<AuxiliaryNodeGroup> auxiliaryNodeGroups) {
    this.auxiliaryNodeGroups = auxiliaryNodeGroups;
    return this;
  }

  public ClusterConfig addAuxiliaryNodeGroupsItem(AuxiliaryNodeGroup auxiliaryNodeGroupsItem) {
    if (this.auxiliaryNodeGroups == null) {
      this.auxiliaryNodeGroups = new ArrayList<>();
    }
    this.auxiliaryNodeGroups.add(auxiliaryNodeGroupsItem);
    return this;
  }

  /**
   * Optional. The node group settings.
   * @return auxiliaryNodeGroups
   */
  @javax.annotation.Nullable
  public List<AuxiliaryNodeGroup> getAuxiliaryNodeGroups() {
    return auxiliaryNodeGroups;
  }

  public void setAuxiliaryNodeGroups(List<AuxiliaryNodeGroup> auxiliaryNodeGroups) {
    this.auxiliaryNodeGroups = auxiliaryNodeGroups;
  }


  public ClusterConfig configBucket(String configBucket) {
    this.configBucket = configBucket;
    return this;
  }

  /**
   * Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster&#39;s staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging and temp buckets (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
   * @return configBucket
   */
  @javax.annotation.Nullable
  public String getConfigBucket() {
    return configBucket;
  }

  public void setConfigBucket(String configBucket) {
    this.configBucket = configBucket;
  }


  public ClusterConfig dataprocMetricConfig(DataprocMetricConfig dataprocMetricConfig) {
    this.dataprocMetricConfig = dataprocMetricConfig;
    return this;
  }

  /**
   * Get dataprocMetricConfig
   * @return dataprocMetricConfig
   */
  @javax.annotation.Nullable
  public DataprocMetricConfig getDataprocMetricConfig() {
    return dataprocMetricConfig;
  }

  public void setDataprocMetricConfig(DataprocMetricConfig dataprocMetricConfig) {
    this.dataprocMetricConfig = dataprocMetricConfig;
  }


  public ClusterConfig encryptionConfig(EncryptionConfig encryptionConfig) {
    this.encryptionConfig = encryptionConfig;
    return this;
  }

  /**
   * Get encryptionConfig
   * @return encryptionConfig
   */
  @javax.annotation.Nullable
  public EncryptionConfig getEncryptionConfig() {
    return encryptionConfig;
  }

  public void setEncryptionConfig(EncryptionConfig encryptionConfig) {
    this.encryptionConfig = encryptionConfig;
  }


  public ClusterConfig endpointConfig(EndpointConfig endpointConfig) {
    this.endpointConfig = endpointConfig;
    return this;
  }

  /**
   * Get endpointConfig
   * @return endpointConfig
   */
  @javax.annotation.Nullable
  public EndpointConfig getEndpointConfig() {
    return endpointConfig;
  }

  public void setEndpointConfig(EndpointConfig endpointConfig) {
    this.endpointConfig = endpointConfig;
  }


  public ClusterConfig gceClusterConfig(GceClusterConfig gceClusterConfig) {
    this.gceClusterConfig = gceClusterConfig;
    return this;
  }

  /**
   * Get gceClusterConfig
   * @return gceClusterConfig
   */
  @javax.annotation.Nullable
  public GceClusterConfig getGceClusterConfig() {
    return gceClusterConfig;
  }

  public void setGceClusterConfig(GceClusterConfig gceClusterConfig) {
    this.gceClusterConfig = gceClusterConfig;
  }


  public ClusterConfig gkeClusterConfig(GkeClusterConfig gkeClusterConfig) {
    this.gkeClusterConfig = gkeClusterConfig;
    return this;
  }

  /**
   * Get gkeClusterConfig
   * @return gkeClusterConfig
   */
  @javax.annotation.Nullable
  public GkeClusterConfig getGkeClusterConfig() {
    return gkeClusterConfig;
  }

  public void setGkeClusterConfig(GkeClusterConfig gkeClusterConfig) {
    this.gkeClusterConfig = gkeClusterConfig;
  }


  public ClusterConfig initializationActions(List<NodeInitializationAction> initializationActions) {
    this.initializationActions = initializationActions;
    return this;
  }

  public ClusterConfig addInitializationActionsItem(NodeInitializationAction initializationActionsItem) {
    if (this.initializationActions == null) {
      this.initializationActions = new ArrayList<>();
    }
    this.initializationActions.add(initializationActionsItem);
    return this;
  }

  /**
   * Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node&#39;s role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE&#x3D;$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if [[ \&quot;${ROLE}\&quot; &#x3D;&#x3D; &#39;Master&#39; ]]; then ... master specific actions ... else ... worker specific actions ... fi 
   * @return initializationActions
   */
  @javax.annotation.Nullable
  public List<NodeInitializationAction> getInitializationActions() {
    return initializationActions;
  }

  public void setInitializationActions(List<NodeInitializationAction> initializationActions) {
    this.initializationActions = initializationActions;
  }


  public ClusterConfig lifecycleConfig(LifecycleConfig lifecycleConfig) {
    this.lifecycleConfig = lifecycleConfig;
    return this;
  }

  /**
   * Get lifecycleConfig
   * @return lifecycleConfig
   */
  @javax.annotation.Nullable
  public LifecycleConfig getLifecycleConfig() {
    return lifecycleConfig;
  }

  public void setLifecycleConfig(LifecycleConfig lifecycleConfig) {
    this.lifecycleConfig = lifecycleConfig;
  }


  public ClusterConfig masterConfig(InstanceGroupConfig masterConfig) {
    this.masterConfig = masterConfig;
    return this;
  }

  /**
   * Get masterConfig
   * @return masterConfig
   */
  @javax.annotation.Nullable
  public InstanceGroupConfig getMasterConfig() {
    return masterConfig;
  }

  public void setMasterConfig(InstanceGroupConfig masterConfig) {
    this.masterConfig = masterConfig;
  }


  public ClusterConfig metastoreConfig(MetastoreConfig metastoreConfig) {
    this.metastoreConfig = metastoreConfig;
    return this;
  }

  /**
   * Get metastoreConfig
   * @return metastoreConfig
   */
  @javax.annotation.Nullable
  public MetastoreConfig getMetastoreConfig() {
    return metastoreConfig;
  }

  public void setMetastoreConfig(MetastoreConfig metastoreConfig) {
    this.metastoreConfig = metastoreConfig;
  }


  public ClusterConfig secondaryWorkerConfig(InstanceGroupConfig secondaryWorkerConfig) {
    this.secondaryWorkerConfig = secondaryWorkerConfig;
    return this;
  }

  /**
   * Get secondaryWorkerConfig
   * @return secondaryWorkerConfig
   */
  @javax.annotation.Nullable
  public InstanceGroupConfig getSecondaryWorkerConfig() {
    return secondaryWorkerConfig;
  }

  public void setSecondaryWorkerConfig(InstanceGroupConfig secondaryWorkerConfig) {
    this.secondaryWorkerConfig = secondaryWorkerConfig;
  }


  public ClusterConfig securityConfig(SecurityConfig securityConfig) {
    this.securityConfig = securityConfig;
    return this;
  }

  /**
   * Get securityConfig
   * @return securityConfig
   */
  @javax.annotation.Nullable
  public SecurityConfig getSecurityConfig() {
    return securityConfig;
  }

  public void setSecurityConfig(SecurityConfig securityConfig) {
    this.securityConfig = securityConfig;
  }


  public ClusterConfig softwareConfig(SoftwareConfig softwareConfig) {
    this.softwareConfig = softwareConfig;
    return this;
  }

  /**
   * Get softwareConfig
   * @return softwareConfig
   */
  @javax.annotation.Nullable
  public SoftwareConfig getSoftwareConfig() {
    return softwareConfig;
  }

  public void setSoftwareConfig(SoftwareConfig softwareConfig) {
    this.softwareConfig = softwareConfig;
  }


  public ClusterConfig tempBucket(String tempBucket) {
    this.tempBucket = tempBucket;
    return this;
  }

  /**
   * Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster&#39;s temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket (see Dataproc staging and temp buckets (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
   * @return tempBucket
   */
  @javax.annotation.Nullable
  public String getTempBucket() {
    return tempBucket;
  }

  public void setTempBucket(String tempBucket) {
    this.tempBucket = tempBucket;
  }


  public ClusterConfig workerConfig(InstanceGroupConfig workerConfig) {
    this.workerConfig = workerConfig;
    return this;
  }

  /**
   * Get workerConfig
   * @return workerConfig
   */
  @javax.annotation.Nullable
  public InstanceGroupConfig getWorkerConfig() {
    return workerConfig;
  }

  public void setWorkerConfig(InstanceGroupConfig workerConfig) {
    this.workerConfig = workerConfig;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    ClusterConfig clusterConfig = (ClusterConfig) o;
    return Objects.equals(this.autoscalingConfig, clusterConfig.autoscalingConfig) &&
        Objects.equals(this.auxiliaryNodeGroups, clusterConfig.auxiliaryNodeGroups) &&
        Objects.equals(this.configBucket, clusterConfig.configBucket) &&
        Objects.equals(this.dataprocMetricConfig, clusterConfig.dataprocMetricConfig) &&
        Objects.equals(this.encryptionConfig, clusterConfig.encryptionConfig) &&
        Objects.equals(this.endpointConfig, clusterConfig.endpointConfig) &&
        Objects.equals(this.gceClusterConfig, clusterConfig.gceClusterConfig) &&
        Objects.equals(this.gkeClusterConfig, clusterConfig.gkeClusterConfig) &&
        Objects.equals(this.initializationActions, clusterConfig.initializationActions) &&
        Objects.equals(this.lifecycleConfig, clusterConfig.lifecycleConfig) &&
        Objects.equals(this.masterConfig, clusterConfig.masterConfig) &&
        Objects.equals(this.metastoreConfig, clusterConfig.metastoreConfig) &&
        Objects.equals(this.secondaryWorkerConfig, clusterConfig.secondaryWorkerConfig) &&
        Objects.equals(this.securityConfig, clusterConfig.securityConfig) &&
        Objects.equals(this.softwareConfig, clusterConfig.softwareConfig) &&
        Objects.equals(this.tempBucket, clusterConfig.tempBucket) &&
        Objects.equals(this.workerConfig, clusterConfig.workerConfig);
  }

  @Override
  public int hashCode() {
    return Objects.hash(autoscalingConfig, auxiliaryNodeGroups, configBucket, dataprocMetricConfig, encryptionConfig, endpointConfig, gceClusterConfig, gkeClusterConfig, initializationActions, lifecycleConfig, masterConfig, metastoreConfig, secondaryWorkerConfig, securityConfig, softwareConfig, tempBucket, workerConfig);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class ClusterConfig {\n");
    sb.append("    autoscalingConfig: ").append(toIndentedString(autoscalingConfig)).append("\n");
    sb.append("    auxiliaryNodeGroups: ").append(toIndentedString(auxiliaryNodeGroups)).append("\n");
    sb.append("    configBucket: ").append(toIndentedString(configBucket)).append("\n");
    sb.append("    dataprocMetricConfig: ").append(toIndentedString(dataprocMetricConfig)).append("\n");
    sb.append("    encryptionConfig: ").append(toIndentedString(encryptionConfig)).append("\n");
    sb.append("    endpointConfig: ").append(toIndentedString(endpointConfig)).append("\n");
    sb.append("    gceClusterConfig: ").append(toIndentedString(gceClusterConfig)).append("\n");
    sb.append("    gkeClusterConfig: ").append(toIndentedString(gkeClusterConfig)).append("\n");
    sb.append("    initializationActions: ").append(toIndentedString(initializationActions)).append("\n");
    sb.append("    lifecycleConfig: ").append(toIndentedString(lifecycleConfig)).append("\n");
    sb.append("    masterConfig: ").append(toIndentedString(masterConfig)).append("\n");
    sb.append("    metastoreConfig: ").append(toIndentedString(metastoreConfig)).append("\n");
    sb.append("    secondaryWorkerConfig: ").append(toIndentedString(secondaryWorkerConfig)).append("\n");
    sb.append("    securityConfig: ").append(toIndentedString(securityConfig)).append("\n");
    sb.append("    softwareConfig: ").append(toIndentedString(softwareConfig)).append("\n");
    sb.append("    tempBucket: ").append(toIndentedString(tempBucket)).append("\n");
    sb.append("    workerConfig: ").append(toIndentedString(workerConfig)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("autoscalingConfig");
    openapiFields.add("auxiliaryNodeGroups");
    openapiFields.add("configBucket");
    openapiFields.add("dataprocMetricConfig");
    openapiFields.add("encryptionConfig");
    openapiFields.add("endpointConfig");
    openapiFields.add("gceClusterConfig");
    openapiFields.add("gkeClusterConfig");
    openapiFields.add("initializationActions");
    openapiFields.add("lifecycleConfig");
    openapiFields.add("masterConfig");
    openapiFields.add("metastoreConfig");
    openapiFields.add("secondaryWorkerConfig");
    openapiFields.add("securityConfig");
    openapiFields.add("softwareConfig");
    openapiFields.add("tempBucket");
    openapiFields.add("workerConfig");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to ClusterConfig
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!ClusterConfig.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in ClusterConfig is not found in the empty JSON string", ClusterConfig.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!ClusterConfig.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `ClusterConfig` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // validate the optional field `autoscalingConfig`
      if (jsonObj.get("autoscalingConfig") != null && !jsonObj.get("autoscalingConfig").isJsonNull()) {
        AutoscalingConfig.validateJsonElement(jsonObj.get("autoscalingConfig"));
      }
      if (jsonObj.get("auxiliaryNodeGroups") != null && !jsonObj.get("auxiliaryNodeGroups").isJsonNull()) {
        JsonArray jsonArrayauxiliaryNodeGroups = jsonObj.getAsJsonArray("auxiliaryNodeGroups");
        if (jsonArrayauxiliaryNodeGroups != null) {
          // ensure the json data is an array
          if (!jsonObj.get("auxiliaryNodeGroups").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `auxiliaryNodeGroups` to be an array in the JSON string but got `%s`", jsonObj.get("auxiliaryNodeGroups").toString()));
          }

          // validate the optional field `auxiliaryNodeGroups` (array)
          for (int i = 0; i < jsonArrayauxiliaryNodeGroups.size(); i++) {
            AuxiliaryNodeGroup.validateJsonElement(jsonArrayauxiliaryNodeGroups.get(i));
          };
        }
      }
      if ((jsonObj.get("configBucket") != null && !jsonObj.get("configBucket").isJsonNull()) && !jsonObj.get("configBucket").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `configBucket` to be a primitive type in the JSON string but got `%s`", jsonObj.get("configBucket").toString()));
      }
      // validate the optional field `dataprocMetricConfig`
      if (jsonObj.get("dataprocMetricConfig") != null && !jsonObj.get("dataprocMetricConfig").isJsonNull()) {
        DataprocMetricConfig.validateJsonElement(jsonObj.get("dataprocMetricConfig"));
      }
      // validate the optional field `encryptionConfig`
      if (jsonObj.get("encryptionConfig") != null && !jsonObj.get("encryptionConfig").isJsonNull()) {
        EncryptionConfig.validateJsonElement(jsonObj.get("encryptionConfig"));
      }
      // validate the optional field `endpointConfig`
      if (jsonObj.get("endpointConfig") != null && !jsonObj.get("endpointConfig").isJsonNull()) {
        EndpointConfig.validateJsonElement(jsonObj.get("endpointConfig"));
      }
      // validate the optional field `gceClusterConfig`
      if (jsonObj.get("gceClusterConfig") != null && !jsonObj.get("gceClusterConfig").isJsonNull()) {
        GceClusterConfig.validateJsonElement(jsonObj.get("gceClusterConfig"));
      }
      // validate the optional field `gkeClusterConfig`
      if (jsonObj.get("gkeClusterConfig") != null && !jsonObj.get("gkeClusterConfig").isJsonNull()) {
        GkeClusterConfig.validateJsonElement(jsonObj.get("gkeClusterConfig"));
      }
      if (jsonObj.get("initializationActions") != null && !jsonObj.get("initializationActions").isJsonNull()) {
        JsonArray jsonArrayinitializationActions = jsonObj.getAsJsonArray("initializationActions");
        if (jsonArrayinitializationActions != null) {
          // ensure the json data is an array
          if (!jsonObj.get("initializationActions").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `initializationActions` to be an array in the JSON string but got `%s`", jsonObj.get("initializationActions").toString()));
          }

          // validate the optional field `initializationActions` (array)
          for (int i = 0; i < jsonArrayinitializationActions.size(); i++) {
            NodeInitializationAction.validateJsonElement(jsonArrayinitializationActions.get(i));
          };
        }
      }
      // validate the optional field `lifecycleConfig`
      if (jsonObj.get("lifecycleConfig") != null && !jsonObj.get("lifecycleConfig").isJsonNull()) {
        LifecycleConfig.validateJsonElement(jsonObj.get("lifecycleConfig"));
      }
      // validate the optional field `masterConfig`
      if (jsonObj.get("masterConfig") != null && !jsonObj.get("masterConfig").isJsonNull()) {
        InstanceGroupConfig.validateJsonElement(jsonObj.get("masterConfig"));
      }
      // validate the optional field `metastoreConfig`
      if (jsonObj.get("metastoreConfig") != null && !jsonObj.get("metastoreConfig").isJsonNull()) {
        MetastoreConfig.validateJsonElement(jsonObj.get("metastoreConfig"));
      }
      // validate the optional field `secondaryWorkerConfig`
      if (jsonObj.get("secondaryWorkerConfig") != null && !jsonObj.get("secondaryWorkerConfig").isJsonNull()) {
        InstanceGroupConfig.validateJsonElement(jsonObj.get("secondaryWorkerConfig"));
      }
      // validate the optional field `securityConfig`
      if (jsonObj.get("securityConfig") != null && !jsonObj.get("securityConfig").isJsonNull()) {
        SecurityConfig.validateJsonElement(jsonObj.get("securityConfig"));
      }
      // validate the optional field `softwareConfig`
      if (jsonObj.get("softwareConfig") != null && !jsonObj.get("softwareConfig").isJsonNull()) {
        SoftwareConfig.validateJsonElement(jsonObj.get("softwareConfig"));
      }
      if ((jsonObj.get("tempBucket") != null && !jsonObj.get("tempBucket").isJsonNull()) && !jsonObj.get("tempBucket").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `tempBucket` to be a primitive type in the JSON string but got `%s`", jsonObj.get("tempBucket").toString()));
      }
      // validate the optional field `workerConfig`
      if (jsonObj.get("workerConfig") != null && !jsonObj.get("workerConfig").isJsonNull()) {
        InstanceGroupConfig.validateJsonElement(jsonObj.get("workerConfig"));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!ClusterConfig.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'ClusterConfig' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<ClusterConfig> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(ClusterConfig.class));

       return (TypeAdapter<T>) new TypeAdapter<ClusterConfig>() {
           @Override
           public void write(JsonWriter out, ClusterConfig value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public ClusterConfig read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of ClusterConfig given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of ClusterConfig
   * @throws IOException if the JSON string is invalid with respect to ClusterConfig
   */
  public static ClusterConfig fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, ClusterConfig.class);
  }

  /**
   * Convert an instance of ClusterConfig to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

