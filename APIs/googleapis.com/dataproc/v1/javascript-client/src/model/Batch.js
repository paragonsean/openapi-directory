/**
 * Cloud Dataproc API
 * Manages Hadoop-based clusters and jobs on Google Cloud Platform.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import EnvironmentConfig from './EnvironmentConfig';
import PySparkBatch from './PySparkBatch';
import RuntimeConfig from './RuntimeConfig';
import RuntimeInfo from './RuntimeInfo';
import SparkBatch from './SparkBatch';
import SparkRBatch from './SparkRBatch';
import SparkSqlBatch from './SparkSqlBatch';
import StateHistory from './StateHistory';

/**
 * The Batch model module.
 * @module model/Batch
 * @version v1
 */
class Batch {
    /**
     * Constructs a new <code>Batch</code>.
     * A representation of a batch workload in the service.
     * @alias module:model/Batch
     */
    constructor() { 
        
        Batch.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>Batch</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/Batch} obj Optional instance to populate.
     * @return {module:model/Batch} The populated <code>Batch</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new Batch();

            if (data.hasOwnProperty('createTime')) {
                obj['createTime'] = ApiClient.convertToType(data['createTime'], 'String');
            }
            if (data.hasOwnProperty('creator')) {
                obj['creator'] = ApiClient.convertToType(data['creator'], 'String');
            }
            if (data.hasOwnProperty('environmentConfig')) {
                obj['environmentConfig'] = EnvironmentConfig.constructFromObject(data['environmentConfig']);
            }
            if (data.hasOwnProperty('labels')) {
                obj['labels'] = ApiClient.convertToType(data['labels'], {'String': 'String'});
            }
            if (data.hasOwnProperty('name')) {
                obj['name'] = ApiClient.convertToType(data['name'], 'String');
            }
            if (data.hasOwnProperty('operation')) {
                obj['operation'] = ApiClient.convertToType(data['operation'], 'String');
            }
            if (data.hasOwnProperty('pysparkBatch')) {
                obj['pysparkBatch'] = PySparkBatch.constructFromObject(data['pysparkBatch']);
            }
            if (data.hasOwnProperty('runtimeConfig')) {
                obj['runtimeConfig'] = RuntimeConfig.constructFromObject(data['runtimeConfig']);
            }
            if (data.hasOwnProperty('runtimeInfo')) {
                obj['runtimeInfo'] = RuntimeInfo.constructFromObject(data['runtimeInfo']);
            }
            if (data.hasOwnProperty('sparkBatch')) {
                obj['sparkBatch'] = SparkBatch.constructFromObject(data['sparkBatch']);
            }
            if (data.hasOwnProperty('sparkRBatch')) {
                obj['sparkRBatch'] = SparkRBatch.constructFromObject(data['sparkRBatch']);
            }
            if (data.hasOwnProperty('sparkSqlBatch')) {
                obj['sparkSqlBatch'] = SparkSqlBatch.constructFromObject(data['sparkSqlBatch']);
            }
            if (data.hasOwnProperty('state')) {
                obj['state'] = ApiClient.convertToType(data['state'], 'String');
            }
            if (data.hasOwnProperty('stateHistory')) {
                obj['stateHistory'] = ApiClient.convertToType(data['stateHistory'], [StateHistory]);
            }
            if (data.hasOwnProperty('stateMessage')) {
                obj['stateMessage'] = ApiClient.convertToType(data['stateMessage'], 'String');
            }
            if (data.hasOwnProperty('stateTime')) {
                obj['stateTime'] = ApiClient.convertToType(data['stateTime'], 'String');
            }
            if (data.hasOwnProperty('uuid')) {
                obj['uuid'] = ApiClient.convertToType(data['uuid'], 'String');
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>Batch</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>Batch</code>.
     */
    static validateJSON(data) {
        // ensure the json data is a string
        if (data['createTime'] && !(typeof data['createTime'] === 'string' || data['createTime'] instanceof String)) {
            throw new Error("Expected the field `createTime` to be a primitive type in the JSON string but got " + data['createTime']);
        }
        // ensure the json data is a string
        if (data['creator'] && !(typeof data['creator'] === 'string' || data['creator'] instanceof String)) {
            throw new Error("Expected the field `creator` to be a primitive type in the JSON string but got " + data['creator']);
        }
        // validate the optional field `environmentConfig`
        if (data['environmentConfig']) { // data not null
          EnvironmentConfig.validateJSON(data['environmentConfig']);
        }
        // ensure the json data is a string
        if (data['name'] && !(typeof data['name'] === 'string' || data['name'] instanceof String)) {
            throw new Error("Expected the field `name` to be a primitive type in the JSON string but got " + data['name']);
        }
        // ensure the json data is a string
        if (data['operation'] && !(typeof data['operation'] === 'string' || data['operation'] instanceof String)) {
            throw new Error("Expected the field `operation` to be a primitive type in the JSON string but got " + data['operation']);
        }
        // validate the optional field `pysparkBatch`
        if (data['pysparkBatch']) { // data not null
          PySparkBatch.validateJSON(data['pysparkBatch']);
        }
        // validate the optional field `runtimeConfig`
        if (data['runtimeConfig']) { // data not null
          RuntimeConfig.validateJSON(data['runtimeConfig']);
        }
        // validate the optional field `runtimeInfo`
        if (data['runtimeInfo']) { // data not null
          RuntimeInfo.validateJSON(data['runtimeInfo']);
        }
        // validate the optional field `sparkBatch`
        if (data['sparkBatch']) { // data not null
          SparkBatch.validateJSON(data['sparkBatch']);
        }
        // validate the optional field `sparkRBatch`
        if (data['sparkRBatch']) { // data not null
          SparkRBatch.validateJSON(data['sparkRBatch']);
        }
        // validate the optional field `sparkSqlBatch`
        if (data['sparkSqlBatch']) { // data not null
          SparkSqlBatch.validateJSON(data['sparkSqlBatch']);
        }
        // ensure the json data is a string
        if (data['state'] && !(typeof data['state'] === 'string' || data['state'] instanceof String)) {
            throw new Error("Expected the field `state` to be a primitive type in the JSON string but got " + data['state']);
        }
        if (data['stateHistory']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['stateHistory'])) {
                throw new Error("Expected the field `stateHistory` to be an array in the JSON data but got " + data['stateHistory']);
            }
            // validate the optional field `stateHistory` (array)
            for (const item of data['stateHistory']) {
                StateHistory.validateJSON(item);
            };
        }
        // ensure the json data is a string
        if (data['stateMessage'] && !(typeof data['stateMessage'] === 'string' || data['stateMessage'] instanceof String)) {
            throw new Error("Expected the field `stateMessage` to be a primitive type in the JSON string but got " + data['stateMessage']);
        }
        // ensure the json data is a string
        if (data['stateTime'] && !(typeof data['stateTime'] === 'string' || data['stateTime'] instanceof String)) {
            throw new Error("Expected the field `stateTime` to be a primitive type in the JSON string but got " + data['stateTime']);
        }
        // ensure the json data is a string
        if (data['uuid'] && !(typeof data['uuid'] === 'string' || data['uuid'] instanceof String)) {
            throw new Error("Expected the field `uuid` to be a primitive type in the JSON string but got " + data['uuid']);
        }

        return true;
    }


}



/**
 * Output only. The time when the batch was created.
 * @member {String} createTime
 */
Batch.prototype['createTime'] = undefined;

/**
 * Output only. The email address of the user who created the batch.
 * @member {String} creator
 */
Batch.prototype['creator'] = undefined;

/**
 * @member {module:model/EnvironmentConfig} environmentConfig
 */
Batch.prototype['environmentConfig'] = undefined;

/**
 * Optional. The labels to associate with this batch. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a batch.
 * @member {Object.<String, String>} labels
 */
Batch.prototype['labels'] = undefined;

/**
 * Output only. The resource name of the batch.
 * @member {String} name
 */
Batch.prototype['name'] = undefined;

/**
 * Output only. The resource name of the operation associated with this batch.
 * @member {String} operation
 */
Batch.prototype['operation'] = undefined;

/**
 * @member {module:model/PySparkBatch} pysparkBatch
 */
Batch.prototype['pysparkBatch'] = undefined;

/**
 * @member {module:model/RuntimeConfig} runtimeConfig
 */
Batch.prototype['runtimeConfig'] = undefined;

/**
 * @member {module:model/RuntimeInfo} runtimeInfo
 */
Batch.prototype['runtimeInfo'] = undefined;

/**
 * @member {module:model/SparkBatch} sparkBatch
 */
Batch.prototype['sparkBatch'] = undefined;

/**
 * @member {module:model/SparkRBatch} sparkRBatch
 */
Batch.prototype['sparkRBatch'] = undefined;

/**
 * @member {module:model/SparkSqlBatch} sparkSqlBatch
 */
Batch.prototype['sparkSqlBatch'] = undefined;

/**
 * Output only. The state of the batch.
 * @member {module:model/Batch.StateEnum} state
 */
Batch.prototype['state'] = undefined;

/**
 * Output only. Historical state information for the batch.
 * @member {Array.<module:model/StateHistory>} stateHistory
 */
Batch.prototype['stateHistory'] = undefined;

/**
 * Output only. Batch state details, such as a failure description if the state is FAILED.
 * @member {String} stateMessage
 */
Batch.prototype['stateMessage'] = undefined;

/**
 * Output only. The time when the batch entered a current state.
 * @member {String} stateTime
 */
Batch.prototype['stateTime'] = undefined;

/**
 * Output only. A batch UUID (Unique Universal Identifier). The service generates this value when it creates the batch.
 * @member {String} uuid
 */
Batch.prototype['uuid'] = undefined;





/**
 * Allowed values for the <code>state</code> property.
 * @enum {String}
 * @readonly
 */
Batch['StateEnum'] = {

    /**
     * value: "STATE_UNSPECIFIED"
     * @const
     */
    "STATE_UNSPECIFIED": "STATE_UNSPECIFIED",

    /**
     * value: "PENDING"
     * @const
     */
    "PENDING": "PENDING",

    /**
     * value: "RUNNING"
     * @const
     */
    "RUNNING": "RUNNING",

    /**
     * value: "CANCELLING"
     * @const
     */
    "CANCELLING": "CANCELLING",

    /**
     * value: "CANCELLED"
     * @const
     */
    "CANCELLED": "CANCELLED",

    /**
     * value: "SUCCEEDED"
     * @const
     */
    "SUCCEEDED": "SUCCEEDED",

    /**
     * value: "FAILED"
     * @const
     */
    "FAILED": "FAILED"
};



export default Batch;

