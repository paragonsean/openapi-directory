# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server.models.logging_config import LoggingConfig
from openapi_server.models.query_list import QueryList
from openapi_server import util


class SparkSqlJob(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, jar_file_uris: List[str]=None, logging_config: LoggingConfig=None, properties: Dict[str, str]=None, query_file_uri: str=None, query_list: QueryList=None, script_variables: Dict[str, str]=None):
        """SparkSqlJob - a model defined in OpenAPI

        :param jar_file_uris: The jar_file_uris of this SparkSqlJob.
        :param logging_config: The logging_config of this SparkSqlJob.
        :param properties: The properties of this SparkSqlJob.
        :param query_file_uri: The query_file_uri of this SparkSqlJob.
        :param query_list: The query_list of this SparkSqlJob.
        :param script_variables: The script_variables of this SparkSqlJob.
        """
        self.openapi_types = {
            'jar_file_uris': List[str],
            'logging_config': LoggingConfig,
            'properties': Dict[str, str],
            'query_file_uri': str,
            'query_list': QueryList,
            'script_variables': Dict[str, str]
        }

        self.attribute_map = {
            'jar_file_uris': 'jarFileUris',
            'logging_config': 'loggingConfig',
            'properties': 'properties',
            'query_file_uri': 'queryFileUri',
            'query_list': 'queryList',
            'script_variables': 'scriptVariables'
        }

        self._jar_file_uris = jar_file_uris
        self._logging_config = logging_config
        self._properties = properties
        self._query_file_uri = query_file_uri
        self._query_list = query_list
        self._script_variables = script_variables

    @classmethod
    def from_dict(cls, dikt: dict) -> 'SparkSqlJob':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The SparkSqlJob of this SparkSqlJob.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def jar_file_uris(self):
        """Gets the jar_file_uris of this SparkSqlJob.

        Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.

        :return: The jar_file_uris of this SparkSqlJob.
        :rtype: List[str]
        """
        return self._jar_file_uris

    @jar_file_uris.setter
    def jar_file_uris(self, jar_file_uris):
        """Sets the jar_file_uris of this SparkSqlJob.

        Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.

        :param jar_file_uris: The jar_file_uris of this SparkSqlJob.
        :type jar_file_uris: List[str]
        """

        self._jar_file_uris = jar_file_uris

    @property
    def logging_config(self):
        """Gets the logging_config of this SparkSqlJob.


        :return: The logging_config of this SparkSqlJob.
        :rtype: LoggingConfig
        """
        return self._logging_config

    @logging_config.setter
    def logging_config(self, logging_config):
        """Sets the logging_config of this SparkSqlJob.


        :param logging_config: The logging_config of this SparkSqlJob.
        :type logging_config: LoggingConfig
        """

        self._logging_config = logging_config

    @property
    def properties(self):
        """Gets the properties of this SparkSqlJob.

        Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API might be overwritten.

        :return: The properties of this SparkSqlJob.
        :rtype: Dict[str, str]
        """
        return self._properties

    @properties.setter
    def properties(self, properties):
        """Sets the properties of this SparkSqlJob.

        Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API might be overwritten.

        :param properties: The properties of this SparkSqlJob.
        :type properties: Dict[str, str]
        """

        self._properties = properties

    @property
    def query_file_uri(self):
        """Gets the query_file_uri of this SparkSqlJob.

        The HCFS URI of the script that contains SQL queries.

        :return: The query_file_uri of this SparkSqlJob.
        :rtype: str
        """
        return self._query_file_uri

    @query_file_uri.setter
    def query_file_uri(self, query_file_uri):
        """Sets the query_file_uri of this SparkSqlJob.

        The HCFS URI of the script that contains SQL queries.

        :param query_file_uri: The query_file_uri of this SparkSqlJob.
        :type query_file_uri: str
        """

        self._query_file_uri = query_file_uri

    @property
    def query_list(self):
        """Gets the query_list of this SparkSqlJob.


        :return: The query_list of this SparkSqlJob.
        :rtype: QueryList
        """
        return self._query_list

    @query_list.setter
    def query_list(self, query_list):
        """Sets the query_list of this SparkSqlJob.


        :param query_list: The query_list of this SparkSqlJob.
        :type query_list: QueryList
        """

        self._query_list = query_list

    @property
    def script_variables(self):
        """Gets the script_variables of this SparkSqlJob.

        Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name=\"value\";).

        :return: The script_variables of this SparkSqlJob.
        :rtype: Dict[str, str]
        """
        return self._script_variables

    @script_variables.setter
    def script_variables(self, script_variables):
        """Sets the script_variables of this SparkSqlJob.

        Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name=\"value\";).

        :param script_variables: The script_variables of this SparkSqlJob.
        :type script_variables: Dict[str, str]
        """

        self._script_variables = script_variables
