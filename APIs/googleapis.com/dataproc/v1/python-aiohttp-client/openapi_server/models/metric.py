# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server import util


class Metric(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, metric_overrides: List[str]=None, metric_source: str=None):
        """Metric - a model defined in OpenAPI

        :param metric_overrides: The metric_overrides of this Metric.
        :param metric_source: The metric_source of this Metric.
        """
        self.openapi_types = {
            'metric_overrides': List[str],
            'metric_source': str
        }

        self.attribute_map = {
            'metric_overrides': 'metricOverrides',
            'metric_source': 'metricSource'
        }

        self._metric_overrides = metric_overrides
        self._metric_source = metric_source

    @classmethod
    def from_dict(cls, dikt: dict) -> 'Metric':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The Metric of this Metric.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def metric_overrides(self):
        """Gets the metric_overrides of this Metric.

        Optional. Specify one or more Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) to collect for the metric course (for the SPARK metric source (any Spark metric (https://spark.apache.org/docs/latest/monitoring.html#metrics) can be specified).Provide metrics in the following format: METRIC_SOURCE: INSTANCE:GROUP:METRIC Use camelcase as appropriate.Examples: yarn:ResourceManager:QueueMetrics:AppsCompleted spark:driver:DAGScheduler:job.allJobs sparkHistoryServer:JVM:Memory:NonHeapMemoryUsage.committed hiveserver2:JVM:Memory:NonHeapMemoryUsage.used Notes: Only the specified overridden metrics are collected for the metric source. For example, if one or more spark:executive metrics are listed as metric overrides, other SPARK metrics are not collected. The collection of the metrics for other enabled custom metric sources is unaffected. For example, if both SPARK andd YARN metric sources are enabled, and overrides are provided for Spark metrics only, all YARN metrics are collected.

        :return: The metric_overrides of this Metric.
        :rtype: List[str]
        """
        return self._metric_overrides

    @metric_overrides.setter
    def metric_overrides(self, metric_overrides):
        """Sets the metric_overrides of this Metric.

        Optional. Specify one or more Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) to collect for the metric course (for the SPARK metric source (any Spark metric (https://spark.apache.org/docs/latest/monitoring.html#metrics) can be specified).Provide metrics in the following format: METRIC_SOURCE: INSTANCE:GROUP:METRIC Use camelcase as appropriate.Examples: yarn:ResourceManager:QueueMetrics:AppsCompleted spark:driver:DAGScheduler:job.allJobs sparkHistoryServer:JVM:Memory:NonHeapMemoryUsage.committed hiveserver2:JVM:Memory:NonHeapMemoryUsage.used Notes: Only the specified overridden metrics are collected for the metric source. For example, if one or more spark:executive metrics are listed as metric overrides, other SPARK metrics are not collected. The collection of the metrics for other enabled custom metric sources is unaffected. For example, if both SPARK andd YARN metric sources are enabled, and overrides are provided for Spark metrics only, all YARN metrics are collected.

        :param metric_overrides: The metric_overrides of this Metric.
        :type metric_overrides: List[str]
        """

        self._metric_overrides = metric_overrides

    @property
    def metric_source(self):
        """Gets the metric_source of this Metric.

        Required. A standard set of metrics is collected unless metricOverrides are specified for the metric source (see Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) for more information).

        :return: The metric_source of this Metric.
        :rtype: str
        """
        return self._metric_source

    @metric_source.setter
    def metric_source(self, metric_source):
        """Sets the metric_source of this Metric.

        Required. A standard set of metrics is collected unless metricOverrides are specified for the metric source (see Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) for more information).

        :param metric_source: The metric_source of this Metric.
        :type metric_source: str
        """
        allowed_values = ["METRIC_SOURCE_UNSPECIFIED", "MONITORING_AGENT_DEFAULTS", "HDFS", "SPARK", "YARN", "SPARK_HISTORY_SERVER", "HIVESERVER2", "HIVEMETASTORE", "FLINK"]  # noqa: E501
        if metric_source not in allowed_values:
            raise ValueError(
                "Invalid value for `metric_source` ({0}), must be one of {1}"
                .format(metric_source, allowed_values)
            )

        self._metric_source = metric_source
