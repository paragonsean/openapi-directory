# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server.models.logging_config import LoggingConfig
from openapi_server import util


class SparkRJob(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, archive_uris: List[str]=None, args: List[str]=None, file_uris: List[str]=None, logging_config: LoggingConfig=None, main_r_file_uri: str=None, properties: Dict[str, str]=None):
        """SparkRJob - a model defined in OpenAPI

        :param archive_uris: The archive_uris of this SparkRJob.
        :param args: The args of this SparkRJob.
        :param file_uris: The file_uris of this SparkRJob.
        :param logging_config: The logging_config of this SparkRJob.
        :param main_r_file_uri: The main_r_file_uri of this SparkRJob.
        :param properties: The properties of this SparkRJob.
        """
        self.openapi_types = {
            'archive_uris': List[str],
            'args': List[str],
            'file_uris': List[str],
            'logging_config': LoggingConfig,
            'main_r_file_uri': str,
            'properties': Dict[str, str]
        }

        self.attribute_map = {
            'archive_uris': 'archiveUris',
            'args': 'args',
            'file_uris': 'fileUris',
            'logging_config': 'loggingConfig',
            'main_r_file_uri': 'mainRFileUri',
            'properties': 'properties'
        }

        self._archive_uris = archive_uris
        self._args = args
        self._file_uris = file_uris
        self._logging_config = logging_config
        self._main_r_file_uri = main_r_file_uri
        self._properties = properties

    @classmethod
    def from_dict(cls, dikt: dict) -> 'SparkRJob':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The SparkRJob of this SparkRJob.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def archive_uris(self):
        """Gets the archive_uris of this SparkRJob.

        Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.

        :return: The archive_uris of this SparkRJob.
        :rtype: List[str]
        """
        return self._archive_uris

    @archive_uris.setter
    def archive_uris(self, archive_uris):
        """Sets the archive_uris of this SparkRJob.

        Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.

        :param archive_uris: The archive_uris of this SparkRJob.
        :type archive_uris: List[str]
        """

        self._archive_uris = archive_uris

    @property
    def args(self):
        """Gets the args of this SparkRJob.

        Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

        :return: The args of this SparkRJob.
        :rtype: List[str]
        """
        return self._args

    @args.setter
    def args(self, args):
        """Sets the args of this SparkRJob.

        Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

        :param args: The args of this SparkRJob.
        :type args: List[str]
        """

        self._args = args

    @property
    def file_uris(self):
        """Gets the file_uris of this SparkRJob.

        Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.

        :return: The file_uris of this SparkRJob.
        :rtype: List[str]
        """
        return self._file_uris

    @file_uris.setter
    def file_uris(self, file_uris):
        """Sets the file_uris of this SparkRJob.

        Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.

        :param file_uris: The file_uris of this SparkRJob.
        :type file_uris: List[str]
        """

        self._file_uris = file_uris

    @property
    def logging_config(self):
        """Gets the logging_config of this SparkRJob.


        :return: The logging_config of this SparkRJob.
        :rtype: LoggingConfig
        """
        return self._logging_config

    @logging_config.setter
    def logging_config(self, logging_config):
        """Sets the logging_config of this SparkRJob.


        :param logging_config: The logging_config of this SparkRJob.
        :type logging_config: LoggingConfig
        """

        self._logging_config = logging_config

    @property
    def main_r_file_uri(self):
        """Gets the main_r_file_uri of this SparkRJob.

        Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.

        :return: The main_r_file_uri of this SparkRJob.
        :rtype: str
        """
        return self._main_r_file_uri

    @main_r_file_uri.setter
    def main_r_file_uri(self, main_r_file_uri):
        """Sets the main_r_file_uri of this SparkRJob.

        Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.

        :param main_r_file_uri: The main_r_file_uri of this SparkRJob.
        :type main_r_file_uri: str
        """

        self._main_r_file_uri = main_r_file_uri

    @property
    def properties(self):
        """Gets the properties of this SparkRJob.

        Optional. A mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API might be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.

        :return: The properties of this SparkRJob.
        :rtype: Dict[str, str]
        """
        return self._properties

    @properties.setter
    def properties(self, properties):
        """Sets the properties of this SparkRJob.

        Optional. A mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API might be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.

        :param properties: The properties of this SparkRJob.
        :type properties: Dict[str, str]
        """

        self._properties = properties
