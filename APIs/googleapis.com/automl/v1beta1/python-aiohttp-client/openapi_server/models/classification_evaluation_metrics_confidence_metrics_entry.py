# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server import util


class ClassificationEvaluationMetricsConfidenceMetricsEntry(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, confidence_threshold: float=None, f1_score: float=None, f1_score_at1: float=None, false_negative_count: str=None, false_positive_count: str=None, false_positive_rate: float=None, false_positive_rate_at1: float=None, position_threshold: int=None, precision: float=None, precision_at1: float=None, recall: float=None, recall_at1: float=None, true_negative_count: str=None, true_positive_count: str=None):
        """ClassificationEvaluationMetricsConfidenceMetricsEntry - a model defined in OpenAPI

        :param confidence_threshold: The confidence_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param f1_score: The f1_score of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param f1_score_at1: The f1_score_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param false_negative_count: The false_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param false_positive_count: The false_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param false_positive_rate: The false_positive_rate of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param false_positive_rate_at1: The false_positive_rate_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param position_threshold: The position_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param precision: The precision of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param precision_at1: The precision_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param recall: The recall of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param recall_at1: The recall_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param true_negative_count: The true_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :param true_positive_count: The true_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        """
        self.openapi_types = {
            'confidence_threshold': float,
            'f1_score': float,
            'f1_score_at1': float,
            'false_negative_count': str,
            'false_positive_count': str,
            'false_positive_rate': float,
            'false_positive_rate_at1': float,
            'position_threshold': int,
            'precision': float,
            'precision_at1': float,
            'recall': float,
            'recall_at1': float,
            'true_negative_count': str,
            'true_positive_count': str
        }

        self.attribute_map = {
            'confidence_threshold': 'confidenceThreshold',
            'f1_score': 'f1Score',
            'f1_score_at1': 'f1ScoreAt1',
            'false_negative_count': 'falseNegativeCount',
            'false_positive_count': 'falsePositiveCount',
            'false_positive_rate': 'falsePositiveRate',
            'false_positive_rate_at1': 'falsePositiveRateAt1',
            'position_threshold': 'positionThreshold',
            'precision': 'precision',
            'precision_at1': 'precisionAt1',
            'recall': 'recall',
            'recall_at1': 'recallAt1',
            'true_negative_count': 'trueNegativeCount',
            'true_positive_count': 'truePositiveCount'
        }

        self._confidence_threshold = confidence_threshold
        self._f1_score = f1_score
        self._f1_score_at1 = f1_score_at1
        self._false_negative_count = false_negative_count
        self._false_positive_count = false_positive_count
        self._false_positive_rate = false_positive_rate
        self._false_positive_rate_at1 = false_positive_rate_at1
        self._position_threshold = position_threshold
        self._precision = precision
        self._precision_at1 = precision_at1
        self._recall = recall
        self._recall_at1 = recall_at1
        self._true_negative_count = true_negative_count
        self._true_positive_count = true_positive_count

    @classmethod
    def from_dict(cls, dikt: dict) -> 'ClassificationEvaluationMetricsConfidenceMetricsEntry':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The ClassificationEvaluationMetricsConfidenceMetricsEntry of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def confidence_threshold(self):
        """Gets the confidence_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Metrics are computed with an assumption that the model never returns predictions with score lower than this value.

        :return: The confidence_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._confidence_threshold

    @confidence_threshold.setter
    def confidence_threshold(self, confidence_threshold):
        """Sets the confidence_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Metrics are computed with an assumption that the model never returns predictions with score lower than this value.

        :param confidence_threshold: The confidence_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type confidence_threshold: float
        """

        self._confidence_threshold = confidence_threshold

    @property
    def f1_score(self):
        """Gets the f1_score of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The harmonic mean of recall and precision.

        :return: The f1_score of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._f1_score

    @f1_score.setter
    def f1_score(self, f1_score):
        """Sets the f1_score of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The harmonic mean of recall and precision.

        :param f1_score: The f1_score of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type f1_score: float
        """

        self._f1_score = f1_score

    @property
    def f1_score_at1(self):
        """Gets the f1_score_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The harmonic mean of recall_at1 and precision_at1.

        :return: The f1_score_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._f1_score_at1

    @f1_score_at1.setter
    def f1_score_at1(self, f1_score_at1):
        """Sets the f1_score_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The harmonic mean of recall_at1 and precision_at1.

        :param f1_score_at1: The f1_score_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type f1_score_at1: float
        """

        self._f1_score_at1 = f1_score_at1

    @property
    def false_negative_count(self):
        """Gets the false_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of ground truth labels that are not matched by a model created label.

        :return: The false_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: str
        """
        return self._false_negative_count

    @false_negative_count.setter
    def false_negative_count(self, false_negative_count):
        """Sets the false_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of ground truth labels that are not matched by a model created label.

        :param false_negative_count: The false_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type false_negative_count: str
        """

        self._false_negative_count = false_negative_count

    @property
    def false_positive_count(self):
        """Gets the false_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of model created labels that do not match a ground truth label.

        :return: The false_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: str
        """
        return self._false_positive_count

    @false_positive_count.setter
    def false_positive_count(self, false_positive_count):
        """Sets the false_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of model created labels that do not match a ground truth label.

        :param false_positive_count: The false_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type false_positive_count: str
        """

        self._false_positive_count = false_positive_count

    @property
    def false_positive_rate(self):
        """Gets the false_positive_rate of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. False Positive Rate for the given confidence threshold.

        :return: The false_positive_rate of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._false_positive_rate

    @false_positive_rate.setter
    def false_positive_rate(self, false_positive_rate):
        """Sets the false_positive_rate of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. False Positive Rate for the given confidence threshold.

        :param false_positive_rate: The false_positive_rate of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type false_positive_rate: float
        """

        self._false_positive_rate = false_positive_rate

    @property
    def false_positive_rate_at1(self):
        """Gets the false_positive_rate_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The False Positive Rate when only considering the label that has the highest prediction score and not below the confidence threshold for each example.

        :return: The false_positive_rate_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._false_positive_rate_at1

    @false_positive_rate_at1.setter
    def false_positive_rate_at1(self, false_positive_rate_at1):
        """Sets the false_positive_rate_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The False Positive Rate when only considering the label that has the highest prediction score and not below the confidence threshold for each example.

        :param false_positive_rate_at1: The false_positive_rate_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type false_positive_rate_at1: float
        """

        self._false_positive_rate_at1 = false_positive_rate_at1

    @property
    def position_threshold(self):
        """Gets the position_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Metrics are computed with an assumption that the model always returns at most this many predictions (ordered by their score, descendingly), but they all still need to meet the confidence_threshold.

        :return: The position_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: int
        """
        return self._position_threshold

    @position_threshold.setter
    def position_threshold(self, position_threshold):
        """Sets the position_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Metrics are computed with an assumption that the model always returns at most this many predictions (ordered by their score, descendingly), but they all still need to meet the confidence_threshold.

        :param position_threshold: The position_threshold of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type position_threshold: int
        """

        self._position_threshold = position_threshold

    @property
    def precision(self):
        """Gets the precision of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Precision for the given confidence threshold.

        :return: The precision of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._precision

    @precision.setter
    def precision(self, precision):
        """Sets the precision of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Precision for the given confidence threshold.

        :param precision: The precision of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type precision: float
        """

        self._precision = precision

    @property
    def precision_at1(self):
        """Gets the precision_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The precision when only considering the label that has the highest prediction score and not below the confidence threshold for each example.

        :return: The precision_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._precision_at1

    @precision_at1.setter
    def precision_at1(self, precision_at1):
        """Sets the precision_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The precision when only considering the label that has the highest prediction score and not below the confidence threshold for each example.

        :param precision_at1: The precision_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type precision_at1: float
        """

        self._precision_at1 = precision_at1

    @property
    def recall(self):
        """Gets the recall of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Recall (True Positive Rate) for the given confidence threshold.

        :return: The recall of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._recall

    @recall.setter
    def recall(self, recall):
        """Sets the recall of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. Recall (True Positive Rate) for the given confidence threshold.

        :param recall: The recall of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type recall: float
        """

        self._recall = recall

    @property
    def recall_at1(self):
        """Gets the recall_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The Recall (True Positive Rate) when only considering the label that has the highest prediction score and not below the confidence threshold for each example.

        :return: The recall_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: float
        """
        return self._recall_at1

    @recall_at1.setter
    def recall_at1(self, recall_at1):
        """Sets the recall_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The Recall (True Positive Rate) when only considering the label that has the highest prediction score and not below the confidence threshold for each example.

        :param recall_at1: The recall_at1 of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type recall_at1: float
        """

        self._recall_at1 = recall_at1

    @property
    def true_negative_count(self):
        """Gets the true_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of labels that were not created by the model, but if they would, they would not match a ground truth label.

        :return: The true_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: str
        """
        return self._true_negative_count

    @true_negative_count.setter
    def true_negative_count(self, true_negative_count):
        """Sets the true_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of labels that were not created by the model, but if they would, they would not match a ground truth label.

        :param true_negative_count: The true_negative_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type true_negative_count: str
        """

        self._true_negative_count = true_negative_count

    @property
    def true_positive_count(self):
        """Gets the true_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of model created labels that match a ground truth label.

        :return: The true_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :rtype: str
        """
        return self._true_positive_count

    @true_positive_count.setter
    def true_positive_count(self, true_positive_count):
        """Sets the true_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.

        Output only. The number of model created labels that match a ground truth label.

        :param true_positive_count: The true_positive_count of this ClassificationEvaluationMetricsConfidenceMetricsEntry.
        :type true_positive_count: str
        """

        self._true_positive_count = true_positive_count
