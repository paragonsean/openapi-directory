/**
 * Cloud Speech-to-Text API
 * Converts audio to text by applying powerful neural network models.
 *
 * The version of the OpenAPI document: v1p1beta1
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAISpeechRecognitionResult.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAISpeechRecognitionResult::OAISpeechRecognitionResult(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAISpeechRecognitionResult::OAISpeechRecognitionResult() {
    this->initializeModel();
}

OAISpeechRecognitionResult::~OAISpeechRecognitionResult() {}

void OAISpeechRecognitionResult::initializeModel() {

    m_alternatives_isSet = false;
    m_alternatives_isValid = false;

    m_channel_tag_isSet = false;
    m_channel_tag_isValid = false;

    m_language_code_isSet = false;
    m_language_code_isValid = false;

    m_result_end_time_isSet = false;
    m_result_end_time_isValid = false;
}

void OAISpeechRecognitionResult::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAISpeechRecognitionResult::fromJsonObject(QJsonObject json) {

    m_alternatives_isValid = ::OpenAPI::fromJsonValue(m_alternatives, json[QString("alternatives")]);
    m_alternatives_isSet = !json[QString("alternatives")].isNull() && m_alternatives_isValid;

    m_channel_tag_isValid = ::OpenAPI::fromJsonValue(m_channel_tag, json[QString("channelTag")]);
    m_channel_tag_isSet = !json[QString("channelTag")].isNull() && m_channel_tag_isValid;

    m_language_code_isValid = ::OpenAPI::fromJsonValue(m_language_code, json[QString("languageCode")]);
    m_language_code_isSet = !json[QString("languageCode")].isNull() && m_language_code_isValid;

    m_result_end_time_isValid = ::OpenAPI::fromJsonValue(m_result_end_time, json[QString("resultEndTime")]);
    m_result_end_time_isSet = !json[QString("resultEndTime")].isNull() && m_result_end_time_isValid;
}

QString OAISpeechRecognitionResult::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAISpeechRecognitionResult::asJsonObject() const {
    QJsonObject obj;
    if (m_alternatives.size() > 0) {
        obj.insert(QString("alternatives"), ::OpenAPI::toJsonValue(m_alternatives));
    }
    if (m_channel_tag_isSet) {
        obj.insert(QString("channelTag"), ::OpenAPI::toJsonValue(m_channel_tag));
    }
    if (m_language_code_isSet) {
        obj.insert(QString("languageCode"), ::OpenAPI::toJsonValue(m_language_code));
    }
    if (m_result_end_time_isSet) {
        obj.insert(QString("resultEndTime"), ::OpenAPI::toJsonValue(m_result_end_time));
    }
    return obj;
}

QList<OAISpeechRecognitionAlternative> OAISpeechRecognitionResult::getAlternatives() const {
    return m_alternatives;
}
void OAISpeechRecognitionResult::setAlternatives(const QList<OAISpeechRecognitionAlternative> &alternatives) {
    m_alternatives = alternatives;
    m_alternatives_isSet = true;
}

bool OAISpeechRecognitionResult::is_alternatives_Set() const{
    return m_alternatives_isSet;
}

bool OAISpeechRecognitionResult::is_alternatives_Valid() const{
    return m_alternatives_isValid;
}

qint32 OAISpeechRecognitionResult::getChannelTag() const {
    return m_channel_tag;
}
void OAISpeechRecognitionResult::setChannelTag(const qint32 &channel_tag) {
    m_channel_tag = channel_tag;
    m_channel_tag_isSet = true;
}

bool OAISpeechRecognitionResult::is_channel_tag_Set() const{
    return m_channel_tag_isSet;
}

bool OAISpeechRecognitionResult::is_channel_tag_Valid() const{
    return m_channel_tag_isValid;
}

QString OAISpeechRecognitionResult::getLanguageCode() const {
    return m_language_code;
}
void OAISpeechRecognitionResult::setLanguageCode(const QString &language_code) {
    m_language_code = language_code;
    m_language_code_isSet = true;
}

bool OAISpeechRecognitionResult::is_language_code_Set() const{
    return m_language_code_isSet;
}

bool OAISpeechRecognitionResult::is_language_code_Valid() const{
    return m_language_code_isValid;
}

QString OAISpeechRecognitionResult::getResultEndTime() const {
    return m_result_end_time;
}
void OAISpeechRecognitionResult::setResultEndTime(const QString &result_end_time) {
    m_result_end_time = result_end_time;
    m_result_end_time_isSet = true;
}

bool OAISpeechRecognitionResult::is_result_end_time_Set() const{
    return m_result_end_time_isSet;
}

bool OAISpeechRecognitionResult::is_result_end_time_Valid() const{
    return m_result_end_time_isValid;
}

bool OAISpeechRecognitionResult::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_alternatives.size() > 0) {
            isObjectUpdated = true;
            break;
        }

        if (m_channel_tag_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_language_code_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_result_end_time_isSet) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAISpeechRecognitionResult::isValid() const {
    // only required properties are required for the object to be considered valid
    return true;
}

} // namespace OpenAPI
