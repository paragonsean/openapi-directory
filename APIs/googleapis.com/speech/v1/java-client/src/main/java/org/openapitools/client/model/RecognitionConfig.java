/*
 * Cloud Speech-to-Text API
 * Converts audio to text by applying powerful neural network models.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.openapitools.client.model.RecognitionMetadata;
import org.openapitools.client.model.SpeakerDiarizationConfig;
import org.openapitools.client.model.SpeechAdaptation;
import org.openapitools.client.model.SpeechContext;
import org.openapitools.client.model.TranscriptNormalization;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * Provides information to the recognizer that specifies how to process the request.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:46:53.441209-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class RecognitionConfig {
  public static final String SERIALIZED_NAME_ADAPTATION = "adaptation";
  @SerializedName(SERIALIZED_NAME_ADAPTATION)
  private SpeechAdaptation adaptation;

  public static final String SERIALIZED_NAME_ALTERNATIVE_LANGUAGE_CODES = "alternativeLanguageCodes";
  @SerializedName(SERIALIZED_NAME_ALTERNATIVE_LANGUAGE_CODES)
  private List<String> alternativeLanguageCodes = new ArrayList<>();

  public static final String SERIALIZED_NAME_AUDIO_CHANNEL_COUNT = "audioChannelCount";
  @SerializedName(SERIALIZED_NAME_AUDIO_CHANNEL_COUNT)
  private Integer audioChannelCount;

  public static final String SERIALIZED_NAME_DIARIZATION_CONFIG = "diarizationConfig";
  @SerializedName(SERIALIZED_NAME_DIARIZATION_CONFIG)
  private SpeakerDiarizationConfig diarizationConfig;

  public static final String SERIALIZED_NAME_ENABLE_AUTOMATIC_PUNCTUATION = "enableAutomaticPunctuation";
  @SerializedName(SERIALIZED_NAME_ENABLE_AUTOMATIC_PUNCTUATION)
  private Boolean enableAutomaticPunctuation;

  public static final String SERIALIZED_NAME_ENABLE_SEPARATE_RECOGNITION_PER_CHANNEL = "enableSeparateRecognitionPerChannel";
  @SerializedName(SERIALIZED_NAME_ENABLE_SEPARATE_RECOGNITION_PER_CHANNEL)
  private Boolean enableSeparateRecognitionPerChannel;

  public static final String SERIALIZED_NAME_ENABLE_SPOKEN_EMOJIS = "enableSpokenEmojis";
  @SerializedName(SERIALIZED_NAME_ENABLE_SPOKEN_EMOJIS)
  private Boolean enableSpokenEmojis;

  public static final String SERIALIZED_NAME_ENABLE_SPOKEN_PUNCTUATION = "enableSpokenPunctuation";
  @SerializedName(SERIALIZED_NAME_ENABLE_SPOKEN_PUNCTUATION)
  private Boolean enableSpokenPunctuation;

  public static final String SERIALIZED_NAME_ENABLE_WORD_CONFIDENCE = "enableWordConfidence";
  @SerializedName(SERIALIZED_NAME_ENABLE_WORD_CONFIDENCE)
  private Boolean enableWordConfidence;

  public static final String SERIALIZED_NAME_ENABLE_WORD_TIME_OFFSETS = "enableWordTimeOffsets";
  @SerializedName(SERIALIZED_NAME_ENABLE_WORD_TIME_OFFSETS)
  private Boolean enableWordTimeOffsets;

  /**
   * Encoding of audio data sent in all &#x60;RecognitionAudio&#x60; messages. This field is optional for &#x60;FLAC&#x60; and &#x60;WAV&#x60; audio files and required for all other audio formats. For details, see AudioEncoding.
   */
  @JsonAdapter(EncodingEnum.Adapter.class)
  public enum EncodingEnum {
    ENCODING_UNSPECIFIED("ENCODING_UNSPECIFIED"),
    
    LINEAR16("LINEAR16"),
    
    FLAC("FLAC"),
    
    MULAW("MULAW"),
    
    AMR("AMR"),
    
    AMR_WB("AMR_WB"),
    
    OGG_OPUS("OGG_OPUS"),
    
    SPEEX_WITH_HEADER_BYTE("SPEEX_WITH_HEADER_BYTE"),
    
    MP3("MP3"),
    
    WEBM_OPUS("WEBM_OPUS");

    private String value;

    EncodingEnum(String value) {
      this.value = value;
    }

    public String getValue() {
      return value;
    }

    @Override
    public String toString() {
      return String.valueOf(value);
    }

    public static EncodingEnum fromValue(String value) {
      for (EncodingEnum b : EncodingEnum.values()) {
        if (b.value.equals(value)) {
          return b;
        }
      }
      throw new IllegalArgumentException("Unexpected value '" + value + "'");
    }

    public static class Adapter extends TypeAdapter<EncodingEnum> {
      @Override
      public void write(final JsonWriter jsonWriter, final EncodingEnum enumeration) throws IOException {
        jsonWriter.value(enumeration.getValue());
      }

      @Override
      public EncodingEnum read(final JsonReader jsonReader) throws IOException {
        String value =  jsonReader.nextString();
        return EncodingEnum.fromValue(value);
      }
    }

    public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      String value = jsonElement.getAsString();
      EncodingEnum.fromValue(value);
    }
  }

  public static final String SERIALIZED_NAME_ENCODING = "encoding";
  @SerializedName(SERIALIZED_NAME_ENCODING)
  private EncodingEnum encoding;

  public static final String SERIALIZED_NAME_LANGUAGE_CODE = "languageCode";
  @SerializedName(SERIALIZED_NAME_LANGUAGE_CODE)
  private String languageCode;

  public static final String SERIALIZED_NAME_MAX_ALTERNATIVES = "maxAlternatives";
  @SerializedName(SERIALIZED_NAME_MAX_ALTERNATIVES)
  private Integer maxAlternatives;

  public static final String SERIALIZED_NAME_METADATA = "metadata";
  @Deprecated
  @SerializedName(SERIALIZED_NAME_METADATA)
  private RecognitionMetadata metadata;

  public static final String SERIALIZED_NAME_MODEL = "model";
  @SerializedName(SERIALIZED_NAME_MODEL)
  private String model;

  public static final String SERIALIZED_NAME_PROFANITY_FILTER = "profanityFilter";
  @SerializedName(SERIALIZED_NAME_PROFANITY_FILTER)
  private Boolean profanityFilter;

  public static final String SERIALIZED_NAME_SAMPLE_RATE_HERTZ = "sampleRateHertz";
  @SerializedName(SERIALIZED_NAME_SAMPLE_RATE_HERTZ)
  private Integer sampleRateHertz;

  public static final String SERIALIZED_NAME_SPEECH_CONTEXTS = "speechContexts";
  @SerializedName(SERIALIZED_NAME_SPEECH_CONTEXTS)
  private List<SpeechContext> speechContexts = new ArrayList<>();

  public static final String SERIALIZED_NAME_TRANSCRIPT_NORMALIZATION = "transcriptNormalization";
  @SerializedName(SERIALIZED_NAME_TRANSCRIPT_NORMALIZATION)
  private TranscriptNormalization transcriptNormalization;

  public static final String SERIALIZED_NAME_USE_ENHANCED = "useEnhanced";
  @SerializedName(SERIALIZED_NAME_USE_ENHANCED)
  private Boolean useEnhanced;

  public RecognitionConfig() {
  }

  public RecognitionConfig adaptation(SpeechAdaptation adaptation) {
    this.adaptation = adaptation;
    return this;
  }

  /**
   * Get adaptation
   * @return adaptation
   */
  @javax.annotation.Nullable
  public SpeechAdaptation getAdaptation() {
    return adaptation;
  }

  public void setAdaptation(SpeechAdaptation adaptation) {
    this.adaptation = adaptation;
  }


  public RecognitionConfig alternativeLanguageCodes(List<String> alternativeLanguageCodes) {
    this.alternativeLanguageCodes = alternativeLanguageCodes;
    return this;
  }

  public RecognitionConfig addAlternativeLanguageCodesItem(String alternativeLanguageCodesItem) {
    if (this.alternativeLanguageCodes == null) {
      this.alternativeLanguageCodes = new ArrayList<>();
    }
    this.alternativeLanguageCodes.add(alternativeLanguageCodesItem);
    return this;
  }

  /**
   * A list of up to 3 additional [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tags, listing possible alternative languages of the supplied audio. See [Language Support](https://cloud.google.com/speech-to-text/docs/languages) for a list of the currently supported language codes. If alternative languages are listed, recognition result will contain recognition in the most likely language detected including the main language_code. The recognition result will include the language tag of the language detected in the audio. Note: This feature is only supported for Voice Command and Voice Search use cases and performance may vary for other use cases (e.g., phone call transcription).
   * @return alternativeLanguageCodes
   */
  @javax.annotation.Nullable
  public List<String> getAlternativeLanguageCodes() {
    return alternativeLanguageCodes;
  }

  public void setAlternativeLanguageCodes(List<String> alternativeLanguageCodes) {
    this.alternativeLanguageCodes = alternativeLanguageCodes;
  }


  public RecognitionConfig audioChannelCount(Integer audioChannelCount) {
    this.audioChannelCount = audioChannelCount;
    return this;
  }

  /**
   * The number of channels in the input audio data. ONLY set this for MULTI-CHANNEL recognition. Valid values for LINEAR16, OGG_OPUS and FLAC are &#x60;1&#x60;-&#x60;8&#x60;. Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only &#x60;1&#x60;. If &#x60;0&#x60; or omitted, defaults to one channel (mono). Note: We only recognize the first channel by default. To perform independent recognition on each channel set &#x60;enable_separate_recognition_per_channel&#x60; to &#39;true&#39;.
   * @return audioChannelCount
   */
  @javax.annotation.Nullable
  public Integer getAudioChannelCount() {
    return audioChannelCount;
  }

  public void setAudioChannelCount(Integer audioChannelCount) {
    this.audioChannelCount = audioChannelCount;
  }


  public RecognitionConfig diarizationConfig(SpeakerDiarizationConfig diarizationConfig) {
    this.diarizationConfig = diarizationConfig;
    return this;
  }

  /**
   * Get diarizationConfig
   * @return diarizationConfig
   */
  @javax.annotation.Nullable
  public SpeakerDiarizationConfig getDiarizationConfig() {
    return diarizationConfig;
  }

  public void setDiarizationConfig(SpeakerDiarizationConfig diarizationConfig) {
    this.diarizationConfig = diarizationConfig;
  }


  public RecognitionConfig enableAutomaticPunctuation(Boolean enableAutomaticPunctuation) {
    this.enableAutomaticPunctuation = enableAutomaticPunctuation;
    return this;
  }

  /**
   * If &#39;true&#39;, adds punctuation to recognition result hypotheses. This feature is only available in select languages. Setting this for requests in other languages has no effect at all. The default &#39;false&#39; value does not add punctuation to result hypotheses.
   * @return enableAutomaticPunctuation
   */
  @javax.annotation.Nullable
  public Boolean getEnableAutomaticPunctuation() {
    return enableAutomaticPunctuation;
  }

  public void setEnableAutomaticPunctuation(Boolean enableAutomaticPunctuation) {
    this.enableAutomaticPunctuation = enableAutomaticPunctuation;
  }


  public RecognitionConfig enableSeparateRecognitionPerChannel(Boolean enableSeparateRecognitionPerChannel) {
    this.enableSeparateRecognitionPerChannel = enableSeparateRecognitionPerChannel;
    return this;
  }

  /**
   * This needs to be set to &#x60;true&#x60; explicitly and &#x60;audio_channel_count&#x60; &gt; 1 to get each channel recognized separately. The recognition result will contain a &#x60;channel_tag&#x60; field to state which channel that result belongs to. If this is not true, we will only recognize the first channel. The request is billed cumulatively for all channels recognized: &#x60;audio_channel_count&#x60; multiplied by the length of the audio.
   * @return enableSeparateRecognitionPerChannel
   */
  @javax.annotation.Nullable
  public Boolean getEnableSeparateRecognitionPerChannel() {
    return enableSeparateRecognitionPerChannel;
  }

  public void setEnableSeparateRecognitionPerChannel(Boolean enableSeparateRecognitionPerChannel) {
    this.enableSeparateRecognitionPerChannel = enableSeparateRecognitionPerChannel;
  }


  public RecognitionConfig enableSpokenEmojis(Boolean enableSpokenEmojis) {
    this.enableSpokenEmojis = enableSpokenEmojis;
    return this;
  }

  /**
   * The spoken emoji behavior for the call If not set, uses default behavior based on model of choice If &#39;true&#39;, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If &#39;false&#39;, spoken emojis are not replaced.
   * @return enableSpokenEmojis
   */
  @javax.annotation.Nullable
  public Boolean getEnableSpokenEmojis() {
    return enableSpokenEmojis;
  }

  public void setEnableSpokenEmojis(Boolean enableSpokenEmojis) {
    this.enableSpokenEmojis = enableSpokenEmojis;
  }


  public RecognitionConfig enableSpokenPunctuation(Boolean enableSpokenPunctuation) {
    this.enableSpokenPunctuation = enableSpokenPunctuation;
    return this;
  }

  /**
   * The spoken punctuation behavior for the call If not set, uses default behavior based on model of choice e.g. command_and_search will enable spoken punctuation by default If &#39;true&#39;, replaces spoken punctuation with the corresponding symbols in the request. For example, \&quot;how are you question mark\&quot; becomes \&quot;how are you?\&quot;. See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If &#39;false&#39;, spoken punctuation is not replaced.
   * @return enableSpokenPunctuation
   */
  @javax.annotation.Nullable
  public Boolean getEnableSpokenPunctuation() {
    return enableSpokenPunctuation;
  }

  public void setEnableSpokenPunctuation(Boolean enableSpokenPunctuation) {
    this.enableSpokenPunctuation = enableSpokenPunctuation;
  }


  public RecognitionConfig enableWordConfidence(Boolean enableWordConfidence) {
    this.enableWordConfidence = enableWordConfidence;
    return this;
  }

  /**
   * If &#x60;true&#x60;, the top result includes a list of words and the confidence for those words. If &#x60;false&#x60;, no word-level confidence information is returned. The default is &#x60;false&#x60;.
   * @return enableWordConfidence
   */
  @javax.annotation.Nullable
  public Boolean getEnableWordConfidence() {
    return enableWordConfidence;
  }

  public void setEnableWordConfidence(Boolean enableWordConfidence) {
    this.enableWordConfidence = enableWordConfidence;
  }


  public RecognitionConfig enableWordTimeOffsets(Boolean enableWordTimeOffsets) {
    this.enableWordTimeOffsets = enableWordTimeOffsets;
    return this;
  }

  /**
   * If &#x60;true&#x60;, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If &#x60;false&#x60;, no word-level time offset information is returned. The default is &#x60;false&#x60;.
   * @return enableWordTimeOffsets
   */
  @javax.annotation.Nullable
  public Boolean getEnableWordTimeOffsets() {
    return enableWordTimeOffsets;
  }

  public void setEnableWordTimeOffsets(Boolean enableWordTimeOffsets) {
    this.enableWordTimeOffsets = enableWordTimeOffsets;
  }


  public RecognitionConfig encoding(EncodingEnum encoding) {
    this.encoding = encoding;
    return this;
  }

  /**
   * Encoding of audio data sent in all &#x60;RecognitionAudio&#x60; messages. This field is optional for &#x60;FLAC&#x60; and &#x60;WAV&#x60; audio files and required for all other audio formats. For details, see AudioEncoding.
   * @return encoding
   */
  @javax.annotation.Nullable
  public EncodingEnum getEncoding() {
    return encoding;
  }

  public void setEncoding(EncodingEnum encoding) {
    this.encoding = encoding;
  }


  public RecognitionConfig languageCode(String languageCode) {
    this.languageCode = languageCode;
    return this;
  }

  /**
   * Required. The language of the supplied audio as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: \&quot;en-US\&quot;. See [Language Support](https://cloud.google.com/speech-to-text/docs/languages) for a list of the currently supported language codes.
   * @return languageCode
   */
  @javax.annotation.Nullable
  public String getLanguageCode() {
    return languageCode;
  }

  public void setLanguageCode(String languageCode) {
    this.languageCode = languageCode;
  }


  public RecognitionConfig maxAlternatives(Integer maxAlternatives) {
    this.maxAlternatives = maxAlternatives;
    return this;
  }

  /**
   * Maximum number of recognition hypotheses to be returned. Specifically, the maximum number of &#x60;SpeechRecognitionAlternative&#x60; messages within each &#x60;SpeechRecognitionResult&#x60;. The server may return fewer than &#x60;max_alternatives&#x60;. Valid values are &#x60;0&#x60;-&#x60;30&#x60;. A value of &#x60;0&#x60; or &#x60;1&#x60; will return a maximum of one. If omitted, will return a maximum of one.
   * @return maxAlternatives
   */
  @javax.annotation.Nullable
  public Integer getMaxAlternatives() {
    return maxAlternatives;
  }

  public void setMaxAlternatives(Integer maxAlternatives) {
    this.maxAlternatives = maxAlternatives;
  }


  @Deprecated
  public RecognitionConfig metadata(RecognitionMetadata metadata) {
    this.metadata = metadata;
    return this;
  }

  /**
   * Get metadata
   * @return metadata
   * @deprecated
   */
  @Deprecated
  @javax.annotation.Nullable
  public RecognitionMetadata getMetadata() {
    return metadata;
  }

  @Deprecated
  public void setMetadata(RecognitionMetadata metadata) {
    this.metadata = metadata;
  }


  public RecognitionConfig model(String model) {
    this.model = model;
    return this;
  }

  /**
   * Which model to select for the given request. Select the model best suited to your domain to get best results. If a model is not explicitly specified, then we auto-select a model based on the parameters in the RecognitionConfig. *Model* *Description* latest_long Best for long form content like media or conversation. latest_short Best for short form content like commands or single shot directed speech. command_and_search Best for short queries such as voice commands or voice search. phone_call Best for audio that originated from a phone call (typically recorded at an 8khz sampling rate). video Best for audio that originated from video or includes multiple speakers. Ideally the audio is recorded at a 16khz or greater sampling rate. This is a premium model that costs more than the standard rate. default Best for audio that is not one of the specific audio models. For example, long-form audio. Ideally the audio is high-fidelity, recorded at a 16khz or greater sampling rate. medical_conversation Best for audio that originated from a conversation between a medical provider and patient. medical_dictation Best for audio that originated from dictation notes by a medical provider. 
   * @return model
   */
  @javax.annotation.Nullable
  public String getModel() {
    return model;
  }

  public void setModel(String model) {
    this.model = model;
  }


  public RecognitionConfig profanityFilter(Boolean profanityFilter) {
    this.profanityFilter = profanityFilter;
    return this;
  }

  /**
   * If set to &#x60;true&#x60;, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, e.g. \&quot;f***\&quot;. If set to &#x60;false&#x60; or omitted, profanities won&#39;t be filtered out.
   * @return profanityFilter
   */
  @javax.annotation.Nullable
  public Boolean getProfanityFilter() {
    return profanityFilter;
  }

  public void setProfanityFilter(Boolean profanityFilter) {
    this.profanityFilter = profanityFilter;
  }


  public RecognitionConfig sampleRateHertz(Integer sampleRateHertz) {
    this.sampleRateHertz = sampleRateHertz;
    return this;
  }

  /**
   * Sample rate in Hertz of the audio data sent in all &#x60;RecognitionAudio&#x60; messages. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that&#39;s not possible, use the native sample rate of the audio source (instead of re-sampling). This field is optional for FLAC and WAV audio files, but is required for all other audio formats. For details, see AudioEncoding.
   * @return sampleRateHertz
   */
  @javax.annotation.Nullable
  public Integer getSampleRateHertz() {
    return sampleRateHertz;
  }

  public void setSampleRateHertz(Integer sampleRateHertz) {
    this.sampleRateHertz = sampleRateHertz;
  }


  public RecognitionConfig speechContexts(List<SpeechContext> speechContexts) {
    this.speechContexts = speechContexts;
    return this;
  }

  public RecognitionConfig addSpeechContextsItem(SpeechContext speechContextsItem) {
    if (this.speechContexts == null) {
      this.speechContexts = new ArrayList<>();
    }
    this.speechContexts.add(speechContextsItem);
    return this;
  }

  /**
   * Array of SpeechContext. A means to provide context to assist the speech recognition. For more information, see [speech adaptation](https://cloud.google.com/speech-to-text/docs/adaptation).
   * @return speechContexts
   */
  @javax.annotation.Nullable
  public List<SpeechContext> getSpeechContexts() {
    return speechContexts;
  }

  public void setSpeechContexts(List<SpeechContext> speechContexts) {
    this.speechContexts = speechContexts;
  }


  public RecognitionConfig transcriptNormalization(TranscriptNormalization transcriptNormalization) {
    this.transcriptNormalization = transcriptNormalization;
    return this;
  }

  /**
   * Get transcriptNormalization
   * @return transcriptNormalization
   */
  @javax.annotation.Nullable
  public TranscriptNormalization getTranscriptNormalization() {
    return transcriptNormalization;
  }

  public void setTranscriptNormalization(TranscriptNormalization transcriptNormalization) {
    this.transcriptNormalization = transcriptNormalization;
  }


  public RecognitionConfig useEnhanced(Boolean useEnhanced) {
    this.useEnhanced = useEnhanced;
    return this;
  }

  /**
   * Set to true to use an enhanced model for speech recognition. If &#x60;use_enhanced&#x60; is set to true and the &#x60;model&#x60; field is not set, then an appropriate enhanced model is chosen if an enhanced model exists for the audio. If &#x60;use_enhanced&#x60; is true and an enhanced version of the specified model does not exist, then the speech is recognized using the standard version of the specified model.
   * @return useEnhanced
   */
  @javax.annotation.Nullable
  public Boolean getUseEnhanced() {
    return useEnhanced;
  }

  public void setUseEnhanced(Boolean useEnhanced) {
    this.useEnhanced = useEnhanced;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    RecognitionConfig recognitionConfig = (RecognitionConfig) o;
    return Objects.equals(this.adaptation, recognitionConfig.adaptation) &&
        Objects.equals(this.alternativeLanguageCodes, recognitionConfig.alternativeLanguageCodes) &&
        Objects.equals(this.audioChannelCount, recognitionConfig.audioChannelCount) &&
        Objects.equals(this.diarizationConfig, recognitionConfig.diarizationConfig) &&
        Objects.equals(this.enableAutomaticPunctuation, recognitionConfig.enableAutomaticPunctuation) &&
        Objects.equals(this.enableSeparateRecognitionPerChannel, recognitionConfig.enableSeparateRecognitionPerChannel) &&
        Objects.equals(this.enableSpokenEmojis, recognitionConfig.enableSpokenEmojis) &&
        Objects.equals(this.enableSpokenPunctuation, recognitionConfig.enableSpokenPunctuation) &&
        Objects.equals(this.enableWordConfidence, recognitionConfig.enableWordConfidence) &&
        Objects.equals(this.enableWordTimeOffsets, recognitionConfig.enableWordTimeOffsets) &&
        Objects.equals(this.encoding, recognitionConfig.encoding) &&
        Objects.equals(this.languageCode, recognitionConfig.languageCode) &&
        Objects.equals(this.maxAlternatives, recognitionConfig.maxAlternatives) &&
        Objects.equals(this.metadata, recognitionConfig.metadata) &&
        Objects.equals(this.model, recognitionConfig.model) &&
        Objects.equals(this.profanityFilter, recognitionConfig.profanityFilter) &&
        Objects.equals(this.sampleRateHertz, recognitionConfig.sampleRateHertz) &&
        Objects.equals(this.speechContexts, recognitionConfig.speechContexts) &&
        Objects.equals(this.transcriptNormalization, recognitionConfig.transcriptNormalization) &&
        Objects.equals(this.useEnhanced, recognitionConfig.useEnhanced);
  }

  @Override
  public int hashCode() {
    return Objects.hash(adaptation, alternativeLanguageCodes, audioChannelCount, diarizationConfig, enableAutomaticPunctuation, enableSeparateRecognitionPerChannel, enableSpokenEmojis, enableSpokenPunctuation, enableWordConfidence, enableWordTimeOffsets, encoding, languageCode, maxAlternatives, metadata, model, profanityFilter, sampleRateHertz, speechContexts, transcriptNormalization, useEnhanced);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class RecognitionConfig {\n");
    sb.append("    adaptation: ").append(toIndentedString(adaptation)).append("\n");
    sb.append("    alternativeLanguageCodes: ").append(toIndentedString(alternativeLanguageCodes)).append("\n");
    sb.append("    audioChannelCount: ").append(toIndentedString(audioChannelCount)).append("\n");
    sb.append("    diarizationConfig: ").append(toIndentedString(diarizationConfig)).append("\n");
    sb.append("    enableAutomaticPunctuation: ").append(toIndentedString(enableAutomaticPunctuation)).append("\n");
    sb.append("    enableSeparateRecognitionPerChannel: ").append(toIndentedString(enableSeparateRecognitionPerChannel)).append("\n");
    sb.append("    enableSpokenEmojis: ").append(toIndentedString(enableSpokenEmojis)).append("\n");
    sb.append("    enableSpokenPunctuation: ").append(toIndentedString(enableSpokenPunctuation)).append("\n");
    sb.append("    enableWordConfidence: ").append(toIndentedString(enableWordConfidence)).append("\n");
    sb.append("    enableWordTimeOffsets: ").append(toIndentedString(enableWordTimeOffsets)).append("\n");
    sb.append("    encoding: ").append(toIndentedString(encoding)).append("\n");
    sb.append("    languageCode: ").append(toIndentedString(languageCode)).append("\n");
    sb.append("    maxAlternatives: ").append(toIndentedString(maxAlternatives)).append("\n");
    sb.append("    metadata: ").append(toIndentedString(metadata)).append("\n");
    sb.append("    model: ").append(toIndentedString(model)).append("\n");
    sb.append("    profanityFilter: ").append(toIndentedString(profanityFilter)).append("\n");
    sb.append("    sampleRateHertz: ").append(toIndentedString(sampleRateHertz)).append("\n");
    sb.append("    speechContexts: ").append(toIndentedString(speechContexts)).append("\n");
    sb.append("    transcriptNormalization: ").append(toIndentedString(transcriptNormalization)).append("\n");
    sb.append("    useEnhanced: ").append(toIndentedString(useEnhanced)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("adaptation");
    openapiFields.add("alternativeLanguageCodes");
    openapiFields.add("audioChannelCount");
    openapiFields.add("diarizationConfig");
    openapiFields.add("enableAutomaticPunctuation");
    openapiFields.add("enableSeparateRecognitionPerChannel");
    openapiFields.add("enableSpokenEmojis");
    openapiFields.add("enableSpokenPunctuation");
    openapiFields.add("enableWordConfidence");
    openapiFields.add("enableWordTimeOffsets");
    openapiFields.add("encoding");
    openapiFields.add("languageCode");
    openapiFields.add("maxAlternatives");
    openapiFields.add("metadata");
    openapiFields.add("model");
    openapiFields.add("profanityFilter");
    openapiFields.add("sampleRateHertz");
    openapiFields.add("speechContexts");
    openapiFields.add("transcriptNormalization");
    openapiFields.add("useEnhanced");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to RecognitionConfig
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!RecognitionConfig.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in RecognitionConfig is not found in the empty JSON string", RecognitionConfig.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!RecognitionConfig.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `RecognitionConfig` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // validate the optional field `adaptation`
      if (jsonObj.get("adaptation") != null && !jsonObj.get("adaptation").isJsonNull()) {
        SpeechAdaptation.validateJsonElement(jsonObj.get("adaptation"));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("alternativeLanguageCodes") != null && !jsonObj.get("alternativeLanguageCodes").isJsonNull() && !jsonObj.get("alternativeLanguageCodes").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `alternativeLanguageCodes` to be an array in the JSON string but got `%s`", jsonObj.get("alternativeLanguageCodes").toString()));
      }
      // validate the optional field `diarizationConfig`
      if (jsonObj.get("diarizationConfig") != null && !jsonObj.get("diarizationConfig").isJsonNull()) {
        SpeakerDiarizationConfig.validateJsonElement(jsonObj.get("diarizationConfig"));
      }
      if ((jsonObj.get("encoding") != null && !jsonObj.get("encoding").isJsonNull()) && !jsonObj.get("encoding").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `encoding` to be a primitive type in the JSON string but got `%s`", jsonObj.get("encoding").toString()));
      }
      // validate the optional field `encoding`
      if (jsonObj.get("encoding") != null && !jsonObj.get("encoding").isJsonNull()) {
        EncodingEnum.validateJsonElement(jsonObj.get("encoding"));
      }
      if ((jsonObj.get("languageCode") != null && !jsonObj.get("languageCode").isJsonNull()) && !jsonObj.get("languageCode").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `languageCode` to be a primitive type in the JSON string but got `%s`", jsonObj.get("languageCode").toString()));
      }
      // validate the optional field `metadata`
      if (jsonObj.get("metadata") != null && !jsonObj.get("metadata").isJsonNull()) {
        RecognitionMetadata.validateJsonElement(jsonObj.get("metadata"));
      }
      if ((jsonObj.get("model") != null && !jsonObj.get("model").isJsonNull()) && !jsonObj.get("model").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `model` to be a primitive type in the JSON string but got `%s`", jsonObj.get("model").toString()));
      }
      if (jsonObj.get("speechContexts") != null && !jsonObj.get("speechContexts").isJsonNull()) {
        JsonArray jsonArrayspeechContexts = jsonObj.getAsJsonArray("speechContexts");
        if (jsonArrayspeechContexts != null) {
          // ensure the json data is an array
          if (!jsonObj.get("speechContexts").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `speechContexts` to be an array in the JSON string but got `%s`", jsonObj.get("speechContexts").toString()));
          }

          // validate the optional field `speechContexts` (array)
          for (int i = 0; i < jsonArrayspeechContexts.size(); i++) {
            SpeechContext.validateJsonElement(jsonArrayspeechContexts.get(i));
          };
        }
      }
      // validate the optional field `transcriptNormalization`
      if (jsonObj.get("transcriptNormalization") != null && !jsonObj.get("transcriptNormalization").isJsonNull()) {
        TranscriptNormalization.validateJsonElement(jsonObj.get("transcriptNormalization"));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!RecognitionConfig.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'RecognitionConfig' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<RecognitionConfig> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(RecognitionConfig.class));

       return (TypeAdapter<T>) new TypeAdapter<RecognitionConfig>() {
           @Override
           public void write(JsonWriter out, RecognitionConfig value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public RecognitionConfig read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of RecognitionConfig given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of RecognitionConfig
   * @throws IOException if the JSON string is invalid with respect to RecognitionConfig
   */
  public static RecognitionConfig fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, RecognitionConfig.class);
  }

  /**
   * Convert an instance of RecognitionConfig to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

