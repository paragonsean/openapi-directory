/*
 * Cloud Asset API
 * The Cloud Asset API manages the history and inventory of Google Cloud resources.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.Arrays;
import org.openapitools.client.model.PartitionSpec;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * A BigQuery destination for exporting assets to.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:36:52.366195-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class BigQueryDestination {
  public static final String SERIALIZED_NAME_DATASET = "dataset";
  @SerializedName(SERIALIZED_NAME_DATASET)
  private String dataset;

  public static final String SERIALIZED_NAME_FORCE = "force";
  @SerializedName(SERIALIZED_NAME_FORCE)
  private Boolean force;

  public static final String SERIALIZED_NAME_PARTITION_SPEC = "partitionSpec";
  @SerializedName(SERIALIZED_NAME_PARTITION_SPEC)
  private PartitionSpec partitionSpec;

  public static final String SERIALIZED_NAME_SEPARATE_TABLES_PER_ASSET_TYPE = "separateTablesPerAssetType";
  @SerializedName(SERIALIZED_NAME_SEPARATE_TABLES_PER_ASSET_TYPE)
  private Boolean separateTablesPerAssetType;

  public static final String SERIALIZED_NAME_TABLE = "table";
  @SerializedName(SERIALIZED_NAME_TABLE)
  private String table;

  public BigQueryDestination() {
  }

  public BigQueryDestination dataset(String dataset) {
    this.dataset = dataset;
    return this;
  }

  /**
   * Required. The BigQuery dataset in format \&quot;projects/projectId/datasets/datasetId\&quot;, to which the snapshot result should be exported. If this dataset does not exist, the export call returns an INVALID_ARGUMENT error. Setting the &#x60;contentType&#x60; for &#x60;exportAssets&#x60; determines the [schema](/asset-inventory/docs/exporting-to-bigquery#bigquery-schema) of the BigQuery table. Setting &#x60;separateTablesPerAssetType&#x60; to &#x60;TRUE&#x60; also influences the schema.
   * @return dataset
   */
  @javax.annotation.Nullable
  public String getDataset() {
    return dataset;
  }

  public void setDataset(String dataset) {
    this.dataset = dataset;
  }


  public BigQueryDestination force(Boolean force) {
    this.force = force;
    return this;
  }

  /**
   * If the destination table already exists and this flag is &#x60;TRUE&#x60;, the table will be overwritten by the contents of assets snapshot. If the flag is &#x60;FALSE&#x60; or unset and the destination table already exists, the export call returns an INVALID_ARGUMEMT error.
   * @return force
   */
  @javax.annotation.Nullable
  public Boolean getForce() {
    return force;
  }

  public void setForce(Boolean force) {
    this.force = force;
  }


  public BigQueryDestination partitionSpec(PartitionSpec partitionSpec) {
    this.partitionSpec = partitionSpec;
    return this;
  }

  /**
   * Get partitionSpec
   * @return partitionSpec
   */
  @javax.annotation.Nullable
  public PartitionSpec getPartitionSpec() {
    return partitionSpec;
  }

  public void setPartitionSpec(PartitionSpec partitionSpec) {
    this.partitionSpec = partitionSpec;
  }


  public BigQueryDestination separateTablesPerAssetType(Boolean separateTablesPerAssetType) {
    this.separateTablesPerAssetType = separateTablesPerAssetType;
    return this;
  }

  /**
   * If this flag is &#x60;TRUE&#x60;, the snapshot results will be written to one or multiple tables, each of which contains results of one asset type. The [force] and [partition_spec] fields will apply to each of them. Field [table] will be concatenated with \&quot;_\&quot; and the asset type names (see https://cloud.google.com/asset-inventory/docs/supported-asset-types for supported asset types) to construct per-asset-type table names, in which all non-alphanumeric characters like \&quot;.\&quot; and \&quot;/\&quot; will be substituted by \&quot;_\&quot;. Example: if field [table] is \&quot;mytable\&quot; and snapshot results contain \&quot;storage.googleapis.com/Bucket\&quot; assets, the corresponding table name will be \&quot;mytable_storage_googleapis_com_Bucket\&quot;. If any of these tables does not exist, a new table with the concatenated name will be created. When [content_type] in the ExportAssetsRequest is &#x60;RESOURCE&#x60;, the schema of each table will include RECORD-type columns mapped to the nested fields in the Asset.resource.data field of that asset type (up to the 15 nested level BigQuery supports (https://cloud.google.com/bigquery/docs/nested-repeated#limitations)). The fields in &gt;15 nested levels will be stored in JSON format string as a child column of its parent RECORD column. If error occurs when exporting to any table, the whole export call will return an error but the export results that already succeed will persist. Example: if exporting to table_type_A succeeds when exporting to table_type_B fails during one export call, the results in table_type_A will persist and there will not be partial results persisting in a table.
   * @return separateTablesPerAssetType
   */
  @javax.annotation.Nullable
  public Boolean getSeparateTablesPerAssetType() {
    return separateTablesPerAssetType;
  }

  public void setSeparateTablesPerAssetType(Boolean separateTablesPerAssetType) {
    this.separateTablesPerAssetType = separateTablesPerAssetType;
  }


  public BigQueryDestination table(String table) {
    this.table = table;
    return this;
  }

  /**
   * Required. The BigQuery table to which the snapshot result should be written. If this table does not exist, a new table with the given name will be created.
   * @return table
   */
  @javax.annotation.Nullable
  public String getTable() {
    return table;
  }

  public void setTable(String table) {
    this.table = table;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    BigQueryDestination bigQueryDestination = (BigQueryDestination) o;
    return Objects.equals(this.dataset, bigQueryDestination.dataset) &&
        Objects.equals(this.force, bigQueryDestination.force) &&
        Objects.equals(this.partitionSpec, bigQueryDestination.partitionSpec) &&
        Objects.equals(this.separateTablesPerAssetType, bigQueryDestination.separateTablesPerAssetType) &&
        Objects.equals(this.table, bigQueryDestination.table);
  }

  @Override
  public int hashCode() {
    return Objects.hash(dataset, force, partitionSpec, separateTablesPerAssetType, table);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class BigQueryDestination {\n");
    sb.append("    dataset: ").append(toIndentedString(dataset)).append("\n");
    sb.append("    force: ").append(toIndentedString(force)).append("\n");
    sb.append("    partitionSpec: ").append(toIndentedString(partitionSpec)).append("\n");
    sb.append("    separateTablesPerAssetType: ").append(toIndentedString(separateTablesPerAssetType)).append("\n");
    sb.append("    table: ").append(toIndentedString(table)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("dataset");
    openapiFields.add("force");
    openapiFields.add("partitionSpec");
    openapiFields.add("separateTablesPerAssetType");
    openapiFields.add("table");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to BigQueryDestination
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!BigQueryDestination.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in BigQueryDestination is not found in the empty JSON string", BigQueryDestination.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!BigQueryDestination.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `BigQueryDestination` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      if ((jsonObj.get("dataset") != null && !jsonObj.get("dataset").isJsonNull()) && !jsonObj.get("dataset").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `dataset` to be a primitive type in the JSON string but got `%s`", jsonObj.get("dataset").toString()));
      }
      // validate the optional field `partitionSpec`
      if (jsonObj.get("partitionSpec") != null && !jsonObj.get("partitionSpec").isJsonNull()) {
        PartitionSpec.validateJsonElement(jsonObj.get("partitionSpec"));
      }
      if ((jsonObj.get("table") != null && !jsonObj.get("table").isJsonNull()) && !jsonObj.get("table").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `table` to be a primitive type in the JSON string but got `%s`", jsonObj.get("table").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!BigQueryDestination.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'BigQueryDestination' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<BigQueryDestination> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(BigQueryDestination.class));

       return (TypeAdapter<T>) new TypeAdapter<BigQueryDestination>() {
           @Override
           public void write(JsonWriter out, BigQueryDestination value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public BigQueryDestination read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of BigQueryDestination given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of BigQueryDestination
   * @throws IOException if the JSON string is invalid with respect to BigQueryDestination
   */
  public static BigQueryDestination fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, BigQueryDestination.class);
  }

  /**
   * Convert an instance of BigQueryDestination to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

