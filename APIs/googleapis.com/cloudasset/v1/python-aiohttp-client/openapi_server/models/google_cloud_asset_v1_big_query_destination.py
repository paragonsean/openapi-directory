# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server import util


class GoogleCloudAssetV1BigQueryDestination(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, dataset: str=None, partition_key: str=None, table_prefix: str=None, write_disposition: str=None):
        """GoogleCloudAssetV1BigQueryDestination - a model defined in OpenAPI

        :param dataset: The dataset of this GoogleCloudAssetV1BigQueryDestination.
        :param partition_key: The partition_key of this GoogleCloudAssetV1BigQueryDestination.
        :param table_prefix: The table_prefix of this GoogleCloudAssetV1BigQueryDestination.
        :param write_disposition: The write_disposition of this GoogleCloudAssetV1BigQueryDestination.
        """
        self.openapi_types = {
            'dataset': str,
            'partition_key': str,
            'table_prefix': str,
            'write_disposition': str
        }

        self.attribute_map = {
            'dataset': 'dataset',
            'partition_key': 'partitionKey',
            'table_prefix': 'tablePrefix',
            'write_disposition': 'writeDisposition'
        }

        self._dataset = dataset
        self._partition_key = partition_key
        self._table_prefix = table_prefix
        self._write_disposition = write_disposition

    @classmethod
    def from_dict(cls, dikt: dict) -> 'GoogleCloudAssetV1BigQueryDestination':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The GoogleCloudAssetV1BigQueryDestination of this GoogleCloudAssetV1BigQueryDestination.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def dataset(self):
        """Gets the dataset of this GoogleCloudAssetV1BigQueryDestination.

        Required. The BigQuery dataset in format \"projects/projectId/datasets/datasetId\", to which the analysis results should be exported. If this dataset does not exist, the export call will return an INVALID_ARGUMENT error.

        :return: The dataset of this GoogleCloudAssetV1BigQueryDestination.
        :rtype: str
        """
        return self._dataset

    @dataset.setter
    def dataset(self, dataset):
        """Sets the dataset of this GoogleCloudAssetV1BigQueryDestination.

        Required. The BigQuery dataset in format \"projects/projectId/datasets/datasetId\", to which the analysis results should be exported. If this dataset does not exist, the export call will return an INVALID_ARGUMENT error.

        :param dataset: The dataset of this GoogleCloudAssetV1BigQueryDestination.
        :type dataset: str
        """

        self._dataset = dataset

    @property
    def partition_key(self):
        """Gets the partition_key of this GoogleCloudAssetV1BigQueryDestination.

        The partition key for BigQuery partitioned table.

        :return: The partition_key of this GoogleCloudAssetV1BigQueryDestination.
        :rtype: str
        """
        return self._partition_key

    @partition_key.setter
    def partition_key(self, partition_key):
        """Sets the partition_key of this GoogleCloudAssetV1BigQueryDestination.

        The partition key for BigQuery partitioned table.

        :param partition_key: The partition_key of this GoogleCloudAssetV1BigQueryDestination.
        :type partition_key: str
        """
        allowed_values = ["PARTITION_KEY_UNSPECIFIED", "REQUEST_TIME"]  # noqa: E501
        if partition_key not in allowed_values:
            raise ValueError(
                "Invalid value for `partition_key` ({0}), must be one of {1}"
                .format(partition_key, allowed_values)
            )

        self._partition_key = partition_key

    @property
    def table_prefix(self):
        """Gets the table_prefix of this GoogleCloudAssetV1BigQueryDestination.

        Required. The prefix of the BigQuery tables to which the analysis results will be written. Tables will be created based on this table_prefix if not exist: * _analysis table will contain export operation's metadata. * _analysis_result will contain all the IamPolicyAnalysisResult. When [partition_key] is specified, both tables will be partitioned based on the [partition_key].

        :return: The table_prefix of this GoogleCloudAssetV1BigQueryDestination.
        :rtype: str
        """
        return self._table_prefix

    @table_prefix.setter
    def table_prefix(self, table_prefix):
        """Sets the table_prefix of this GoogleCloudAssetV1BigQueryDestination.

        Required. The prefix of the BigQuery tables to which the analysis results will be written. Tables will be created based on this table_prefix if not exist: * _analysis table will contain export operation's metadata. * _analysis_result will contain all the IamPolicyAnalysisResult. When [partition_key] is specified, both tables will be partitioned based on the [partition_key].

        :param table_prefix: The table_prefix of this GoogleCloudAssetV1BigQueryDestination.
        :type table_prefix: str
        """

        self._table_prefix = table_prefix

    @property
    def write_disposition(self):
        """Gets the write_disposition of this GoogleCloudAssetV1BigQueryDestination.

        Optional. Specifies the action that occurs if the destination table or partition already exists. The following values are supported: * WRITE_TRUNCATE: If the table or partition already exists, BigQuery overwrites the entire table or all the partitions data. * WRITE_APPEND: If the table or partition already exists, BigQuery appends the data to the table or the latest partition. * WRITE_EMPTY: If the table already exists and contains data, an error is returned. The default value is WRITE_APPEND. Each action is atomic and only occurs if BigQuery is able to complete the job successfully. Details are at https://cloud.google.com/bigquery/docs/loading-data-local#appending_to_or_overwriting_a_table_using_a_local_file.

        :return: The write_disposition of this GoogleCloudAssetV1BigQueryDestination.
        :rtype: str
        """
        return self._write_disposition

    @write_disposition.setter
    def write_disposition(self, write_disposition):
        """Sets the write_disposition of this GoogleCloudAssetV1BigQueryDestination.

        Optional. Specifies the action that occurs if the destination table or partition already exists. The following values are supported: * WRITE_TRUNCATE: If the table or partition already exists, BigQuery overwrites the entire table or all the partitions data. * WRITE_APPEND: If the table or partition already exists, BigQuery appends the data to the table or the latest partition. * WRITE_EMPTY: If the table already exists and contains data, an error is returned. The default value is WRITE_APPEND. Each action is atomic and only occurs if BigQuery is able to complete the job successfully. Details are at https://cloud.google.com/bigquery/docs/loading-data-local#appending_to_or_overwriting_a_table_using_a_local_file.

        :param write_disposition: The write_disposition of this GoogleCloudAssetV1BigQueryDestination.
        :type write_disposition: str
        """

        self._write_disposition = write_disposition
