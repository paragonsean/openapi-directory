/**
 * Remote Build Execution API
 * Supplies a Remote Execution API service for tools such as bazel.
 *
 * The version of the OpenAPI document: v1alpha
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * OAIBuildBazelRemoteExecutionV2Digest.h
 *
 * A content digest. A digest for a given blob consists of the size of the blob and its hash. The hash algorithm to use is defined by the server. The size is considered to be an integral part of the digest and cannot be separated. That is, even if the &#x60;hash&#x60; field is correctly specified but &#x60;size_bytes&#x60; is not, the server MUST reject the request. The reason for including the size in the digest is as follows: in a great many cases, the server needs to know the size of the blob it is about to work with prior to starting an operation with it, such as flattening Merkle tree structures or streaming it to a worker. Technically, the server could implement a separate metadata store, but this results in a significantly more complicated implementation as opposed to having the client specify the size up-front (or storing the size along with the digest in every message where digests are embedded). This does mean that the API leaks some implementation details of (what we consider to be) a reasonable server implementation, but we consider this to be a worthwhile tradeoff. When a &#x60;Digest&#x60; is used to refer to a proto message, it always refers to the message in binary encoded form. To ensure consistent hashing, clients and servers MUST ensure that they serialize messages according to the following rules, even if there are alternate valid encodings for the same message: * Fields are serialized in tag order. * There are no unknown fields. * There are no duplicate fields. * Fields are serialized according to the default semantics for their type. Most protocol buffer implementations will always follow these rules when serializing, but care should be taken to avoid shortcuts. For instance, concatenating two messages to merge them may produce duplicate fields.
 */

#ifndef OAIBuildBazelRemoteExecutionV2Digest_H
#define OAIBuildBazelRemoteExecutionV2Digest_H

#include <QJsonObject>

#include <QString>

#include "OAIEnum.h"
#include "OAIObject.h"

namespace OpenAPI {

class OAIBuildBazelRemoteExecutionV2Digest : public OAIObject {
public:
    OAIBuildBazelRemoteExecutionV2Digest();
    OAIBuildBazelRemoteExecutionV2Digest(QString json);
    ~OAIBuildBazelRemoteExecutionV2Digest() override;

    QString asJson() const override;
    QJsonObject asJsonObject() const override;
    void fromJsonObject(QJsonObject json) override;
    void fromJson(QString jsonString) override;

    QString getHash() const;
    void setHash(const QString &hash);
    bool is_hash_Set() const;
    bool is_hash_Valid() const;

    QString getSizeBytes() const;
    void setSizeBytes(const QString &size_bytes);
    bool is_size_bytes_Set() const;
    bool is_size_bytes_Valid() const;

    virtual bool isSet() const override;
    virtual bool isValid() const override;

private:
    void initializeModel();

    QString m_hash;
    bool m_hash_isSet;
    bool m_hash_isValid;

    QString m_size_bytes;
    bool m_size_bytes_isSet;
    bool m_size_bytes_isValid;
};

} // namespace OpenAPI

Q_DECLARE_METATYPE(OpenAPI::OAIBuildBazelRemoteExecutionV2Digest)

#endif // OAIBuildBazelRemoteExecutionV2Digest_H
