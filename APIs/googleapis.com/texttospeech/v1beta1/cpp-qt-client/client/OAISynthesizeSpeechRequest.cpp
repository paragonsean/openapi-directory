/**
 * Cloud Text-to-Speech API
 * Synthesizes natural-sounding speech by applying powerful neural network models.
 *
 * The version of the OpenAPI document: v1beta1
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAISynthesizeSpeechRequest.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAISynthesizeSpeechRequest::OAISynthesizeSpeechRequest(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAISynthesizeSpeechRequest::OAISynthesizeSpeechRequest() {
    this->initializeModel();
}

OAISynthesizeSpeechRequest::~OAISynthesizeSpeechRequest() {}

void OAISynthesizeSpeechRequest::initializeModel() {

    m_audio_config_isSet = false;
    m_audio_config_isValid = false;

    m_enable_time_pointing_isSet = false;
    m_enable_time_pointing_isValid = false;

    m_input_isSet = false;
    m_input_isValid = false;

    m_voice_isSet = false;
    m_voice_isValid = false;
}

void OAISynthesizeSpeechRequest::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAISynthesizeSpeechRequest::fromJsonObject(QJsonObject json) {

    m_audio_config_isValid = ::OpenAPI::fromJsonValue(m_audio_config, json[QString("audioConfig")]);
    m_audio_config_isSet = !json[QString("audioConfig")].isNull() && m_audio_config_isValid;

    m_enable_time_pointing_isValid = ::OpenAPI::fromJsonValue(m_enable_time_pointing, json[QString("enableTimePointing")]);
    m_enable_time_pointing_isSet = !json[QString("enableTimePointing")].isNull() && m_enable_time_pointing_isValid;

    m_input_isValid = ::OpenAPI::fromJsonValue(m_input, json[QString("input")]);
    m_input_isSet = !json[QString("input")].isNull() && m_input_isValid;

    m_voice_isValid = ::OpenAPI::fromJsonValue(m_voice, json[QString("voice")]);
    m_voice_isSet = !json[QString("voice")].isNull() && m_voice_isValid;
}

QString OAISynthesizeSpeechRequest::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAISynthesizeSpeechRequest::asJsonObject() const {
    QJsonObject obj;
    if (m_audio_config.isSet()) {
        obj.insert(QString("audioConfig"), ::OpenAPI::toJsonValue(m_audio_config));
    }
    if (m_enable_time_pointing.size() > 0) {
        obj.insert(QString("enableTimePointing"), ::OpenAPI::toJsonValue(m_enable_time_pointing));
    }
    if (m_input.isSet()) {
        obj.insert(QString("input"), ::OpenAPI::toJsonValue(m_input));
    }
    if (m_voice.isSet()) {
        obj.insert(QString("voice"), ::OpenAPI::toJsonValue(m_voice));
    }
    return obj;
}

OAIAudioConfig OAISynthesizeSpeechRequest::getAudioConfig() const {
    return m_audio_config;
}
void OAISynthesizeSpeechRequest::setAudioConfig(const OAIAudioConfig &audio_config) {
    m_audio_config = audio_config;
    m_audio_config_isSet = true;
}

bool OAISynthesizeSpeechRequest::is_audio_config_Set() const{
    return m_audio_config_isSet;
}

bool OAISynthesizeSpeechRequest::is_audio_config_Valid() const{
    return m_audio_config_isValid;
}

QList<QString> OAISynthesizeSpeechRequest::getEnableTimePointing() const {
    return m_enable_time_pointing;
}
void OAISynthesizeSpeechRequest::setEnableTimePointing(const QList<QString> &enable_time_pointing) {
    m_enable_time_pointing = enable_time_pointing;
    m_enable_time_pointing_isSet = true;
}

bool OAISynthesizeSpeechRequest::is_enable_time_pointing_Set() const{
    return m_enable_time_pointing_isSet;
}

bool OAISynthesizeSpeechRequest::is_enable_time_pointing_Valid() const{
    return m_enable_time_pointing_isValid;
}

OAISynthesisInput OAISynthesizeSpeechRequest::getInput() const {
    return m_input;
}
void OAISynthesizeSpeechRequest::setInput(const OAISynthesisInput &input) {
    m_input = input;
    m_input_isSet = true;
}

bool OAISynthesizeSpeechRequest::is_input_Set() const{
    return m_input_isSet;
}

bool OAISynthesizeSpeechRequest::is_input_Valid() const{
    return m_input_isValid;
}

OAIVoiceSelectionParams OAISynthesizeSpeechRequest::getVoice() const {
    return m_voice;
}
void OAISynthesizeSpeechRequest::setVoice(const OAIVoiceSelectionParams &voice) {
    m_voice = voice;
    m_voice_isSet = true;
}

bool OAISynthesizeSpeechRequest::is_voice_Set() const{
    return m_voice_isSet;
}

bool OAISynthesizeSpeechRequest::is_voice_Valid() const{
    return m_voice_isValid;
}

bool OAISynthesizeSpeechRequest::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_audio_config.isSet()) {
            isObjectUpdated = true;
            break;
        }

        if (m_enable_time_pointing.size() > 0) {
            isObjectUpdated = true;
            break;
        }

        if (m_input.isSet()) {
            isObjectUpdated = true;
            break;
        }

        if (m_voice.isSet()) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAISynthesizeSpeechRequest::isValid() const {
    // only required properties are required for the object to be considered valid
    return true;
}

} // namespace OpenAPI
