/*
 * Cloud Text-to-Speech API
 * Synthesizes natural-sounding speech by applying powerful neural network models.
 *
 * The version of the OpenAPI document: v1beta1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.openapitools.client.model.AudioConfig;
import org.openapitools.client.model.Timepoint;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * The message returned to the client by the &#x60;SynthesizeSpeech&#x60; method.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:48:11.482940-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class SynthesizeSpeechResponse {
  public static final String SERIALIZED_NAME_AUDIO_CONFIG = "audioConfig";
  @SerializedName(SERIALIZED_NAME_AUDIO_CONFIG)
  private AudioConfig audioConfig;

  public static final String SERIALIZED_NAME_AUDIO_CONTENT = "audioContent";
  @SerializedName(SERIALIZED_NAME_AUDIO_CONTENT)
  private byte[] audioContent;

  public static final String SERIALIZED_NAME_TIMEPOINTS = "timepoints";
  @SerializedName(SERIALIZED_NAME_TIMEPOINTS)
  private List<Timepoint> timepoints = new ArrayList<>();

  public SynthesizeSpeechResponse() {
  }

  public SynthesizeSpeechResponse audioConfig(AudioConfig audioConfig) {
    this.audioConfig = audioConfig;
    return this;
  }

  /**
   * Get audioConfig
   * @return audioConfig
   */
  @javax.annotation.Nullable
  public AudioConfig getAudioConfig() {
    return audioConfig;
  }

  public void setAudioConfig(AudioConfig audioConfig) {
    this.audioConfig = audioConfig;
  }


  public SynthesizeSpeechResponse audioContent(byte[] audioContent) {
    this.audioContent = audioContent;
    return this;
  }

  /**
   * The audio data bytes encoded as specified in the request, including the header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS). For LINEAR16 audio, we include the WAV header. Note: as with all bytes fields, protobuffers use a pure binary representation, whereas JSON representations use base64.
   * @return audioContent
   */
  @javax.annotation.Nullable
  public byte[] getAudioContent() {
    return audioContent;
  }

  public void setAudioContent(byte[] audioContent) {
    this.audioContent = audioContent;
  }


  public SynthesizeSpeechResponse timepoints(List<Timepoint> timepoints) {
    this.timepoints = timepoints;
    return this;
  }

  public SynthesizeSpeechResponse addTimepointsItem(Timepoint timepointsItem) {
    if (this.timepoints == null) {
      this.timepoints = new ArrayList<>();
    }
    this.timepoints.add(timepointsItem);
    return this;
  }

  /**
   * A link between a position in the original request input and a corresponding time in the output audio. It&#39;s only supported via &#x60;&#x60; of SSML input.
   * @return timepoints
   */
  @javax.annotation.Nullable
  public List<Timepoint> getTimepoints() {
    return timepoints;
  }

  public void setTimepoints(List<Timepoint> timepoints) {
    this.timepoints = timepoints;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SynthesizeSpeechResponse synthesizeSpeechResponse = (SynthesizeSpeechResponse) o;
    return Objects.equals(this.audioConfig, synthesizeSpeechResponse.audioConfig) &&
        Arrays.equals(this.audioContent, synthesizeSpeechResponse.audioContent) &&
        Objects.equals(this.timepoints, synthesizeSpeechResponse.timepoints);
  }

  @Override
  public int hashCode() {
    return Objects.hash(audioConfig, Arrays.hashCode(audioContent), timepoints);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SynthesizeSpeechResponse {\n");
    sb.append("    audioConfig: ").append(toIndentedString(audioConfig)).append("\n");
    sb.append("    audioContent: ").append(toIndentedString(audioContent)).append("\n");
    sb.append("    timepoints: ").append(toIndentedString(timepoints)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("audioConfig");
    openapiFields.add("audioContent");
    openapiFields.add("timepoints");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to SynthesizeSpeechResponse
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!SynthesizeSpeechResponse.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in SynthesizeSpeechResponse is not found in the empty JSON string", SynthesizeSpeechResponse.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!SynthesizeSpeechResponse.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `SynthesizeSpeechResponse` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // validate the optional field `audioConfig`
      if (jsonObj.get("audioConfig") != null && !jsonObj.get("audioConfig").isJsonNull()) {
        AudioConfig.validateJsonElement(jsonObj.get("audioConfig"));
      }
      if (jsonObj.get("timepoints") != null && !jsonObj.get("timepoints").isJsonNull()) {
        JsonArray jsonArraytimepoints = jsonObj.getAsJsonArray("timepoints");
        if (jsonArraytimepoints != null) {
          // ensure the json data is an array
          if (!jsonObj.get("timepoints").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `timepoints` to be an array in the JSON string but got `%s`", jsonObj.get("timepoints").toString()));
          }

          // validate the optional field `timepoints` (array)
          for (int i = 0; i < jsonArraytimepoints.size(); i++) {
            Timepoint.validateJsonElement(jsonArraytimepoints.get(i));
          };
        }
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!SynthesizeSpeechResponse.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'SynthesizeSpeechResponse' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<SynthesizeSpeechResponse> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(SynthesizeSpeechResponse.class));

       return (TypeAdapter<T>) new TypeAdapter<SynthesizeSpeechResponse>() {
           @Override
           public void write(JsonWriter out, SynthesizeSpeechResponse value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public SynthesizeSpeechResponse read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of SynthesizeSpeechResponse given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of SynthesizeSpeechResponse
   * @throws IOException if the JSON string is invalid with respect to SynthesizeSpeechResponse
   */
  public static SynthesizeSpeechResponse fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, SynthesizeSpeechResponse.class);
  }

  /**
   * Convert an instance of SynthesizeSpeechResponse to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

