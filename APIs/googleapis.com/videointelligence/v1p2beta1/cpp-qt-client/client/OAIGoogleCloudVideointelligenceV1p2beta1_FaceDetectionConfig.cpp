/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1p2beta1
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig() {
    this->initializeModel();
}

OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::~OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig() {}

void OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::initializeModel() {

    m_include_attributes_isSet = false;
    m_include_attributes_isValid = false;

    m_include_bounding_boxes_isSet = false;
    m_include_bounding_boxes_isValid = false;

    m_model_isSet = false;
    m_model_isValid = false;
}

void OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::fromJsonObject(QJsonObject json) {

    m_include_attributes_isValid = ::OpenAPI::fromJsonValue(m_include_attributes, json[QString("includeAttributes")]);
    m_include_attributes_isSet = !json[QString("includeAttributes")].isNull() && m_include_attributes_isValid;

    m_include_bounding_boxes_isValid = ::OpenAPI::fromJsonValue(m_include_bounding_boxes, json[QString("includeBoundingBoxes")]);
    m_include_bounding_boxes_isSet = !json[QString("includeBoundingBoxes")].isNull() && m_include_bounding_boxes_isValid;

    m_model_isValid = ::OpenAPI::fromJsonValue(m_model, json[QString("model")]);
    m_model_isSet = !json[QString("model")].isNull() && m_model_isValid;
}

QString OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::asJsonObject() const {
    QJsonObject obj;
    if (m_include_attributes_isSet) {
        obj.insert(QString("includeAttributes"), ::OpenAPI::toJsonValue(m_include_attributes));
    }
    if (m_include_bounding_boxes_isSet) {
        obj.insert(QString("includeBoundingBoxes"), ::OpenAPI::toJsonValue(m_include_bounding_boxes));
    }
    if (m_model_isSet) {
        obj.insert(QString("model"), ::OpenAPI::toJsonValue(m_model));
    }
    return obj;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::isIncludeAttributes() const {
    return m_include_attributes;
}
void OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::setIncludeAttributes(const bool &include_attributes) {
    m_include_attributes = include_attributes;
    m_include_attributes_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::is_include_attributes_Set() const{
    return m_include_attributes_isSet;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::is_include_attributes_Valid() const{
    return m_include_attributes_isValid;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::isIncludeBoundingBoxes() const {
    return m_include_bounding_boxes;
}
void OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::setIncludeBoundingBoxes(const bool &include_bounding_boxes) {
    m_include_bounding_boxes = include_bounding_boxes;
    m_include_bounding_boxes_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::is_include_bounding_boxes_Set() const{
    return m_include_bounding_boxes_isSet;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::is_include_bounding_boxes_Valid() const{
    return m_include_bounding_boxes_isValid;
}

QString OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::getModel() const {
    return m_model;
}
void OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::setModel(const QString &model) {
    m_model = model;
    m_model_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::is_model_Set() const{
    return m_model_isSet;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::is_model_Valid() const{
    return m_model_isValid;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_include_attributes_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_include_bounding_boxes_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_model_isSet) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAIGoogleCloudVideointelligenceV1p2beta1_FaceDetectionConfig::isValid() const {
    // only required properties are required for the object to be considered valid
    return true;
}

} // namespace OpenAPI
