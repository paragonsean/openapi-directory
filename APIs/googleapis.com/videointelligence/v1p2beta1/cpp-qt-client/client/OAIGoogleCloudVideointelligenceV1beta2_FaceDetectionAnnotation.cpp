/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1p2beta1
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation() {
    this->initializeModel();
}

OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::~OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation() {}

void OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::initializeModel() {

    m_thumbnail_isSet = false;
    m_thumbnail_isValid = false;

    m_tracks_isSet = false;
    m_tracks_isValid = false;

    m_version_isSet = false;
    m_version_isValid = false;
}

void OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::fromJsonObject(QJsonObject json) {

    m_thumbnail_isValid = ::OpenAPI::fromJsonValue(m_thumbnail, json[QString("thumbnail")]);
    m_thumbnail_isSet = !json[QString("thumbnail")].isNull() && m_thumbnail_isValid;

    m_tracks_isValid = ::OpenAPI::fromJsonValue(m_tracks, json[QString("tracks")]);
    m_tracks_isSet = !json[QString("tracks")].isNull() && m_tracks_isValid;

    m_version_isValid = ::OpenAPI::fromJsonValue(m_version, json[QString("version")]);
    m_version_isSet = !json[QString("version")].isNull() && m_version_isValid;
}

QString OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::asJsonObject() const {
    QJsonObject obj;
    if (m_thumbnail_isSet) {
        obj.insert(QString("thumbnail"), ::OpenAPI::toJsonValue(m_thumbnail));
    }
    if (m_tracks.size() > 0) {
        obj.insert(QString("tracks"), ::OpenAPI::toJsonValue(m_tracks));
    }
    if (m_version_isSet) {
        obj.insert(QString("version"), ::OpenAPI::toJsonValue(m_version));
    }
    return obj;
}

QByteArray OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::getThumbnail() const {
    return m_thumbnail;
}
void OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::setThumbnail(const QByteArray &thumbnail) {
    m_thumbnail = thumbnail;
    m_thumbnail_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::is_thumbnail_Set() const{
    return m_thumbnail_isSet;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::is_thumbnail_Valid() const{
    return m_thumbnail_isValid;
}

QList<OAIGoogleCloudVideointelligenceV1beta2_Track> OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::getTracks() const {
    return m_tracks;
}
void OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::setTracks(const QList<OAIGoogleCloudVideointelligenceV1beta2_Track> &tracks) {
    m_tracks = tracks;
    m_tracks_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::is_tracks_Set() const{
    return m_tracks_isSet;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::is_tracks_Valid() const{
    return m_tracks_isValid;
}

QString OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::getVersion() const {
    return m_version;
}
void OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::setVersion(const QString &version) {
    m_version = version;
    m_version_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::is_version_Set() const{
    return m_version_isSet;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::is_version_Valid() const{
    return m_version_isValid;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_thumbnail_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_tracks.size() > 0) {
            isObjectUpdated = true;
            break;
        }

        if (m_version_isSet) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAIGoogleCloudVideointelligenceV1beta2_FaceDetectionAnnotation::isValid() const {
    // only required properties are required for the object to be considered valid
    return true;
}

} // namespace OpenAPI
