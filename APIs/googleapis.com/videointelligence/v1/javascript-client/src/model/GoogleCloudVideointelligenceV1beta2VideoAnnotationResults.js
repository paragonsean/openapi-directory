/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation from './GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation';
import GoogleCloudVideointelligenceV1beta2FaceAnnotation from './GoogleCloudVideointelligenceV1beta2FaceAnnotation';
import GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation from './GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation';
import GoogleCloudVideointelligenceV1beta2LabelAnnotation from './GoogleCloudVideointelligenceV1beta2LabelAnnotation';
import GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation from './GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation';
import GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation from './GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation';
import GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation from './GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation';
import GoogleCloudVideointelligenceV1beta2SpeechTranscription from './GoogleCloudVideointelligenceV1beta2SpeechTranscription';
import GoogleCloudVideointelligenceV1beta2TextAnnotation from './GoogleCloudVideointelligenceV1beta2TextAnnotation';
import GoogleCloudVideointelligenceV1beta2VideoSegment from './GoogleCloudVideointelligenceV1beta2VideoSegment';
import GoogleRpcStatus from './GoogleRpcStatus';

/**
 * The GoogleCloudVideointelligenceV1beta2VideoAnnotationResults model module.
 * @module model/GoogleCloudVideointelligenceV1beta2VideoAnnotationResults
 * @version v1
 */
class GoogleCloudVideointelligenceV1beta2VideoAnnotationResults {
    /**
     * Constructs a new <code>GoogleCloudVideointelligenceV1beta2VideoAnnotationResults</code>.
     * Annotation results for a single video.
     * @alias module:model/GoogleCloudVideointelligenceV1beta2VideoAnnotationResults
     */
    constructor() { 
        
        GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>GoogleCloudVideointelligenceV1beta2VideoAnnotationResults</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/GoogleCloudVideointelligenceV1beta2VideoAnnotationResults} obj Optional instance to populate.
     * @return {module:model/GoogleCloudVideointelligenceV1beta2VideoAnnotationResults} The populated <code>GoogleCloudVideointelligenceV1beta2VideoAnnotationResults</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new GoogleCloudVideointelligenceV1beta2VideoAnnotationResults();

            if (data.hasOwnProperty('error')) {
                obj['error'] = GoogleRpcStatus.constructFromObject(data['error']);
            }
            if (data.hasOwnProperty('explicitAnnotation')) {
                obj['explicitAnnotation'] = GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation.constructFromObject(data['explicitAnnotation']);
            }
            if (data.hasOwnProperty('faceAnnotations')) {
                obj['faceAnnotations'] = ApiClient.convertToType(data['faceAnnotations'], [GoogleCloudVideointelligenceV1beta2FaceAnnotation]);
            }
            if (data.hasOwnProperty('faceDetectionAnnotations')) {
                obj['faceDetectionAnnotations'] = ApiClient.convertToType(data['faceDetectionAnnotations'], [GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation]);
            }
            if (data.hasOwnProperty('frameLabelAnnotations')) {
                obj['frameLabelAnnotations'] = ApiClient.convertToType(data['frameLabelAnnotations'], [GoogleCloudVideointelligenceV1beta2LabelAnnotation]);
            }
            if (data.hasOwnProperty('inputUri')) {
                obj['inputUri'] = ApiClient.convertToType(data['inputUri'], 'String');
            }
            if (data.hasOwnProperty('logoRecognitionAnnotations')) {
                obj['logoRecognitionAnnotations'] = ApiClient.convertToType(data['logoRecognitionAnnotations'], [GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation]);
            }
            if (data.hasOwnProperty('objectAnnotations')) {
                obj['objectAnnotations'] = ApiClient.convertToType(data['objectAnnotations'], [GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation]);
            }
            if (data.hasOwnProperty('personDetectionAnnotations')) {
                obj['personDetectionAnnotations'] = ApiClient.convertToType(data['personDetectionAnnotations'], [GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation]);
            }
            if (data.hasOwnProperty('segment')) {
                obj['segment'] = GoogleCloudVideointelligenceV1beta2VideoSegment.constructFromObject(data['segment']);
            }
            if (data.hasOwnProperty('segmentLabelAnnotations')) {
                obj['segmentLabelAnnotations'] = ApiClient.convertToType(data['segmentLabelAnnotations'], [GoogleCloudVideointelligenceV1beta2LabelAnnotation]);
            }
            if (data.hasOwnProperty('segmentPresenceLabelAnnotations')) {
                obj['segmentPresenceLabelAnnotations'] = ApiClient.convertToType(data['segmentPresenceLabelAnnotations'], [GoogleCloudVideointelligenceV1beta2LabelAnnotation]);
            }
            if (data.hasOwnProperty('shotAnnotations')) {
                obj['shotAnnotations'] = ApiClient.convertToType(data['shotAnnotations'], [GoogleCloudVideointelligenceV1beta2VideoSegment]);
            }
            if (data.hasOwnProperty('shotLabelAnnotations')) {
                obj['shotLabelAnnotations'] = ApiClient.convertToType(data['shotLabelAnnotations'], [GoogleCloudVideointelligenceV1beta2LabelAnnotation]);
            }
            if (data.hasOwnProperty('shotPresenceLabelAnnotations')) {
                obj['shotPresenceLabelAnnotations'] = ApiClient.convertToType(data['shotPresenceLabelAnnotations'], [GoogleCloudVideointelligenceV1beta2LabelAnnotation]);
            }
            if (data.hasOwnProperty('speechTranscriptions')) {
                obj['speechTranscriptions'] = ApiClient.convertToType(data['speechTranscriptions'], [GoogleCloudVideointelligenceV1beta2SpeechTranscription]);
            }
            if (data.hasOwnProperty('textAnnotations')) {
                obj['textAnnotations'] = ApiClient.convertToType(data['textAnnotations'], [GoogleCloudVideointelligenceV1beta2TextAnnotation]);
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>GoogleCloudVideointelligenceV1beta2VideoAnnotationResults</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>GoogleCloudVideointelligenceV1beta2VideoAnnotationResults</code>.
     */
    static validateJSON(data) {
        // validate the optional field `error`
        if (data['error']) { // data not null
          GoogleRpcStatus.validateJSON(data['error']);
        }
        // validate the optional field `explicitAnnotation`
        if (data['explicitAnnotation']) { // data not null
          GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation.validateJSON(data['explicitAnnotation']);
        }
        if (data['faceAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['faceAnnotations'])) {
                throw new Error("Expected the field `faceAnnotations` to be an array in the JSON data but got " + data['faceAnnotations']);
            }
            // validate the optional field `faceAnnotations` (array)
            for (const item of data['faceAnnotations']) {
                GoogleCloudVideointelligenceV1beta2FaceAnnotation.validateJSON(item);
            };
        }
        if (data['faceDetectionAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['faceDetectionAnnotations'])) {
                throw new Error("Expected the field `faceDetectionAnnotations` to be an array in the JSON data but got " + data['faceDetectionAnnotations']);
            }
            // validate the optional field `faceDetectionAnnotations` (array)
            for (const item of data['faceDetectionAnnotations']) {
                GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation.validateJSON(item);
            };
        }
        if (data['frameLabelAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['frameLabelAnnotations'])) {
                throw new Error("Expected the field `frameLabelAnnotations` to be an array in the JSON data but got " + data['frameLabelAnnotations']);
            }
            // validate the optional field `frameLabelAnnotations` (array)
            for (const item of data['frameLabelAnnotations']) {
                GoogleCloudVideointelligenceV1beta2LabelAnnotation.validateJSON(item);
            };
        }
        // ensure the json data is a string
        if (data['inputUri'] && !(typeof data['inputUri'] === 'string' || data['inputUri'] instanceof String)) {
            throw new Error("Expected the field `inputUri` to be a primitive type in the JSON string but got " + data['inputUri']);
        }
        if (data['logoRecognitionAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['logoRecognitionAnnotations'])) {
                throw new Error("Expected the field `logoRecognitionAnnotations` to be an array in the JSON data but got " + data['logoRecognitionAnnotations']);
            }
            // validate the optional field `logoRecognitionAnnotations` (array)
            for (const item of data['logoRecognitionAnnotations']) {
                GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation.validateJSON(item);
            };
        }
        if (data['objectAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['objectAnnotations'])) {
                throw new Error("Expected the field `objectAnnotations` to be an array in the JSON data but got " + data['objectAnnotations']);
            }
            // validate the optional field `objectAnnotations` (array)
            for (const item of data['objectAnnotations']) {
                GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation.validateJSON(item);
            };
        }
        if (data['personDetectionAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['personDetectionAnnotations'])) {
                throw new Error("Expected the field `personDetectionAnnotations` to be an array in the JSON data but got " + data['personDetectionAnnotations']);
            }
            // validate the optional field `personDetectionAnnotations` (array)
            for (const item of data['personDetectionAnnotations']) {
                GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation.validateJSON(item);
            };
        }
        // validate the optional field `segment`
        if (data['segment']) { // data not null
          GoogleCloudVideointelligenceV1beta2VideoSegment.validateJSON(data['segment']);
        }
        if (data['segmentLabelAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['segmentLabelAnnotations'])) {
                throw new Error("Expected the field `segmentLabelAnnotations` to be an array in the JSON data but got " + data['segmentLabelAnnotations']);
            }
            // validate the optional field `segmentLabelAnnotations` (array)
            for (const item of data['segmentLabelAnnotations']) {
                GoogleCloudVideointelligenceV1beta2LabelAnnotation.validateJSON(item);
            };
        }
        if (data['segmentPresenceLabelAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['segmentPresenceLabelAnnotations'])) {
                throw new Error("Expected the field `segmentPresenceLabelAnnotations` to be an array in the JSON data but got " + data['segmentPresenceLabelAnnotations']);
            }
            // validate the optional field `segmentPresenceLabelAnnotations` (array)
            for (const item of data['segmentPresenceLabelAnnotations']) {
                GoogleCloudVideointelligenceV1beta2LabelAnnotation.validateJSON(item);
            };
        }
        if (data['shotAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['shotAnnotations'])) {
                throw new Error("Expected the field `shotAnnotations` to be an array in the JSON data but got " + data['shotAnnotations']);
            }
            // validate the optional field `shotAnnotations` (array)
            for (const item of data['shotAnnotations']) {
                GoogleCloudVideointelligenceV1beta2VideoSegment.validateJSON(item);
            };
        }
        if (data['shotLabelAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['shotLabelAnnotations'])) {
                throw new Error("Expected the field `shotLabelAnnotations` to be an array in the JSON data but got " + data['shotLabelAnnotations']);
            }
            // validate the optional field `shotLabelAnnotations` (array)
            for (const item of data['shotLabelAnnotations']) {
                GoogleCloudVideointelligenceV1beta2LabelAnnotation.validateJSON(item);
            };
        }
        if (data['shotPresenceLabelAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['shotPresenceLabelAnnotations'])) {
                throw new Error("Expected the field `shotPresenceLabelAnnotations` to be an array in the JSON data but got " + data['shotPresenceLabelAnnotations']);
            }
            // validate the optional field `shotPresenceLabelAnnotations` (array)
            for (const item of data['shotPresenceLabelAnnotations']) {
                GoogleCloudVideointelligenceV1beta2LabelAnnotation.validateJSON(item);
            };
        }
        if (data['speechTranscriptions']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['speechTranscriptions'])) {
                throw new Error("Expected the field `speechTranscriptions` to be an array in the JSON data but got " + data['speechTranscriptions']);
            }
            // validate the optional field `speechTranscriptions` (array)
            for (const item of data['speechTranscriptions']) {
                GoogleCloudVideointelligenceV1beta2SpeechTranscription.validateJSON(item);
            };
        }
        if (data['textAnnotations']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['textAnnotations'])) {
                throw new Error("Expected the field `textAnnotations` to be an array in the JSON data but got " + data['textAnnotations']);
            }
            // validate the optional field `textAnnotations` (array)
            for (const item of data['textAnnotations']) {
                GoogleCloudVideointelligenceV1beta2TextAnnotation.validateJSON(item);
            };
        }

        return true;
    }


}



/**
 * @member {module:model/GoogleRpcStatus} error
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['error'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1beta2ExplicitContentAnnotation} explicitAnnotation
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['explicitAnnotation'] = undefined;

/**
 * Deprecated. Please use `face_detection_annotations` instead.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2FaceAnnotation>} faceAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['faceAnnotations'] = undefined;

/**
 * Face detection annotations.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2FaceDetectionAnnotation>} faceDetectionAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['faceDetectionAnnotations'] = undefined;

/**
 * Label annotations on frame level. There is exactly one element for each unique label.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2LabelAnnotation>} frameLabelAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['frameLabelAnnotations'] = undefined;

/**
 * Video file location in [Cloud Storage](https://cloud.google.com/storage/).
 * @member {String} inputUri
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['inputUri'] = undefined;

/**
 * Annotations for list of logos detected, tracked and recognized in video.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2LogoRecognitionAnnotation>} logoRecognitionAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['logoRecognitionAnnotations'] = undefined;

/**
 * Annotations for list of objects detected and tracked in video.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2ObjectTrackingAnnotation>} objectAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['objectAnnotations'] = undefined;

/**
 * Person detection annotations.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2PersonDetectionAnnotation>} personDetectionAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['personDetectionAnnotations'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1beta2VideoSegment} segment
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['segment'] = undefined;

/**
 * Topical label annotations on video level or user-specified segment level. There is exactly one element for each unique label.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2LabelAnnotation>} segmentLabelAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['segmentLabelAnnotations'] = undefined;

/**
 * Presence label annotations on video level or user-specified segment level. There is exactly one element for each unique label. Compared to the existing topical `segment_label_annotations`, this field presents more fine-grained, segment-level labels detected in video content and is made available only when the client sets `LabelDetectionConfig.model` to \"builtin/latest\" in the request.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2LabelAnnotation>} segmentPresenceLabelAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['segmentPresenceLabelAnnotations'] = undefined;

/**
 * Shot annotations. Each shot is represented as a video segment.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2VideoSegment>} shotAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['shotAnnotations'] = undefined;

/**
 * Topical label annotations on shot level. There is exactly one element for each unique label.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2LabelAnnotation>} shotLabelAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['shotLabelAnnotations'] = undefined;

/**
 * Presence label annotations on shot level. There is exactly one element for each unique label. Compared to the existing topical `shot_label_annotations`, this field presents more fine-grained, shot-level labels detected in video content and is made available only when the client sets `LabelDetectionConfig.model` to \"builtin/latest\" in the request.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2LabelAnnotation>} shotPresenceLabelAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['shotPresenceLabelAnnotations'] = undefined;

/**
 * Speech transcription.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2SpeechTranscription>} speechTranscriptions
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['speechTranscriptions'] = undefined;

/**
 * OCR text detection and tracking. Annotations for list of detected text snippets. Each will have list of frame information associated with it.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1beta2TextAnnotation>} textAnnotations
 */
GoogleCloudVideointelligenceV1beta2VideoAnnotationResults.prototype['textAnnotations'] = undefined;






export default GoogleCloudVideointelligenceV1beta2VideoAnnotationResults;

