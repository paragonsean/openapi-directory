/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig from './GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig';
import GoogleCloudVideointelligenceV1FaceDetectionConfig from './GoogleCloudVideointelligenceV1FaceDetectionConfig';
import GoogleCloudVideointelligenceV1LabelDetectionConfig from './GoogleCloudVideointelligenceV1LabelDetectionConfig';
import GoogleCloudVideointelligenceV1ObjectTrackingConfig from './GoogleCloudVideointelligenceV1ObjectTrackingConfig';
import GoogleCloudVideointelligenceV1PersonDetectionConfig from './GoogleCloudVideointelligenceV1PersonDetectionConfig';
import GoogleCloudVideointelligenceV1ShotChangeDetectionConfig from './GoogleCloudVideointelligenceV1ShotChangeDetectionConfig';
import GoogleCloudVideointelligenceV1SpeechTranscriptionConfig from './GoogleCloudVideointelligenceV1SpeechTranscriptionConfig';
import GoogleCloudVideointelligenceV1TextDetectionConfig from './GoogleCloudVideointelligenceV1TextDetectionConfig';
import GoogleCloudVideointelligenceV1VideoSegment from './GoogleCloudVideointelligenceV1VideoSegment';

/**
 * The GoogleCloudVideointelligenceV1VideoContext model module.
 * @module model/GoogleCloudVideointelligenceV1VideoContext
 * @version v1
 */
class GoogleCloudVideointelligenceV1VideoContext {
    /**
     * Constructs a new <code>GoogleCloudVideointelligenceV1VideoContext</code>.
     * Video context and/or feature-specific parameters.
     * @alias module:model/GoogleCloudVideointelligenceV1VideoContext
     */
    constructor() { 
        
        GoogleCloudVideointelligenceV1VideoContext.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>GoogleCloudVideointelligenceV1VideoContext</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/GoogleCloudVideointelligenceV1VideoContext} obj Optional instance to populate.
     * @return {module:model/GoogleCloudVideointelligenceV1VideoContext} The populated <code>GoogleCloudVideointelligenceV1VideoContext</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new GoogleCloudVideointelligenceV1VideoContext();

            if (data.hasOwnProperty('explicitContentDetectionConfig')) {
                obj['explicitContentDetectionConfig'] = GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig.constructFromObject(data['explicitContentDetectionConfig']);
            }
            if (data.hasOwnProperty('faceDetectionConfig')) {
                obj['faceDetectionConfig'] = GoogleCloudVideointelligenceV1FaceDetectionConfig.constructFromObject(data['faceDetectionConfig']);
            }
            if (data.hasOwnProperty('labelDetectionConfig')) {
                obj['labelDetectionConfig'] = GoogleCloudVideointelligenceV1LabelDetectionConfig.constructFromObject(data['labelDetectionConfig']);
            }
            if (data.hasOwnProperty('objectTrackingConfig')) {
                obj['objectTrackingConfig'] = GoogleCloudVideointelligenceV1ObjectTrackingConfig.constructFromObject(data['objectTrackingConfig']);
            }
            if (data.hasOwnProperty('personDetectionConfig')) {
                obj['personDetectionConfig'] = GoogleCloudVideointelligenceV1PersonDetectionConfig.constructFromObject(data['personDetectionConfig']);
            }
            if (data.hasOwnProperty('segments')) {
                obj['segments'] = ApiClient.convertToType(data['segments'], [GoogleCloudVideointelligenceV1VideoSegment]);
            }
            if (data.hasOwnProperty('shotChangeDetectionConfig')) {
                obj['shotChangeDetectionConfig'] = GoogleCloudVideointelligenceV1ShotChangeDetectionConfig.constructFromObject(data['shotChangeDetectionConfig']);
            }
            if (data.hasOwnProperty('speechTranscriptionConfig')) {
                obj['speechTranscriptionConfig'] = GoogleCloudVideointelligenceV1SpeechTranscriptionConfig.constructFromObject(data['speechTranscriptionConfig']);
            }
            if (data.hasOwnProperty('textDetectionConfig')) {
                obj['textDetectionConfig'] = GoogleCloudVideointelligenceV1TextDetectionConfig.constructFromObject(data['textDetectionConfig']);
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>GoogleCloudVideointelligenceV1VideoContext</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>GoogleCloudVideointelligenceV1VideoContext</code>.
     */
    static validateJSON(data) {
        // validate the optional field `explicitContentDetectionConfig`
        if (data['explicitContentDetectionConfig']) { // data not null
          GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig.validateJSON(data['explicitContentDetectionConfig']);
        }
        // validate the optional field `faceDetectionConfig`
        if (data['faceDetectionConfig']) { // data not null
          GoogleCloudVideointelligenceV1FaceDetectionConfig.validateJSON(data['faceDetectionConfig']);
        }
        // validate the optional field `labelDetectionConfig`
        if (data['labelDetectionConfig']) { // data not null
          GoogleCloudVideointelligenceV1LabelDetectionConfig.validateJSON(data['labelDetectionConfig']);
        }
        // validate the optional field `objectTrackingConfig`
        if (data['objectTrackingConfig']) { // data not null
          GoogleCloudVideointelligenceV1ObjectTrackingConfig.validateJSON(data['objectTrackingConfig']);
        }
        // validate the optional field `personDetectionConfig`
        if (data['personDetectionConfig']) { // data not null
          GoogleCloudVideointelligenceV1PersonDetectionConfig.validateJSON(data['personDetectionConfig']);
        }
        if (data['segments']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['segments'])) {
                throw new Error("Expected the field `segments` to be an array in the JSON data but got " + data['segments']);
            }
            // validate the optional field `segments` (array)
            for (const item of data['segments']) {
                GoogleCloudVideointelligenceV1VideoSegment.validateJSON(item);
            };
        }
        // validate the optional field `shotChangeDetectionConfig`
        if (data['shotChangeDetectionConfig']) { // data not null
          GoogleCloudVideointelligenceV1ShotChangeDetectionConfig.validateJSON(data['shotChangeDetectionConfig']);
        }
        // validate the optional field `speechTranscriptionConfig`
        if (data['speechTranscriptionConfig']) { // data not null
          GoogleCloudVideointelligenceV1SpeechTranscriptionConfig.validateJSON(data['speechTranscriptionConfig']);
        }
        // validate the optional field `textDetectionConfig`
        if (data['textDetectionConfig']) { // data not null
          GoogleCloudVideointelligenceV1TextDetectionConfig.validateJSON(data['textDetectionConfig']);
        }

        return true;
    }


}



/**
 * @member {module:model/GoogleCloudVideointelligenceV1ExplicitContentDetectionConfig} explicitContentDetectionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['explicitContentDetectionConfig'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1FaceDetectionConfig} faceDetectionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['faceDetectionConfig'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1LabelDetectionConfig} labelDetectionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['labelDetectionConfig'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1ObjectTrackingConfig} objectTrackingConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['objectTrackingConfig'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1PersonDetectionConfig} personDetectionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['personDetectionConfig'] = undefined;

/**
 * Video segments to annotate. The segments may overlap and are not required to be contiguous or span the whole video. If unspecified, each video is treated as a single segment.
 * @member {Array.<module:model/GoogleCloudVideointelligenceV1VideoSegment>} segments
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['segments'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1ShotChangeDetectionConfig} shotChangeDetectionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['shotChangeDetectionConfig'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1SpeechTranscriptionConfig} speechTranscriptionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['speechTranscriptionConfig'] = undefined;

/**
 * @member {module:model/GoogleCloudVideointelligenceV1TextDetectionConfig} textDetectionConfig
 */
GoogleCloudVideointelligenceV1VideoContext.prototype['textDetectionConfig'] = undefined;






export default GoogleCloudVideointelligenceV1VideoContext;

