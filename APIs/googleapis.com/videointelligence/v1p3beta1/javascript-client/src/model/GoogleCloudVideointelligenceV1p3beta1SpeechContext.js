/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1p3beta1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';

/**
 * The GoogleCloudVideointelligenceV1p3beta1SpeechContext model module.
 * @module model/GoogleCloudVideointelligenceV1p3beta1SpeechContext
 * @version v1p3beta1
 */
class GoogleCloudVideointelligenceV1p3beta1SpeechContext {
    /**
     * Constructs a new <code>GoogleCloudVideointelligenceV1p3beta1SpeechContext</code>.
     * Provides \&quot;hints\&quot; to the speech recognizer to favor specific words and phrases in the results.
     * @alias module:model/GoogleCloudVideointelligenceV1p3beta1SpeechContext
     */
    constructor() { 
        
        GoogleCloudVideointelligenceV1p3beta1SpeechContext.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>GoogleCloudVideointelligenceV1p3beta1SpeechContext</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/GoogleCloudVideointelligenceV1p3beta1SpeechContext} obj Optional instance to populate.
     * @return {module:model/GoogleCloudVideointelligenceV1p3beta1SpeechContext} The populated <code>GoogleCloudVideointelligenceV1p3beta1SpeechContext</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new GoogleCloudVideointelligenceV1p3beta1SpeechContext();

            if (data.hasOwnProperty('phrases')) {
                obj['phrases'] = ApiClient.convertToType(data['phrases'], ['String']);
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>GoogleCloudVideointelligenceV1p3beta1SpeechContext</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>GoogleCloudVideointelligenceV1p3beta1SpeechContext</code>.
     */
    static validateJSON(data) {
        // ensure the json data is an array
        if (!Array.isArray(data['phrases'])) {
            throw new Error("Expected the field `phrases` to be an array in the JSON data but got " + data['phrases']);
        }

        return true;
    }


}



/**
 * Optional. A list of strings containing words and phrases \"hints\" so that the speech recognition is more likely to recognize them. This can be used to improve the accuracy for specific words and phrases, for example, if specific commands are typically spoken by the user. This can also be used to add additional words to the vocabulary of the recognizer. See [usage limits](https://cloud.google.com/speech/limits#content).
 * @member {Array.<String>} phrases
 */
GoogleCloudVideointelligenceV1p3beta1SpeechContext.prototype['phrases'] = undefined;






export default GoogleCloudVideointelligenceV1p3beta1SpeechContext;

