/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1p3beta1
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly() {
    this->initializeModel();
}

OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::~OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly() {}

void OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::initializeModel() {

    m_vertices_isSet = false;
    m_vertices_isValid = false;
}

void OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::fromJsonObject(QJsonObject json) {

    m_vertices_isValid = ::OpenAPI::fromJsonValue(m_vertices, json[QString("vertices")]);
    m_vertices_isSet = !json[QString("vertices")].isNull() && m_vertices_isValid;
}

QString OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::asJsonObject() const {
    QJsonObject obj;
    if (m_vertices.size() > 0) {
        obj.insert(QString("vertices"), ::OpenAPI::toJsonValue(m_vertices));
    }
    return obj;
}

QList<OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedVertex> OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::getVertices() const {
    return m_vertices;
}
void OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::setVertices(const QList<OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedVertex> &vertices) {
    m_vertices = vertices;
    m_vertices_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::is_vertices_Set() const{
    return m_vertices_isSet;
}

bool OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::is_vertices_Valid() const{
    return m_vertices_isValid;
}

bool OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_vertices.size() > 0) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAIGoogleCloudVideointelligenceV1p3beta1_NormalizedBoundingPoly::isValid() const {
    // only required properties are required for the object to be considered valid
    return true;
}

} // namespace OpenAPI
