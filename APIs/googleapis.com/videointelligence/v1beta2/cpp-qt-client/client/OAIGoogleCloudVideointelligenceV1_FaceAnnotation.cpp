/**
 * Cloud Video Intelligence API
 * Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.
 *
 * The version of the OpenAPI document: v1beta2
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAIGoogleCloudVideointelligenceV1_FaceAnnotation.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAIGoogleCloudVideointelligenceV1_FaceAnnotation::OAIGoogleCloudVideointelligenceV1_FaceAnnotation(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAIGoogleCloudVideointelligenceV1_FaceAnnotation::OAIGoogleCloudVideointelligenceV1_FaceAnnotation() {
    this->initializeModel();
}

OAIGoogleCloudVideointelligenceV1_FaceAnnotation::~OAIGoogleCloudVideointelligenceV1_FaceAnnotation() {}

void OAIGoogleCloudVideointelligenceV1_FaceAnnotation::initializeModel() {

    m_frames_isSet = false;
    m_frames_isValid = false;

    m_segments_isSet = false;
    m_segments_isValid = false;

    m_thumbnail_isSet = false;
    m_thumbnail_isValid = false;
}

void OAIGoogleCloudVideointelligenceV1_FaceAnnotation::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAIGoogleCloudVideointelligenceV1_FaceAnnotation::fromJsonObject(QJsonObject json) {

    m_frames_isValid = ::OpenAPI::fromJsonValue(m_frames, json[QString("frames")]);
    m_frames_isSet = !json[QString("frames")].isNull() && m_frames_isValid;

    m_segments_isValid = ::OpenAPI::fromJsonValue(m_segments, json[QString("segments")]);
    m_segments_isSet = !json[QString("segments")].isNull() && m_segments_isValid;

    m_thumbnail_isValid = ::OpenAPI::fromJsonValue(m_thumbnail, json[QString("thumbnail")]);
    m_thumbnail_isSet = !json[QString("thumbnail")].isNull() && m_thumbnail_isValid;
}

QString OAIGoogleCloudVideointelligenceV1_FaceAnnotation::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAIGoogleCloudVideointelligenceV1_FaceAnnotation::asJsonObject() const {
    QJsonObject obj;
    if (m_frames.size() > 0) {
        obj.insert(QString("frames"), ::OpenAPI::toJsonValue(m_frames));
    }
    if (m_segments.size() > 0) {
        obj.insert(QString("segments"), ::OpenAPI::toJsonValue(m_segments));
    }
    if (m_thumbnail_isSet) {
        obj.insert(QString("thumbnail"), ::OpenAPI::toJsonValue(m_thumbnail));
    }
    return obj;
}

QList<OAIGoogleCloudVideointelligenceV1_FaceFrame> OAIGoogleCloudVideointelligenceV1_FaceAnnotation::getFrames() const {
    return m_frames;
}
void OAIGoogleCloudVideointelligenceV1_FaceAnnotation::setFrames(const QList<OAIGoogleCloudVideointelligenceV1_FaceFrame> &frames) {
    m_frames = frames;
    m_frames_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::is_frames_Set() const{
    return m_frames_isSet;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::is_frames_Valid() const{
    return m_frames_isValid;
}

QList<OAIGoogleCloudVideointelligenceV1_FaceSegment> OAIGoogleCloudVideointelligenceV1_FaceAnnotation::getSegments() const {
    return m_segments;
}
void OAIGoogleCloudVideointelligenceV1_FaceAnnotation::setSegments(const QList<OAIGoogleCloudVideointelligenceV1_FaceSegment> &segments) {
    m_segments = segments;
    m_segments_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::is_segments_Set() const{
    return m_segments_isSet;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::is_segments_Valid() const{
    return m_segments_isValid;
}

QByteArray OAIGoogleCloudVideointelligenceV1_FaceAnnotation::getThumbnail() const {
    return m_thumbnail;
}
void OAIGoogleCloudVideointelligenceV1_FaceAnnotation::setThumbnail(const QByteArray &thumbnail) {
    m_thumbnail = thumbnail;
    m_thumbnail_isSet = true;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::is_thumbnail_Set() const{
    return m_thumbnail_isSet;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::is_thumbnail_Valid() const{
    return m_thumbnail_isValid;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_frames.size() > 0) {
            isObjectUpdated = true;
            break;
        }

        if (m_segments.size() > 0) {
            isObjectUpdated = true;
            break;
        }

        if (m_thumbnail_isSet) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAIGoogleCloudVideointelligenceV1_FaceAnnotation::isValid() const {
    // only required properties are required for the object to be considered valid
    return true;
}

} // namespace OpenAPI
