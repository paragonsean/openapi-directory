# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server.models.clustering import Clustering
from openapi_server.models.connection_property import ConnectionProperty
from openapi_server.models.dataset_reference import DatasetReference
from openapi_server.models.encryption_configuration import EncryptionConfiguration
from openapi_server.models.external_data_configuration import ExternalDataConfiguration
from openapi_server.models.query_parameter import QueryParameter
from openapi_server.models.range_partitioning import RangePartitioning
from openapi_server.models.script_options import ScriptOptions
from openapi_server.models.system_variables import SystemVariables
from openapi_server.models.table_reference import TableReference
from openapi_server.models.time_partitioning import TimePartitioning
from openapi_server.models.user_defined_function_resource import UserDefinedFunctionResource
from openapi_server import util


class JobConfigurationQuery(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, allow_large_results: bool=False, clustering: Clustering=None, connection_properties: List[ConnectionProperty]=None, continuous: bool=None, create_disposition: str=None, create_session: bool=None, default_dataset: DatasetReference=None, destination_encryption_configuration: EncryptionConfiguration=None, destination_table: TableReference=None, flatten_results: bool=True, maximum_billing_tier: int=1, maximum_bytes_billed: str=None, parameter_mode: str=None, preserve_nulls: bool=None, priority: str=None, query: str=None, query_parameters: List[QueryParameter]=None, range_partitioning: RangePartitioning=None, schema_update_options: List[str]=None, script_options: ScriptOptions=None, system_variables: SystemVariables=None, table_definitions: Dict[str, ExternalDataConfiguration]=None, time_partitioning: TimePartitioning=None, use_legacy_sql: bool=True, use_query_cache: bool=True, user_defined_function_resources: List[UserDefinedFunctionResource]=None, write_disposition: str=None):
        """JobConfigurationQuery - a model defined in OpenAPI

        :param allow_large_results: The allow_large_results of this JobConfigurationQuery.
        :param clustering: The clustering of this JobConfigurationQuery.
        :param connection_properties: The connection_properties of this JobConfigurationQuery.
        :param continuous: The continuous of this JobConfigurationQuery.
        :param create_disposition: The create_disposition of this JobConfigurationQuery.
        :param create_session: The create_session of this JobConfigurationQuery.
        :param default_dataset: The default_dataset of this JobConfigurationQuery.
        :param destination_encryption_configuration: The destination_encryption_configuration of this JobConfigurationQuery.
        :param destination_table: The destination_table of this JobConfigurationQuery.
        :param flatten_results: The flatten_results of this JobConfigurationQuery.
        :param maximum_billing_tier: The maximum_billing_tier of this JobConfigurationQuery.
        :param maximum_bytes_billed: The maximum_bytes_billed of this JobConfigurationQuery.
        :param parameter_mode: The parameter_mode of this JobConfigurationQuery.
        :param preserve_nulls: The preserve_nulls of this JobConfigurationQuery.
        :param priority: The priority of this JobConfigurationQuery.
        :param query: The query of this JobConfigurationQuery.
        :param query_parameters: The query_parameters of this JobConfigurationQuery.
        :param range_partitioning: The range_partitioning of this JobConfigurationQuery.
        :param schema_update_options: The schema_update_options of this JobConfigurationQuery.
        :param script_options: The script_options of this JobConfigurationQuery.
        :param system_variables: The system_variables of this JobConfigurationQuery.
        :param table_definitions: The table_definitions of this JobConfigurationQuery.
        :param time_partitioning: The time_partitioning of this JobConfigurationQuery.
        :param use_legacy_sql: The use_legacy_sql of this JobConfigurationQuery.
        :param use_query_cache: The use_query_cache of this JobConfigurationQuery.
        :param user_defined_function_resources: The user_defined_function_resources of this JobConfigurationQuery.
        :param write_disposition: The write_disposition of this JobConfigurationQuery.
        """
        self.openapi_types = {
            'allow_large_results': bool,
            'clustering': Clustering,
            'connection_properties': List[ConnectionProperty],
            'continuous': bool,
            'create_disposition': str,
            'create_session': bool,
            'default_dataset': DatasetReference,
            'destination_encryption_configuration': EncryptionConfiguration,
            'destination_table': TableReference,
            'flatten_results': bool,
            'maximum_billing_tier': int,
            'maximum_bytes_billed': str,
            'parameter_mode': str,
            'preserve_nulls': bool,
            'priority': str,
            'query': str,
            'query_parameters': List[QueryParameter],
            'range_partitioning': RangePartitioning,
            'schema_update_options': List[str],
            'script_options': ScriptOptions,
            'system_variables': SystemVariables,
            'table_definitions': Dict[str, ExternalDataConfiguration],
            'time_partitioning': TimePartitioning,
            'use_legacy_sql': bool,
            'use_query_cache': bool,
            'user_defined_function_resources': List[UserDefinedFunctionResource],
            'write_disposition': str
        }

        self.attribute_map = {
            'allow_large_results': 'allowLargeResults',
            'clustering': 'clustering',
            'connection_properties': 'connectionProperties',
            'continuous': 'continuous',
            'create_disposition': 'createDisposition',
            'create_session': 'createSession',
            'default_dataset': 'defaultDataset',
            'destination_encryption_configuration': 'destinationEncryptionConfiguration',
            'destination_table': 'destinationTable',
            'flatten_results': 'flattenResults',
            'maximum_billing_tier': 'maximumBillingTier',
            'maximum_bytes_billed': 'maximumBytesBilled',
            'parameter_mode': 'parameterMode',
            'preserve_nulls': 'preserveNulls',
            'priority': 'priority',
            'query': 'query',
            'query_parameters': 'queryParameters',
            'range_partitioning': 'rangePartitioning',
            'schema_update_options': 'schemaUpdateOptions',
            'script_options': 'scriptOptions',
            'system_variables': 'systemVariables',
            'table_definitions': 'tableDefinitions',
            'time_partitioning': 'timePartitioning',
            'use_legacy_sql': 'useLegacySql',
            'use_query_cache': 'useQueryCache',
            'user_defined_function_resources': 'userDefinedFunctionResources',
            'write_disposition': 'writeDisposition'
        }

        self._allow_large_results = allow_large_results
        self._clustering = clustering
        self._connection_properties = connection_properties
        self._continuous = continuous
        self._create_disposition = create_disposition
        self._create_session = create_session
        self._default_dataset = default_dataset
        self._destination_encryption_configuration = destination_encryption_configuration
        self._destination_table = destination_table
        self._flatten_results = flatten_results
        self._maximum_billing_tier = maximum_billing_tier
        self._maximum_bytes_billed = maximum_bytes_billed
        self._parameter_mode = parameter_mode
        self._preserve_nulls = preserve_nulls
        self._priority = priority
        self._query = query
        self._query_parameters = query_parameters
        self._range_partitioning = range_partitioning
        self._schema_update_options = schema_update_options
        self._script_options = script_options
        self._system_variables = system_variables
        self._table_definitions = table_definitions
        self._time_partitioning = time_partitioning
        self._use_legacy_sql = use_legacy_sql
        self._use_query_cache = use_query_cache
        self._user_defined_function_resources = user_defined_function_resources
        self._write_disposition = write_disposition

    @classmethod
    def from_dict(cls, dikt: dict) -> 'JobConfigurationQuery':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The JobConfigurationQuery of this JobConfigurationQuery.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def allow_large_results(self):
        """Gets the allow_large_results of this JobConfigurationQuery.

        Optional. If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance. Requires destinationTable to be set. For GoogleSQL queries, this flag is ignored and large results are always allowed. However, you must still set destinationTable when result size exceeds the allowed maximum response size.

        :return: The allow_large_results of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._allow_large_results

    @allow_large_results.setter
    def allow_large_results(self, allow_large_results):
        """Sets the allow_large_results of this JobConfigurationQuery.

        Optional. If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance. Requires destinationTable to be set. For GoogleSQL queries, this flag is ignored and large results are always allowed. However, you must still set destinationTable when result size exceeds the allowed maximum response size.

        :param allow_large_results: The allow_large_results of this JobConfigurationQuery.
        :type allow_large_results: bool
        """

        self._allow_large_results = allow_large_results

    @property
    def clustering(self):
        """Gets the clustering of this JobConfigurationQuery.


        :return: The clustering of this JobConfigurationQuery.
        :rtype: Clustering
        """
        return self._clustering

    @clustering.setter
    def clustering(self, clustering):
        """Sets the clustering of this JobConfigurationQuery.


        :param clustering: The clustering of this JobConfigurationQuery.
        :type clustering: Clustering
        """

        self._clustering = clustering

    @property
    def connection_properties(self):
        """Gets the connection_properties of this JobConfigurationQuery.

        Connection properties which can modify the query behavior.

        :return: The connection_properties of this JobConfigurationQuery.
        :rtype: List[ConnectionProperty]
        """
        return self._connection_properties

    @connection_properties.setter
    def connection_properties(self, connection_properties):
        """Sets the connection_properties of this JobConfigurationQuery.

        Connection properties which can modify the query behavior.

        :param connection_properties: The connection_properties of this JobConfigurationQuery.
        :type connection_properties: List[ConnectionProperty]
        """

        self._connection_properties = connection_properties

    @property
    def continuous(self):
        """Gets the continuous of this JobConfigurationQuery.

        [Optional] Specifies whether the query should be executed as a continuous query. The default value is false.

        :return: The continuous of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._continuous

    @continuous.setter
    def continuous(self, continuous):
        """Sets the continuous of this JobConfigurationQuery.

        [Optional] Specifies whether the query should be executed as a continuous query. The default value is false.

        :param continuous: The continuous of this JobConfigurationQuery.
        :type continuous: bool
        """

        self._continuous = continuous

    @property
    def create_disposition(self):
        """Gets the create_disposition of this JobConfigurationQuery.

        Optional. Specifies whether the job is allowed to create new tables. The following values are supported: * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table. * CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result. The default value is CREATE_IF_NEEDED. Creation, truncation and append actions occur as one atomic update upon job completion.

        :return: The create_disposition of this JobConfigurationQuery.
        :rtype: str
        """
        return self._create_disposition

    @create_disposition.setter
    def create_disposition(self, create_disposition):
        """Sets the create_disposition of this JobConfigurationQuery.

        Optional. Specifies whether the job is allowed to create new tables. The following values are supported: * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table. * CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result. The default value is CREATE_IF_NEEDED. Creation, truncation and append actions occur as one atomic update upon job completion.

        :param create_disposition: The create_disposition of this JobConfigurationQuery.
        :type create_disposition: str
        """

        self._create_disposition = create_disposition

    @property
    def create_session(self):
        """Gets the create_session of this JobConfigurationQuery.

        If this property is true, the job creates a new session using a randomly generated session_id. To continue using a created session with subsequent queries, pass the existing session identifier as a `ConnectionProperty` value. The session identifier is returned as part of the `SessionInfo` message within the query statistics. The new session's location will be set to `Job.JobReference.location` if it is present, otherwise it's set to the default location based on existing routing logic.

        :return: The create_session of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._create_session

    @create_session.setter
    def create_session(self, create_session):
        """Sets the create_session of this JobConfigurationQuery.

        If this property is true, the job creates a new session using a randomly generated session_id. To continue using a created session with subsequent queries, pass the existing session identifier as a `ConnectionProperty` value. The session identifier is returned as part of the `SessionInfo` message within the query statistics. The new session's location will be set to `Job.JobReference.location` if it is present, otherwise it's set to the default location based on existing routing logic.

        :param create_session: The create_session of this JobConfigurationQuery.
        :type create_session: bool
        """

        self._create_session = create_session

    @property
    def default_dataset(self):
        """Gets the default_dataset of this JobConfigurationQuery.


        :return: The default_dataset of this JobConfigurationQuery.
        :rtype: DatasetReference
        """
        return self._default_dataset

    @default_dataset.setter
    def default_dataset(self, default_dataset):
        """Sets the default_dataset of this JobConfigurationQuery.


        :param default_dataset: The default_dataset of this JobConfigurationQuery.
        :type default_dataset: DatasetReference
        """

        self._default_dataset = default_dataset

    @property
    def destination_encryption_configuration(self):
        """Gets the destination_encryption_configuration of this JobConfigurationQuery.


        :return: The destination_encryption_configuration of this JobConfigurationQuery.
        :rtype: EncryptionConfiguration
        """
        return self._destination_encryption_configuration

    @destination_encryption_configuration.setter
    def destination_encryption_configuration(self, destination_encryption_configuration):
        """Sets the destination_encryption_configuration of this JobConfigurationQuery.


        :param destination_encryption_configuration: The destination_encryption_configuration of this JobConfigurationQuery.
        :type destination_encryption_configuration: EncryptionConfiguration
        """

        self._destination_encryption_configuration = destination_encryption_configuration

    @property
    def destination_table(self):
        """Gets the destination_table of this JobConfigurationQuery.


        :return: The destination_table of this JobConfigurationQuery.
        :rtype: TableReference
        """
        return self._destination_table

    @destination_table.setter
    def destination_table(self, destination_table):
        """Sets the destination_table of this JobConfigurationQuery.


        :param destination_table: The destination_table of this JobConfigurationQuery.
        :type destination_table: TableReference
        """

        self._destination_table = destination_table

    @property
    def flatten_results(self):
        """Gets the flatten_results of this JobConfigurationQuery.

        Optional. If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results. allowLargeResults must be true if this is set to false. For GoogleSQL queries, this flag is ignored and results are never flattened.

        :return: The flatten_results of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._flatten_results

    @flatten_results.setter
    def flatten_results(self, flatten_results):
        """Sets the flatten_results of this JobConfigurationQuery.

        Optional. If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results. allowLargeResults must be true if this is set to false. For GoogleSQL queries, this flag is ignored and results are never flattened.

        :param flatten_results: The flatten_results of this JobConfigurationQuery.
        :type flatten_results: bool
        """

        self._flatten_results = flatten_results

    @property
    def maximum_billing_tier(self):
        """Gets the maximum_billing_tier of this JobConfigurationQuery.

        Optional. [Deprecated] Maximum billing tier allowed for this query. The billing tier controls the amount of compute resources allotted to the query, and multiplies the on-demand cost of the query accordingly. A query that runs within its allotted resources will succeed and indicate its billing tier in statistics.query.billingTier, but if the query exceeds its allotted resources, it will fail with billingTierLimitExceeded. WARNING: The billed byte amount can be multiplied by an amount up to this number! Most users should not need to alter this setting, and we recommend that you avoid introducing new uses of it.

        :return: The maximum_billing_tier of this JobConfigurationQuery.
        :rtype: int
        """
        return self._maximum_billing_tier

    @maximum_billing_tier.setter
    def maximum_billing_tier(self, maximum_billing_tier):
        """Sets the maximum_billing_tier of this JobConfigurationQuery.

        Optional. [Deprecated] Maximum billing tier allowed for this query. The billing tier controls the amount of compute resources allotted to the query, and multiplies the on-demand cost of the query accordingly. A query that runs within its allotted resources will succeed and indicate its billing tier in statistics.query.billingTier, but if the query exceeds its allotted resources, it will fail with billingTierLimitExceeded. WARNING: The billed byte amount can be multiplied by an amount up to this number! Most users should not need to alter this setting, and we recommend that you avoid introducing new uses of it.

        :param maximum_billing_tier: The maximum_billing_tier of this JobConfigurationQuery.
        :type maximum_billing_tier: int
        """

        self._maximum_billing_tier = maximum_billing_tier

    @property
    def maximum_bytes_billed(self):
        """Gets the maximum_bytes_billed of this JobConfigurationQuery.

        Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge). If unspecified, this will be set to your project default.

        :return: The maximum_bytes_billed of this JobConfigurationQuery.
        :rtype: str
        """
        return self._maximum_bytes_billed

    @maximum_bytes_billed.setter
    def maximum_bytes_billed(self, maximum_bytes_billed):
        """Sets the maximum_bytes_billed of this JobConfigurationQuery.

        Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge). If unspecified, this will be set to your project default.

        :param maximum_bytes_billed: The maximum_bytes_billed of this JobConfigurationQuery.
        :type maximum_bytes_billed: str
        """

        self._maximum_bytes_billed = maximum_bytes_billed

    @property
    def parameter_mode(self):
        """Gets the parameter_mode of this JobConfigurationQuery.

        GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.

        :return: The parameter_mode of this JobConfigurationQuery.
        :rtype: str
        """
        return self._parameter_mode

    @parameter_mode.setter
    def parameter_mode(self, parameter_mode):
        """Sets the parameter_mode of this JobConfigurationQuery.

        GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.

        :param parameter_mode: The parameter_mode of this JobConfigurationQuery.
        :type parameter_mode: str
        """

        self._parameter_mode = parameter_mode

    @property
    def preserve_nulls(self):
        """Gets the preserve_nulls of this JobConfigurationQuery.

        [Deprecated] This property is deprecated.

        :return: The preserve_nulls of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._preserve_nulls

    @preserve_nulls.setter
    def preserve_nulls(self, preserve_nulls):
        """Sets the preserve_nulls of this JobConfigurationQuery.

        [Deprecated] This property is deprecated.

        :param preserve_nulls: The preserve_nulls of this JobConfigurationQuery.
        :type preserve_nulls: bool
        """

        self._preserve_nulls = preserve_nulls

    @property
    def priority(self):
        """Gets the priority of this JobConfigurationQuery.

        Optional. Specifies a priority for the query. Possible values include INTERACTIVE and BATCH. The default value is INTERACTIVE.

        :return: The priority of this JobConfigurationQuery.
        :rtype: str
        """
        return self._priority

    @priority.setter
    def priority(self, priority):
        """Sets the priority of this JobConfigurationQuery.

        Optional. Specifies a priority for the query. Possible values include INTERACTIVE and BATCH. The default value is INTERACTIVE.

        :param priority: The priority of this JobConfigurationQuery.
        :type priority: str
        """

        self._priority = priority

    @property
    def query(self):
        """Gets the query of this JobConfigurationQuery.

        [Required] SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or GoogleSQL.

        :return: The query of this JobConfigurationQuery.
        :rtype: str
        """
        return self._query

    @query.setter
    def query(self, query):
        """Sets the query of this JobConfigurationQuery.

        [Required] SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or GoogleSQL.

        :param query: The query of this JobConfigurationQuery.
        :type query: str
        """

        self._query = query

    @property
    def query_parameters(self):
        """Gets the query_parameters of this JobConfigurationQuery.

        Query parameters for GoogleSQL queries.

        :return: The query_parameters of this JobConfigurationQuery.
        :rtype: List[QueryParameter]
        """
        return self._query_parameters

    @query_parameters.setter
    def query_parameters(self, query_parameters):
        """Sets the query_parameters of this JobConfigurationQuery.

        Query parameters for GoogleSQL queries.

        :param query_parameters: The query_parameters of this JobConfigurationQuery.
        :type query_parameters: List[QueryParameter]
        """

        self._query_parameters = query_parameters

    @property
    def range_partitioning(self):
        """Gets the range_partitioning of this JobConfigurationQuery.


        :return: The range_partitioning of this JobConfigurationQuery.
        :rtype: RangePartitioning
        """
        return self._range_partitioning

    @range_partitioning.setter
    def range_partitioning(self, range_partitioning):
        """Sets the range_partitioning of this JobConfigurationQuery.


        :param range_partitioning: The range_partitioning of this JobConfigurationQuery.
        :type range_partitioning: RangePartitioning
        """

        self._range_partitioning = range_partitioning

    @property
    def schema_update_options(self):
        """Gets the schema_update_options of this JobConfigurationQuery.

        Allows the schema of the destination table to be updated as a side effect of the query job. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified: * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema. * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.

        :return: The schema_update_options of this JobConfigurationQuery.
        :rtype: List[str]
        """
        return self._schema_update_options

    @schema_update_options.setter
    def schema_update_options(self, schema_update_options):
        """Sets the schema_update_options of this JobConfigurationQuery.

        Allows the schema of the destination table to be updated as a side effect of the query job. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified: * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema. * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.

        :param schema_update_options: The schema_update_options of this JobConfigurationQuery.
        :type schema_update_options: List[str]
        """

        self._schema_update_options = schema_update_options

    @property
    def script_options(self):
        """Gets the script_options of this JobConfigurationQuery.


        :return: The script_options of this JobConfigurationQuery.
        :rtype: ScriptOptions
        """
        return self._script_options

    @script_options.setter
    def script_options(self, script_options):
        """Sets the script_options of this JobConfigurationQuery.


        :param script_options: The script_options of this JobConfigurationQuery.
        :type script_options: ScriptOptions
        """

        self._script_options = script_options

    @property
    def system_variables(self):
        """Gets the system_variables of this JobConfigurationQuery.


        :return: The system_variables of this JobConfigurationQuery.
        :rtype: SystemVariables
        """
        return self._system_variables

    @system_variables.setter
    def system_variables(self, system_variables):
        """Sets the system_variables of this JobConfigurationQuery.


        :param system_variables: The system_variables of this JobConfigurationQuery.
        :type system_variables: SystemVariables
        """

        self._system_variables = system_variables

    @property
    def table_definitions(self):
        """Gets the table_definitions of this JobConfigurationQuery.

        Optional. You can specify external table definitions, which operate as ephemeral tables that can be queried. These definitions are configured using a JSON map, where the string key represents the table identifier, and the value is the corresponding external data configuration object.

        :return: The table_definitions of this JobConfigurationQuery.
        :rtype: Dict[str, ExternalDataConfiguration]
        """
        return self._table_definitions

    @table_definitions.setter
    def table_definitions(self, table_definitions):
        """Sets the table_definitions of this JobConfigurationQuery.

        Optional. You can specify external table definitions, which operate as ephemeral tables that can be queried. These definitions are configured using a JSON map, where the string key represents the table identifier, and the value is the corresponding external data configuration object.

        :param table_definitions: The table_definitions of this JobConfigurationQuery.
        :type table_definitions: Dict[str, ExternalDataConfiguration]
        """

        self._table_definitions = table_definitions

    @property
    def time_partitioning(self):
        """Gets the time_partitioning of this JobConfigurationQuery.


        :return: The time_partitioning of this JobConfigurationQuery.
        :rtype: TimePartitioning
        """
        return self._time_partitioning

    @time_partitioning.setter
    def time_partitioning(self, time_partitioning):
        """Sets the time_partitioning of this JobConfigurationQuery.


        :param time_partitioning: The time_partitioning of this JobConfigurationQuery.
        :type time_partitioning: TimePartitioning
        """

        self._time_partitioning = time_partitioning

    @property
    def use_legacy_sql(self):
        """Gets the use_legacy_sql of this JobConfigurationQuery.

        Optional. Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true. If set to false, the query will use BigQuery's GoogleSQL: https://cloud.google.com/bigquery/sql-reference/ When useLegacySql is set to false, the value of flattenResults is ignored; query will be run as if flattenResults is false.

        :return: The use_legacy_sql of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._use_legacy_sql

    @use_legacy_sql.setter
    def use_legacy_sql(self, use_legacy_sql):
        """Sets the use_legacy_sql of this JobConfigurationQuery.

        Optional. Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true. If set to false, the query will use BigQuery's GoogleSQL: https://cloud.google.com/bigquery/sql-reference/ When useLegacySql is set to false, the value of flattenResults is ignored; query will be run as if flattenResults is false.

        :param use_legacy_sql: The use_legacy_sql of this JobConfigurationQuery.
        :type use_legacy_sql: bool
        """

        self._use_legacy_sql = use_legacy_sql

    @property
    def use_query_cache(self):
        """Gets the use_query_cache of this JobConfigurationQuery.

        Optional. Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified. The default value is true.

        :return: The use_query_cache of this JobConfigurationQuery.
        :rtype: bool
        """
        return self._use_query_cache

    @use_query_cache.setter
    def use_query_cache(self, use_query_cache):
        """Sets the use_query_cache of this JobConfigurationQuery.

        Optional. Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified. The default value is true.

        :param use_query_cache: The use_query_cache of this JobConfigurationQuery.
        :type use_query_cache: bool
        """

        self._use_query_cache = use_query_cache

    @property
    def user_defined_function_resources(self):
        """Gets the user_defined_function_resources of this JobConfigurationQuery.

        Describes user-defined function resources used in the query.

        :return: The user_defined_function_resources of this JobConfigurationQuery.
        :rtype: List[UserDefinedFunctionResource]
        """
        return self._user_defined_function_resources

    @user_defined_function_resources.setter
    def user_defined_function_resources(self, user_defined_function_resources):
        """Sets the user_defined_function_resources of this JobConfigurationQuery.

        Describes user-defined function resources used in the query.

        :param user_defined_function_resources: The user_defined_function_resources of this JobConfigurationQuery.
        :type user_defined_function_resources: List[UserDefinedFunctionResource]
        """

        self._user_defined_function_resources = user_defined_function_resources

    @property
    def write_disposition(self):
        """Gets the write_disposition of this JobConfigurationQuery.

        Optional. Specifies the action that occurs if the destination table already exists. The following values are supported: * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the data, removes the constraints, and uses the schema from the query result. * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table. * WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result. The default value is WRITE_EMPTY. Each action is atomic and only occurs if BigQuery is able to complete the job successfully. Creation, truncation and append actions occur as one atomic update upon job completion.

        :return: The write_disposition of this JobConfigurationQuery.
        :rtype: str
        """
        return self._write_disposition

    @write_disposition.setter
    def write_disposition(self, write_disposition):
        """Sets the write_disposition of this JobConfigurationQuery.

        Optional. Specifies the action that occurs if the destination table already exists. The following values are supported: * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the data, removes the constraints, and uses the schema from the query result. * WRITE_APPEND: If the table already exists, BigQuery appends the data to the table. * WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result. The default value is WRITE_EMPTY. Each action is atomic and only occurs if BigQuery is able to complete the job successfully. Creation, truncation and append actions occur as one atomic update upon job completion.

        :param write_disposition: The write_disposition of this JobConfigurationQuery.
        :type write_disposition: str
        """

        self._write_disposition = write_disposition
