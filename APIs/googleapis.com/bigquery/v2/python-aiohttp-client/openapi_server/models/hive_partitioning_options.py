# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server import util


class HivePartitioningOptions(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, fields: List[str]=None, mode: str=None, require_partition_filter: bool=False, source_uri_prefix: str=None):
        """HivePartitioningOptions - a model defined in OpenAPI

        :param fields: The fields of this HivePartitioningOptions.
        :param mode: The mode of this HivePartitioningOptions.
        :param require_partition_filter: The require_partition_filter of this HivePartitioningOptions.
        :param source_uri_prefix: The source_uri_prefix of this HivePartitioningOptions.
        """
        self.openapi_types = {
            'fields': List[str],
            'mode': str,
            'require_partition_filter': bool,
            'source_uri_prefix': str
        }

        self.attribute_map = {
            'fields': 'fields',
            'mode': 'mode',
            'require_partition_filter': 'requirePartitionFilter',
            'source_uri_prefix': 'sourceUriPrefix'
        }

        self._fields = fields
        self._mode = mode
        self._require_partition_filter = require_partition_filter
        self._source_uri_prefix = source_uri_prefix

    @classmethod
    def from_dict(cls, dikt: dict) -> 'HivePartitioningOptions':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The HivePartitioningOptions of this HivePartitioningOptions.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def fields(self):
        """Gets the fields of this HivePartitioningOptions.

        Output only. For permanent external tables, this field is populated with the hive partition keys in the order they were inferred. The types of the partition keys can be deduced by checking the table schema (which will include the partition keys). Not every API will populate this field in the output. For example, Tables.Get will populate it, but Tables.List will not contain this field.

        :return: The fields of this HivePartitioningOptions.
        :rtype: List[str]
        """
        return self._fields

    @fields.setter
    def fields(self, fields):
        """Sets the fields of this HivePartitioningOptions.

        Output only. For permanent external tables, this field is populated with the hive partition keys in the order they were inferred. The types of the partition keys can be deduced by checking the table schema (which will include the partition keys). Not every API will populate this field in the output. For example, Tables.Get will populate it, but Tables.List will not contain this field.

        :param fields: The fields of this HivePartitioningOptions.
        :type fields: List[str]
        """

        self._fields = fields

    @property
    def mode(self):
        """Gets the mode of this HivePartitioningOptions.

        Optional. When set, what mode of hive partitioning to use when reading data. The following modes are supported: * AUTO: automatically infer partition key name(s) and type(s). * STRINGS: automatically infer partition key name(s). All types are strings. * CUSTOM: partition key schema is encoded in the source URI prefix. Not all storage formats support hive partitioning. Requesting hive partitioning on an unsupported format will lead to an error. Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.

        :return: The mode of this HivePartitioningOptions.
        :rtype: str
        """
        return self._mode

    @mode.setter
    def mode(self, mode):
        """Sets the mode of this HivePartitioningOptions.

        Optional. When set, what mode of hive partitioning to use when reading data. The following modes are supported: * AUTO: automatically infer partition key name(s) and type(s). * STRINGS: automatically infer partition key name(s). All types are strings. * CUSTOM: partition key schema is encoded in the source URI prefix. Not all storage formats support hive partitioning. Requesting hive partitioning on an unsupported format will lead to an error. Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.

        :param mode: The mode of this HivePartitioningOptions.
        :type mode: str
        """

        self._mode = mode

    @property
    def require_partition_filter(self):
        """Gets the require_partition_filter of this HivePartitioningOptions.

        Optional. If set to true, queries over this table require a partition filter that can be used for partition elimination to be specified. Note that this field should only be true when creating a permanent external table or querying a temporary external table. Hive-partitioned loads with require_partition_filter explicitly set to true will fail.

        :return: The require_partition_filter of this HivePartitioningOptions.
        :rtype: bool
        """
        return self._require_partition_filter

    @require_partition_filter.setter
    def require_partition_filter(self, require_partition_filter):
        """Sets the require_partition_filter of this HivePartitioningOptions.

        Optional. If set to true, queries over this table require a partition filter that can be used for partition elimination to be specified. Note that this field should only be true when creating a permanent external table or querying a temporary external table. Hive-partitioned loads with require_partition_filter explicitly set to true will fail.

        :param require_partition_filter: The require_partition_filter of this HivePartitioningOptions.
        :type require_partition_filter: bool
        """

        self._require_partition_filter = require_partition_filter

    @property
    def source_uri_prefix(self):
        """Gets the source_uri_prefix of this HivePartitioningOptions.

        Optional. When hive partition detection is requested, a common prefix for all source uris must be required. The prefix must end immediately before the partition key encoding begins. For example, consider files following this data layout: gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive partitioning is requested with either AUTO or STRINGS detection, the common prefix can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/. CUSTOM detection requires encoding the partitioning schema immediately after the common prefix. For CUSTOM, any of * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:INTEGER} * gs://bucket/path_to_table/{dt:STRING}/{country:STRING}/{id:INTEGER} * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:STRING} would all be valid source URI prefixes.

        :return: The source_uri_prefix of this HivePartitioningOptions.
        :rtype: str
        """
        return self._source_uri_prefix

    @source_uri_prefix.setter
    def source_uri_prefix(self, source_uri_prefix):
        """Sets the source_uri_prefix of this HivePartitioningOptions.

        Optional. When hive partition detection is requested, a common prefix for all source uris must be required. The prefix must end immediately before the partition key encoding begins. For example, consider files following this data layout: gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive partitioning is requested with either AUTO or STRINGS detection, the common prefix can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/. CUSTOM detection requires encoding the partitioning schema immediately after the common prefix. For CUSTOM, any of * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:INTEGER} * gs://bucket/path_to_table/{dt:STRING}/{country:STRING}/{id:INTEGER} * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:STRING} would all be valid source URI prefixes.

        :param source_uri_prefix: The source_uri_prefix of this HivePartitioningOptions.
        :type source_uri_prefix: str
        """

        self._source_uri_prefix = source_uri_prefix
