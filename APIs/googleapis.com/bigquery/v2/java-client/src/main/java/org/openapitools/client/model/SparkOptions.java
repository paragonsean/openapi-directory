/*
 * BigQuery API
 * A data platform for customers to create, manage, share and query data.
 *
 * The version of the OpenAPI document: v2
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * Options for a user-defined Spark routine.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:43:22.147192-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class SparkOptions {
  public static final String SERIALIZED_NAME_ARCHIVE_URIS = "archiveUris";
  @SerializedName(SERIALIZED_NAME_ARCHIVE_URIS)
  private List<String> archiveUris = new ArrayList<>();

  public static final String SERIALIZED_NAME_CONNECTION = "connection";
  @SerializedName(SERIALIZED_NAME_CONNECTION)
  private String connection;

  public static final String SERIALIZED_NAME_CONTAINER_IMAGE = "containerImage";
  @SerializedName(SERIALIZED_NAME_CONTAINER_IMAGE)
  private String containerImage;

  public static final String SERIALIZED_NAME_FILE_URIS = "fileUris";
  @SerializedName(SERIALIZED_NAME_FILE_URIS)
  private List<String> fileUris = new ArrayList<>();

  public static final String SERIALIZED_NAME_JAR_URIS = "jarUris";
  @SerializedName(SERIALIZED_NAME_JAR_URIS)
  private List<String> jarUris = new ArrayList<>();

  public static final String SERIALIZED_NAME_MAIN_CLASS = "mainClass";
  @SerializedName(SERIALIZED_NAME_MAIN_CLASS)
  private String mainClass;

  public static final String SERIALIZED_NAME_MAIN_FILE_URI = "mainFileUri";
  @SerializedName(SERIALIZED_NAME_MAIN_FILE_URI)
  private String mainFileUri;

  public static final String SERIALIZED_NAME_PROPERTIES = "properties";
  @SerializedName(SERIALIZED_NAME_PROPERTIES)
  private Map<String, String> properties = new HashMap<>();

  public static final String SERIALIZED_NAME_PY_FILE_URIS = "pyFileUris";
  @SerializedName(SERIALIZED_NAME_PY_FILE_URIS)
  private List<String> pyFileUris = new ArrayList<>();

  public static final String SERIALIZED_NAME_RUNTIME_VERSION = "runtimeVersion";
  @SerializedName(SERIALIZED_NAME_RUNTIME_VERSION)
  private String runtimeVersion;

  public SparkOptions() {
  }

  public SparkOptions archiveUris(List<String> archiveUris) {
    this.archiveUris = archiveUris;
    return this;
  }

  public SparkOptions addArchiveUrisItem(String archiveUrisItem) {
    if (this.archiveUris == null) {
      this.archiveUris = new ArrayList<>();
    }
    this.archiveUris.add(archiveUrisItem);
    return this;
  }

  /**
   * Archive files to be extracted into the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
   * @return archiveUris
   */
  @javax.annotation.Nullable
  public List<String> getArchiveUris() {
    return archiveUris;
  }

  public void setArchiveUris(List<String> archiveUris) {
    this.archiveUris = archiveUris;
  }


  public SparkOptions connection(String connection) {
    this.connection = connection;
    return this;
  }

  /**
   * Fully qualified name of the user-provided Spark connection object. Format: &#x60;&#x60;&#x60;\&quot;projects/{project_id}/locations/{location_id}/connections/{connection_id}\&quot;&#x60;&#x60;&#x60;
   * @return connection
   */
  @javax.annotation.Nullable
  public String getConnection() {
    return connection;
  }

  public void setConnection(String connection) {
    this.connection = connection;
  }


  public SparkOptions containerImage(String containerImage) {
    this.containerImage = containerImage;
    return this;
  }

  /**
   * Custom container image for the runtime environment.
   * @return containerImage
   */
  @javax.annotation.Nullable
  public String getContainerImage() {
    return containerImage;
  }

  public void setContainerImage(String containerImage) {
    this.containerImage = containerImage;
  }


  public SparkOptions fileUris(List<String> fileUris) {
    this.fileUris = fileUris;
    return this;
  }

  public SparkOptions addFileUrisItem(String fileUrisItem) {
    if (this.fileUris == null) {
      this.fileUris = new ArrayList<>();
    }
    this.fileUris.add(fileUrisItem);
    return this;
  }

  /**
   * Files to be placed in the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
   * @return fileUris
   */
  @javax.annotation.Nullable
  public List<String> getFileUris() {
    return fileUris;
  }

  public void setFileUris(List<String> fileUris) {
    this.fileUris = fileUris;
  }


  public SparkOptions jarUris(List<String> jarUris) {
    this.jarUris = jarUris;
    return this;
  }

  public SparkOptions addJarUrisItem(String jarUrisItem) {
    if (this.jarUris == null) {
      this.jarUris = new ArrayList<>();
    }
    this.jarUris.add(jarUrisItem);
    return this;
  }

  /**
   * JARs to include on the driver and executor CLASSPATH. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
   * @return jarUris
   */
  @javax.annotation.Nullable
  public List<String> getJarUris() {
    return jarUris;
  }

  public void setJarUris(List<String> jarUris) {
    this.jarUris = jarUris;
  }


  public SparkOptions mainClass(String mainClass) {
    this.mainClass = mainClass;
    return this;
  }

  /**
   * The fully qualified name of a class in jar_uris, for example, com.example.wordcount. Exactly one of main_class and main_jar_uri field should be set for Java/Scala language type.
   * @return mainClass
   */
  @javax.annotation.Nullable
  public String getMainClass() {
    return mainClass;
  }

  public void setMainClass(String mainClass) {
    this.mainClass = mainClass;
  }


  public SparkOptions mainFileUri(String mainFileUri) {
    this.mainFileUri = mainFileUri;
    return this;
  }

  /**
   * The main file/jar URI of the Spark application. Exactly one of the definition_body field and the main_file_uri field must be set for Python. Exactly one of main_class and main_file_uri field should be set for Java/Scala language type.
   * @return mainFileUri
   */
  @javax.annotation.Nullable
  public String getMainFileUri() {
    return mainFileUri;
  }

  public void setMainFileUri(String mainFileUri) {
    this.mainFileUri = mainFileUri;
  }


  public SparkOptions properties(Map<String, String> properties) {
    this.properties = properties;
    return this;
  }

  public SparkOptions putPropertiesItem(String key, String propertiesItem) {
    if (this.properties == null) {
      this.properties = new HashMap<>();
    }
    this.properties.put(key, propertiesItem);
    return this;
  }

  /**
   * Configuration properties as a set of key/value pairs, which will be passed on to the Spark application. For more information, see [Apache Spark](https://spark.apache.org/docs/latest/index.html) and the [procedure option list](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#procedure_option_list).
   * @return properties
   */
  @javax.annotation.Nullable
  public Map<String, String> getProperties() {
    return properties;
  }

  public void setProperties(Map<String, String> properties) {
    this.properties = properties;
  }


  public SparkOptions pyFileUris(List<String> pyFileUris) {
    this.pyFileUris = pyFileUris;
    return this;
  }

  public SparkOptions addPyFileUrisItem(String pyFileUrisItem) {
    if (this.pyFileUris == null) {
      this.pyFileUris = new ArrayList<>();
    }
    this.pyFileUris.add(pyFileUrisItem);
    return this;
  }

  /**
   * Python files to be placed on the PYTHONPATH for PySpark application. Supported file types: &#x60;.py&#x60;, &#x60;.egg&#x60;, and &#x60;.zip&#x60;. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
   * @return pyFileUris
   */
  @javax.annotation.Nullable
  public List<String> getPyFileUris() {
    return pyFileUris;
  }

  public void setPyFileUris(List<String> pyFileUris) {
    this.pyFileUris = pyFileUris;
  }


  public SparkOptions runtimeVersion(String runtimeVersion) {
    this.runtimeVersion = runtimeVersion;
    return this;
  }

  /**
   * Runtime version. If not specified, the default runtime version is used.
   * @return runtimeVersion
   */
  @javax.annotation.Nullable
  public String getRuntimeVersion() {
    return runtimeVersion;
  }

  public void setRuntimeVersion(String runtimeVersion) {
    this.runtimeVersion = runtimeVersion;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SparkOptions sparkOptions = (SparkOptions) o;
    return Objects.equals(this.archiveUris, sparkOptions.archiveUris) &&
        Objects.equals(this.connection, sparkOptions.connection) &&
        Objects.equals(this.containerImage, sparkOptions.containerImage) &&
        Objects.equals(this.fileUris, sparkOptions.fileUris) &&
        Objects.equals(this.jarUris, sparkOptions.jarUris) &&
        Objects.equals(this.mainClass, sparkOptions.mainClass) &&
        Objects.equals(this.mainFileUri, sparkOptions.mainFileUri) &&
        Objects.equals(this.properties, sparkOptions.properties) &&
        Objects.equals(this.pyFileUris, sparkOptions.pyFileUris) &&
        Objects.equals(this.runtimeVersion, sparkOptions.runtimeVersion);
  }

  @Override
  public int hashCode() {
    return Objects.hash(archiveUris, connection, containerImage, fileUris, jarUris, mainClass, mainFileUri, properties, pyFileUris, runtimeVersion);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SparkOptions {\n");
    sb.append("    archiveUris: ").append(toIndentedString(archiveUris)).append("\n");
    sb.append("    connection: ").append(toIndentedString(connection)).append("\n");
    sb.append("    containerImage: ").append(toIndentedString(containerImage)).append("\n");
    sb.append("    fileUris: ").append(toIndentedString(fileUris)).append("\n");
    sb.append("    jarUris: ").append(toIndentedString(jarUris)).append("\n");
    sb.append("    mainClass: ").append(toIndentedString(mainClass)).append("\n");
    sb.append("    mainFileUri: ").append(toIndentedString(mainFileUri)).append("\n");
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("    pyFileUris: ").append(toIndentedString(pyFileUris)).append("\n");
    sb.append("    runtimeVersion: ").append(toIndentedString(runtimeVersion)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("archiveUris");
    openapiFields.add("connection");
    openapiFields.add("containerImage");
    openapiFields.add("fileUris");
    openapiFields.add("jarUris");
    openapiFields.add("mainClass");
    openapiFields.add("mainFileUri");
    openapiFields.add("properties");
    openapiFields.add("pyFileUris");
    openapiFields.add("runtimeVersion");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to SparkOptions
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!SparkOptions.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in SparkOptions is not found in the empty JSON string", SparkOptions.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!SparkOptions.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `SparkOptions` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // ensure the optional json data is an array if present
      if (jsonObj.get("archiveUris") != null && !jsonObj.get("archiveUris").isJsonNull() && !jsonObj.get("archiveUris").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `archiveUris` to be an array in the JSON string but got `%s`", jsonObj.get("archiveUris").toString()));
      }
      if ((jsonObj.get("connection") != null && !jsonObj.get("connection").isJsonNull()) && !jsonObj.get("connection").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `connection` to be a primitive type in the JSON string but got `%s`", jsonObj.get("connection").toString()));
      }
      if ((jsonObj.get("containerImage") != null && !jsonObj.get("containerImage").isJsonNull()) && !jsonObj.get("containerImage").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `containerImage` to be a primitive type in the JSON string but got `%s`", jsonObj.get("containerImage").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("fileUris") != null && !jsonObj.get("fileUris").isJsonNull() && !jsonObj.get("fileUris").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `fileUris` to be an array in the JSON string but got `%s`", jsonObj.get("fileUris").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("jarUris") != null && !jsonObj.get("jarUris").isJsonNull() && !jsonObj.get("jarUris").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `jarUris` to be an array in the JSON string but got `%s`", jsonObj.get("jarUris").toString()));
      }
      if ((jsonObj.get("mainClass") != null && !jsonObj.get("mainClass").isJsonNull()) && !jsonObj.get("mainClass").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `mainClass` to be a primitive type in the JSON string but got `%s`", jsonObj.get("mainClass").toString()));
      }
      if ((jsonObj.get("mainFileUri") != null && !jsonObj.get("mainFileUri").isJsonNull()) && !jsonObj.get("mainFileUri").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `mainFileUri` to be a primitive type in the JSON string but got `%s`", jsonObj.get("mainFileUri").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("pyFileUris") != null && !jsonObj.get("pyFileUris").isJsonNull() && !jsonObj.get("pyFileUris").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `pyFileUris` to be an array in the JSON string but got `%s`", jsonObj.get("pyFileUris").toString()));
      }
      if ((jsonObj.get("runtimeVersion") != null && !jsonObj.get("runtimeVersion").isJsonNull()) && !jsonObj.get("runtimeVersion").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `runtimeVersion` to be a primitive type in the JSON string but got `%s`", jsonObj.get("runtimeVersion").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!SparkOptions.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'SparkOptions' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<SparkOptions> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(SparkOptions.class));

       return (TypeAdapter<T>) new TypeAdapter<SparkOptions>() {
           @Override
           public void write(JsonWriter out, SparkOptions value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public SparkOptions read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of SparkOptions given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of SparkOptions
   * @throws IOException if the JSON string is invalid with respect to SparkOptions
   */
  public static SparkOptions fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, SparkOptions.class);
  }

  /**
   * Convert an instance of SparkOptions to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

