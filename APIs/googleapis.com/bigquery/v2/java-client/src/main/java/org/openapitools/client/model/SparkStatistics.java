/*
 * BigQuery API
 * A data platform for customers to create, manage, share and query data.
 *
 * The version of the OpenAPI document: v2
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;
import org.openapitools.client.model.SparkLoggingInfo;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * Statistics for a BigSpark query. Populated as part of JobStatistics2
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:43:22.147192-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class SparkStatistics {
  public static final String SERIALIZED_NAME_ENDPOINTS = "endpoints";
  @SerializedName(SERIALIZED_NAME_ENDPOINTS)
  private Map<String, String> endpoints = new HashMap<>();

  public static final String SERIALIZED_NAME_GCS_STAGING_BUCKET = "gcsStagingBucket";
  @SerializedName(SERIALIZED_NAME_GCS_STAGING_BUCKET)
  private String gcsStagingBucket;

  public static final String SERIALIZED_NAME_KMS_KEY_NAME = "kmsKeyName";
  @SerializedName(SERIALIZED_NAME_KMS_KEY_NAME)
  private String kmsKeyName;

  public static final String SERIALIZED_NAME_LOGGING_INFO = "loggingInfo";
  @SerializedName(SERIALIZED_NAME_LOGGING_INFO)
  private SparkLoggingInfo loggingInfo;

  public static final String SERIALIZED_NAME_SPARK_JOB_ID = "sparkJobId";
  @SerializedName(SERIALIZED_NAME_SPARK_JOB_ID)
  private String sparkJobId;

  public static final String SERIALIZED_NAME_SPARK_JOB_LOCATION = "sparkJobLocation";
  @SerializedName(SERIALIZED_NAME_SPARK_JOB_LOCATION)
  private String sparkJobLocation;

  public SparkStatistics() {
  }

  public SparkStatistics(
     Map<String, String> endpoints, 
     String gcsStagingBucket, 
     String kmsKeyName, 
     String sparkJobId, 
     String sparkJobLocation
  ) {
    this();
    this.endpoints = endpoints;
    this.gcsStagingBucket = gcsStagingBucket;
    this.kmsKeyName = kmsKeyName;
    this.sparkJobId = sparkJobId;
    this.sparkJobLocation = sparkJobLocation;
  }

  /**
   * Output only. Endpoints returned from Dataproc. Key list: - history_server_endpoint: A link to Spark job UI.
   * @return endpoints
   */
  @javax.annotation.Nullable
  public Map<String, String> getEndpoints() {
    return endpoints;
  }



  /**
   * Output only. The Google Cloud Storage bucket that is used as the default filesystem by the Spark application. This fields is only filled when the Spark procedure uses the INVOKER security mode. It is inferred from the system variable @@spark_proc_properties.staging_bucket if it is provided. Otherwise, BigQuery creates a default staging bucket for the job and returns the bucket name in this field. Example: * &#x60;gs://[bucket_name]&#x60;
   * @return gcsStagingBucket
   */
  @javax.annotation.Nullable
  public String getGcsStagingBucket() {
    return gcsStagingBucket;
  }



  /**
   * Output only. The Cloud KMS encryption key that is used to protect the resources created by the Spark job. If the Spark procedure uses DEFINER security mode, the Cloud KMS key is inferred from the Spark connection associated with the procedure if it is provided. Otherwise the key is inferred from the default key of the Spark connection&#39;s project if the CMEK organization policy is enforced. If the Spark procedure uses INVOKER security mode, the Cloud KMS encryption key is inferred from the system variable @@spark_proc_properties.kms_key_name if it is provided. Otherwise, the key is inferred fromt he default key of the BigQuery job&#39;s project if the CMEK organization policy is enforced. Example: * &#x60;projects/[kms_project_id]/locations/[region]/keyRings/[key_region]/cryptoKeys/[key]&#x60;
   * @return kmsKeyName
   */
  @javax.annotation.Nullable
  public String getKmsKeyName() {
    return kmsKeyName;
  }



  public SparkStatistics loggingInfo(SparkLoggingInfo loggingInfo) {
    this.loggingInfo = loggingInfo;
    return this;
  }

  /**
   * Get loggingInfo
   * @return loggingInfo
   */
  @javax.annotation.Nullable
  public SparkLoggingInfo getLoggingInfo() {
    return loggingInfo;
  }

  public void setLoggingInfo(SparkLoggingInfo loggingInfo) {
    this.loggingInfo = loggingInfo;
  }


  /**
   * Output only. Spark job ID if a Spark job is created successfully.
   * @return sparkJobId
   */
  @javax.annotation.Nullable
  public String getSparkJobId() {
    return sparkJobId;
  }



  /**
   * Output only. Location where the Spark job is executed. A location is selected by BigQueury for jobs configured to run in a multi-region.
   * @return sparkJobLocation
   */
  @javax.annotation.Nullable
  public String getSparkJobLocation() {
    return sparkJobLocation;
  }




  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SparkStatistics sparkStatistics = (SparkStatistics) o;
    return Objects.equals(this.endpoints, sparkStatistics.endpoints) &&
        Objects.equals(this.gcsStagingBucket, sparkStatistics.gcsStagingBucket) &&
        Objects.equals(this.kmsKeyName, sparkStatistics.kmsKeyName) &&
        Objects.equals(this.loggingInfo, sparkStatistics.loggingInfo) &&
        Objects.equals(this.sparkJobId, sparkStatistics.sparkJobId) &&
        Objects.equals(this.sparkJobLocation, sparkStatistics.sparkJobLocation);
  }

  @Override
  public int hashCode() {
    return Objects.hash(endpoints, gcsStagingBucket, kmsKeyName, loggingInfo, sparkJobId, sparkJobLocation);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SparkStatistics {\n");
    sb.append("    endpoints: ").append(toIndentedString(endpoints)).append("\n");
    sb.append("    gcsStagingBucket: ").append(toIndentedString(gcsStagingBucket)).append("\n");
    sb.append("    kmsKeyName: ").append(toIndentedString(kmsKeyName)).append("\n");
    sb.append("    loggingInfo: ").append(toIndentedString(loggingInfo)).append("\n");
    sb.append("    sparkJobId: ").append(toIndentedString(sparkJobId)).append("\n");
    sb.append("    sparkJobLocation: ").append(toIndentedString(sparkJobLocation)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("endpoints");
    openapiFields.add("gcsStagingBucket");
    openapiFields.add("kmsKeyName");
    openapiFields.add("loggingInfo");
    openapiFields.add("sparkJobId");
    openapiFields.add("sparkJobLocation");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to SparkStatistics
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!SparkStatistics.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in SparkStatistics is not found in the empty JSON string", SparkStatistics.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!SparkStatistics.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `SparkStatistics` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      if ((jsonObj.get("gcsStagingBucket") != null && !jsonObj.get("gcsStagingBucket").isJsonNull()) && !jsonObj.get("gcsStagingBucket").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `gcsStagingBucket` to be a primitive type in the JSON string but got `%s`", jsonObj.get("gcsStagingBucket").toString()));
      }
      if ((jsonObj.get("kmsKeyName") != null && !jsonObj.get("kmsKeyName").isJsonNull()) && !jsonObj.get("kmsKeyName").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `kmsKeyName` to be a primitive type in the JSON string but got `%s`", jsonObj.get("kmsKeyName").toString()));
      }
      // validate the optional field `loggingInfo`
      if (jsonObj.get("loggingInfo") != null && !jsonObj.get("loggingInfo").isJsonNull()) {
        SparkLoggingInfo.validateJsonElement(jsonObj.get("loggingInfo"));
      }
      if ((jsonObj.get("sparkJobId") != null && !jsonObj.get("sparkJobId").isJsonNull()) && !jsonObj.get("sparkJobId").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `sparkJobId` to be a primitive type in the JSON string but got `%s`", jsonObj.get("sparkJobId").toString()));
      }
      if ((jsonObj.get("sparkJobLocation") != null && !jsonObj.get("sparkJobLocation").isJsonNull()) && !jsonObj.get("sparkJobLocation").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `sparkJobLocation` to be a primitive type in the JSON string but got `%s`", jsonObj.get("sparkJobLocation").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!SparkStatistics.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'SparkStatistics' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<SparkStatistics> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(SparkStatistics.class));

       return (TypeAdapter<T>) new TypeAdapter<SparkStatistics>() {
           @Override
           public void write(JsonWriter out, SparkStatistics value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public SparkStatistics read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of SparkStatistics given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of SparkStatistics
   * @throws IOException if the JSON string is invalid with respect to SparkStatistics
   */
  public static SparkStatistics fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, SparkStatistics.class);
  }

  /**
   * Convert an instance of SparkStatistics to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

