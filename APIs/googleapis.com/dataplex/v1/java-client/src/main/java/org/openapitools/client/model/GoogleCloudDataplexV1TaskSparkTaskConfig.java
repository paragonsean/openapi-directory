/*
 * Cloud Dataplex API
 * Dataplex API is used to manage the lifecycle of data lakes.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.openapitools.client.model.GoogleCloudDataplexV1TaskInfrastructureSpec;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * User-specified config for running a Spark task.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:46:09.858800-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class GoogleCloudDataplexV1TaskSparkTaskConfig {
  public static final String SERIALIZED_NAME_ARCHIVE_URIS = "archiveUris";
  @SerializedName(SERIALIZED_NAME_ARCHIVE_URIS)
  private List<String> archiveUris = new ArrayList<>();

  public static final String SERIALIZED_NAME_FILE_URIS = "fileUris";
  @SerializedName(SERIALIZED_NAME_FILE_URIS)
  private List<String> fileUris = new ArrayList<>();

  public static final String SERIALIZED_NAME_INFRASTRUCTURE_SPEC = "infrastructureSpec";
  @SerializedName(SERIALIZED_NAME_INFRASTRUCTURE_SPEC)
  private GoogleCloudDataplexV1TaskInfrastructureSpec infrastructureSpec;

  public static final String SERIALIZED_NAME_MAIN_CLASS = "mainClass";
  @SerializedName(SERIALIZED_NAME_MAIN_CLASS)
  private String mainClass;

  public static final String SERIALIZED_NAME_MAIN_JAR_FILE_URI = "mainJarFileUri";
  @SerializedName(SERIALIZED_NAME_MAIN_JAR_FILE_URI)
  private String mainJarFileUri;

  public static final String SERIALIZED_NAME_PYTHON_SCRIPT_FILE = "pythonScriptFile";
  @SerializedName(SERIALIZED_NAME_PYTHON_SCRIPT_FILE)
  private String pythonScriptFile;

  public static final String SERIALIZED_NAME_SQL_SCRIPT = "sqlScript";
  @SerializedName(SERIALIZED_NAME_SQL_SCRIPT)
  private String sqlScript;

  public static final String SERIALIZED_NAME_SQL_SCRIPT_FILE = "sqlScriptFile";
  @SerializedName(SERIALIZED_NAME_SQL_SCRIPT_FILE)
  private String sqlScriptFile;

  public GoogleCloudDataplexV1TaskSparkTaskConfig() {
  }

  public GoogleCloudDataplexV1TaskSparkTaskConfig archiveUris(List<String> archiveUris) {
    this.archiveUris = archiveUris;
    return this;
  }

  public GoogleCloudDataplexV1TaskSparkTaskConfig addArchiveUrisItem(String archiveUrisItem) {
    if (this.archiveUris == null) {
      this.archiveUris = new ArrayList<>();
    }
    this.archiveUris.add(archiveUrisItem);
    return this;
  }

  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
   * @return archiveUris
   */
  @javax.annotation.Nullable
  public List<String> getArchiveUris() {
    return archiveUris;
  }

  public void setArchiveUris(List<String> archiveUris) {
    this.archiveUris = archiveUris;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig fileUris(List<String> fileUris) {
    this.fileUris = fileUris;
    return this;
  }

  public GoogleCloudDataplexV1TaskSparkTaskConfig addFileUrisItem(String fileUrisItem) {
    if (this.fileUris == null) {
      this.fileUris = new ArrayList<>();
    }
    this.fileUris.add(fileUrisItem);
    return this;
  }

  /**
   * Optional. Cloud Storage URIs of files to be placed in the working directory of each executor.
   * @return fileUris
   */
  @javax.annotation.Nullable
  public List<String> getFileUris() {
    return fileUris;
  }

  public void setFileUris(List<String> fileUris) {
    this.fileUris = fileUris;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig infrastructureSpec(GoogleCloudDataplexV1TaskInfrastructureSpec infrastructureSpec) {
    this.infrastructureSpec = infrastructureSpec;
    return this;
  }

  /**
   * Get infrastructureSpec
   * @return infrastructureSpec
   */
  @javax.annotation.Nullable
  public GoogleCloudDataplexV1TaskInfrastructureSpec getInfrastructureSpec() {
    return infrastructureSpec;
  }

  public void setInfrastructureSpec(GoogleCloudDataplexV1TaskInfrastructureSpec infrastructureSpec) {
    this.infrastructureSpec = infrastructureSpec;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig mainClass(String mainClass) {
    this.mainClass = mainClass;
    return this;
  }

  /**
   * The name of the driver&#39;s main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris. The execution args are passed in as a sequence of named process arguments (--key&#x3D;value).
   * @return mainClass
   */
  @javax.annotation.Nullable
  public String getMainClass() {
    return mainClass;
  }

  public void setMainClass(String mainClass) {
    this.mainClass = mainClass;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig mainJarFileUri(String mainJarFileUri) {
    this.mainJarFileUri = mainJarFileUri;
    return this;
  }

  /**
   * The Cloud Storage URI of the jar file that contains the main class. The execution args are passed in as a sequence of named process arguments (--key&#x3D;value).
   * @return mainJarFileUri
   */
  @javax.annotation.Nullable
  public String getMainJarFileUri() {
    return mainJarFileUri;
  }

  public void setMainJarFileUri(String mainJarFileUri) {
    this.mainJarFileUri = mainJarFileUri;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig pythonScriptFile(String pythonScriptFile) {
    this.pythonScriptFile = pythonScriptFile;
    return this;
  }

  /**
   * The Gcloud Storage URI of the main Python file to use as the driver. Must be a .py file. The execution args are passed in as a sequence of named process arguments (--key&#x3D;value).
   * @return pythonScriptFile
   */
  @javax.annotation.Nullable
  public String getPythonScriptFile() {
    return pythonScriptFile;
  }

  public void setPythonScriptFile(String pythonScriptFile) {
    this.pythonScriptFile = pythonScriptFile;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig sqlScript(String sqlScript) {
    this.sqlScript = sqlScript;
    return this;
  }

  /**
   * The query text. The execution args are used to declare a set of script variables (set key&#x3D;\&quot;value\&quot;;).
   * @return sqlScript
   */
  @javax.annotation.Nullable
  public String getSqlScript() {
    return sqlScript;
  }

  public void setSqlScript(String sqlScript) {
    this.sqlScript = sqlScript;
  }


  public GoogleCloudDataplexV1TaskSparkTaskConfig sqlScriptFile(String sqlScriptFile) {
    this.sqlScriptFile = sqlScriptFile;
    return this;
  }

  /**
   * A reference to a query file. This can be the Cloud Storage URI of the query file or it can the path to a SqlScript Content. The execution args are used to declare a set of script variables (set key&#x3D;\&quot;value\&quot;;).
   * @return sqlScriptFile
   */
  @javax.annotation.Nullable
  public String getSqlScriptFile() {
    return sqlScriptFile;
  }

  public void setSqlScriptFile(String sqlScriptFile) {
    this.sqlScriptFile = sqlScriptFile;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    GoogleCloudDataplexV1TaskSparkTaskConfig googleCloudDataplexV1TaskSparkTaskConfig = (GoogleCloudDataplexV1TaskSparkTaskConfig) o;
    return Objects.equals(this.archiveUris, googleCloudDataplexV1TaskSparkTaskConfig.archiveUris) &&
        Objects.equals(this.fileUris, googleCloudDataplexV1TaskSparkTaskConfig.fileUris) &&
        Objects.equals(this.infrastructureSpec, googleCloudDataplexV1TaskSparkTaskConfig.infrastructureSpec) &&
        Objects.equals(this.mainClass, googleCloudDataplexV1TaskSparkTaskConfig.mainClass) &&
        Objects.equals(this.mainJarFileUri, googleCloudDataplexV1TaskSparkTaskConfig.mainJarFileUri) &&
        Objects.equals(this.pythonScriptFile, googleCloudDataplexV1TaskSparkTaskConfig.pythonScriptFile) &&
        Objects.equals(this.sqlScript, googleCloudDataplexV1TaskSparkTaskConfig.sqlScript) &&
        Objects.equals(this.sqlScriptFile, googleCloudDataplexV1TaskSparkTaskConfig.sqlScriptFile);
  }

  @Override
  public int hashCode() {
    return Objects.hash(archiveUris, fileUris, infrastructureSpec, mainClass, mainJarFileUri, pythonScriptFile, sqlScript, sqlScriptFile);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class GoogleCloudDataplexV1TaskSparkTaskConfig {\n");
    sb.append("    archiveUris: ").append(toIndentedString(archiveUris)).append("\n");
    sb.append("    fileUris: ").append(toIndentedString(fileUris)).append("\n");
    sb.append("    infrastructureSpec: ").append(toIndentedString(infrastructureSpec)).append("\n");
    sb.append("    mainClass: ").append(toIndentedString(mainClass)).append("\n");
    sb.append("    mainJarFileUri: ").append(toIndentedString(mainJarFileUri)).append("\n");
    sb.append("    pythonScriptFile: ").append(toIndentedString(pythonScriptFile)).append("\n");
    sb.append("    sqlScript: ").append(toIndentedString(sqlScript)).append("\n");
    sb.append("    sqlScriptFile: ").append(toIndentedString(sqlScriptFile)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("archiveUris");
    openapiFields.add("fileUris");
    openapiFields.add("infrastructureSpec");
    openapiFields.add("mainClass");
    openapiFields.add("mainJarFileUri");
    openapiFields.add("pythonScriptFile");
    openapiFields.add("sqlScript");
    openapiFields.add("sqlScriptFile");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to GoogleCloudDataplexV1TaskSparkTaskConfig
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!GoogleCloudDataplexV1TaskSparkTaskConfig.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in GoogleCloudDataplexV1TaskSparkTaskConfig is not found in the empty JSON string", GoogleCloudDataplexV1TaskSparkTaskConfig.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!GoogleCloudDataplexV1TaskSparkTaskConfig.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `GoogleCloudDataplexV1TaskSparkTaskConfig` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // ensure the optional json data is an array if present
      if (jsonObj.get("archiveUris") != null && !jsonObj.get("archiveUris").isJsonNull() && !jsonObj.get("archiveUris").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `archiveUris` to be an array in the JSON string but got `%s`", jsonObj.get("archiveUris").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("fileUris") != null && !jsonObj.get("fileUris").isJsonNull() && !jsonObj.get("fileUris").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `fileUris` to be an array in the JSON string but got `%s`", jsonObj.get("fileUris").toString()));
      }
      // validate the optional field `infrastructureSpec`
      if (jsonObj.get("infrastructureSpec") != null && !jsonObj.get("infrastructureSpec").isJsonNull()) {
        GoogleCloudDataplexV1TaskInfrastructureSpec.validateJsonElement(jsonObj.get("infrastructureSpec"));
      }
      if ((jsonObj.get("mainClass") != null && !jsonObj.get("mainClass").isJsonNull()) && !jsonObj.get("mainClass").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `mainClass` to be a primitive type in the JSON string but got `%s`", jsonObj.get("mainClass").toString()));
      }
      if ((jsonObj.get("mainJarFileUri") != null && !jsonObj.get("mainJarFileUri").isJsonNull()) && !jsonObj.get("mainJarFileUri").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `mainJarFileUri` to be a primitive type in the JSON string but got `%s`", jsonObj.get("mainJarFileUri").toString()));
      }
      if ((jsonObj.get("pythonScriptFile") != null && !jsonObj.get("pythonScriptFile").isJsonNull()) && !jsonObj.get("pythonScriptFile").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `pythonScriptFile` to be a primitive type in the JSON string but got `%s`", jsonObj.get("pythonScriptFile").toString()));
      }
      if ((jsonObj.get("sqlScript") != null && !jsonObj.get("sqlScript").isJsonNull()) && !jsonObj.get("sqlScript").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `sqlScript` to be a primitive type in the JSON string but got `%s`", jsonObj.get("sqlScript").toString()));
      }
      if ((jsonObj.get("sqlScriptFile") != null && !jsonObj.get("sqlScriptFile").isJsonNull()) && !jsonObj.get("sqlScriptFile").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `sqlScriptFile` to be a primitive type in the JSON string but got `%s`", jsonObj.get("sqlScriptFile").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!GoogleCloudDataplexV1TaskSparkTaskConfig.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'GoogleCloudDataplexV1TaskSparkTaskConfig' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<GoogleCloudDataplexV1TaskSparkTaskConfig> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(GoogleCloudDataplexV1TaskSparkTaskConfig.class));

       return (TypeAdapter<T>) new TypeAdapter<GoogleCloudDataplexV1TaskSparkTaskConfig>() {
           @Override
           public void write(JsonWriter out, GoogleCloudDataplexV1TaskSparkTaskConfig value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public GoogleCloudDataplexV1TaskSparkTaskConfig read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of GoogleCloudDataplexV1TaskSparkTaskConfig given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of GoogleCloudDataplexV1TaskSparkTaskConfig
   * @throws IOException if the JSON string is invalid with respect to GoogleCloudDataplexV1TaskSparkTaskConfig
   */
  public static GoogleCloudDataplexV1TaskSparkTaskConfig fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, GoogleCloudDataplexV1TaskSparkTaskConfig.class);
  }

  /**
   * Convert an instance of GoogleCloudDataplexV1TaskSparkTaskConfig to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

