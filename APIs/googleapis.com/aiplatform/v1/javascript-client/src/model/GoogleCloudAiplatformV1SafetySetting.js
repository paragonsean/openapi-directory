/**
 * Vertex AI API
 * Train high-quality custom machine learning models with minimal machine learning expertise and effort.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';

/**
 * The GoogleCloudAiplatformV1SafetySetting model module.
 * @module model/GoogleCloudAiplatformV1SafetySetting
 * @version v1
 */
class GoogleCloudAiplatformV1SafetySetting {
    /**
     * Constructs a new <code>GoogleCloudAiplatformV1SafetySetting</code>.
     * Safety settings.
     * @alias module:model/GoogleCloudAiplatformV1SafetySetting
     */
    constructor() { 
        
        GoogleCloudAiplatformV1SafetySetting.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>GoogleCloudAiplatformV1SafetySetting</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/GoogleCloudAiplatformV1SafetySetting} obj Optional instance to populate.
     * @return {module:model/GoogleCloudAiplatformV1SafetySetting} The populated <code>GoogleCloudAiplatformV1SafetySetting</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new GoogleCloudAiplatformV1SafetySetting();

            if (data.hasOwnProperty('category')) {
                obj['category'] = ApiClient.convertToType(data['category'], 'String');
            }
            if (data.hasOwnProperty('threshold')) {
                obj['threshold'] = ApiClient.convertToType(data['threshold'], 'String');
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>GoogleCloudAiplatformV1SafetySetting</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>GoogleCloudAiplatformV1SafetySetting</code>.
     */
    static validateJSON(data) {
        // ensure the json data is a string
        if (data['category'] && !(typeof data['category'] === 'string' || data['category'] instanceof String)) {
            throw new Error("Expected the field `category` to be a primitive type in the JSON string but got " + data['category']);
        }
        // ensure the json data is a string
        if (data['threshold'] && !(typeof data['threshold'] === 'string' || data['threshold'] instanceof String)) {
            throw new Error("Expected the field `threshold` to be a primitive type in the JSON string but got " + data['threshold']);
        }

        return true;
    }


}



/**
 * Required. Harm category.
 * @member {module:model/GoogleCloudAiplatformV1SafetySetting.CategoryEnum} category
 */
GoogleCloudAiplatformV1SafetySetting.prototype['category'] = undefined;

/**
 * Required. The harm block threshold.
 * @member {module:model/GoogleCloudAiplatformV1SafetySetting.ThresholdEnum} threshold
 */
GoogleCloudAiplatformV1SafetySetting.prototype['threshold'] = undefined;





/**
 * Allowed values for the <code>category</code> property.
 * @enum {String}
 * @readonly
 */
GoogleCloudAiplatformV1SafetySetting['CategoryEnum'] = {

    /**
     * value: "HARM_CATEGORY_UNSPECIFIED"
     * @const
     */
    "UNSPECIFIED": "HARM_CATEGORY_UNSPECIFIED",

    /**
     * value: "HARM_CATEGORY_HATE_SPEECH"
     * @const
     */
    "HATE_SPEECH": "HARM_CATEGORY_HATE_SPEECH",

    /**
     * value: "HARM_CATEGORY_DANGEROUS_CONTENT"
     * @const
     */
    "DANGEROUS_CONTENT": "HARM_CATEGORY_DANGEROUS_CONTENT",

    /**
     * value: "HARM_CATEGORY_HARASSMENT"
     * @const
     */
    "HARASSMENT": "HARM_CATEGORY_HARASSMENT",

    /**
     * value: "HARM_CATEGORY_SEXUALLY_EXPLICIT"
     * @const
     */
    "SEXUALLY_EXPLICIT": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
};


/**
 * Allowed values for the <code>threshold</code> property.
 * @enum {String}
 * @readonly
 */
GoogleCloudAiplatformV1SafetySetting['ThresholdEnum'] = {

    /**
     * value: "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
     * @const
     */
    "HARM_BLOCK_THRESHOLD_UNSPECIFIED": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",

    /**
     * value: "BLOCK_LOW_AND_ABOVE"
     * @const
     */
    "BLOCK_LOW_AND_ABOVE": "BLOCK_LOW_AND_ABOVE",

    /**
     * value: "BLOCK_MEDIUM_AND_ABOVE"
     * @const
     */
    "BLOCK_MEDIUM_AND_ABOVE": "BLOCK_MEDIUM_AND_ABOVE",

    /**
     * value: "BLOCK_ONLY_HIGH"
     * @const
     */
    "BLOCK_ONLY_HIGH": "BLOCK_ONLY_HIGH",

    /**
     * value: "BLOCK_NONE"
     * @const
     */
    "BLOCK_NONE": "BLOCK_NONE"
};



export default GoogleCloudAiplatformV1SafetySetting;

