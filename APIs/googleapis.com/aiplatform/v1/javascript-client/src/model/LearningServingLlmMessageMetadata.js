/**
 * Vertex AI API
 * Train high-quality custom machine learning models with minimal machine learning expertise and effort.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import CloudAiNlLlmProtoServiceRaiResult from './CloudAiNlLlmProtoServiceRaiResult';
import LearningGenaiRecitationRecitationResult from './LearningGenaiRecitationRecitationResult';
import LearningGenaiRootClassifierOutputSummary from './LearningGenaiRootClassifierOutputSummary';
import LearningGenaiRootCodeyOutput from './LearningGenaiRootCodeyOutput';
import LearningGenaiRootFilterMetadata from './LearningGenaiRootFilterMetadata';
import LearningGenaiRootGroundingMetadata from './LearningGenaiRootGroundingMetadata';
import LearningGenaiRootRAIOutput from './LearningGenaiRootRAIOutput';
import LearningGenaiRootScore from './LearningGenaiRootScore';
import NlpSaftLangIdResult from './NlpSaftLangIdResult';

/**
 * The LearningServingLlmMessageMetadata model module.
 * @module model/LearningServingLlmMessageMetadata
 * @version v1
 */
class LearningServingLlmMessageMetadata {
    /**
     * Constructs a new <code>LearningServingLlmMessageMetadata</code>.
     * LINT.IfChange This metadata contains additional information required for debugging.
     * @alias module:model/LearningServingLlmMessageMetadata
     */
    constructor() { 
        
        LearningServingLlmMessageMetadata.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>LearningServingLlmMessageMetadata</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/LearningServingLlmMessageMetadata} obj Optional instance to populate.
     * @return {module:model/LearningServingLlmMessageMetadata} The populated <code>LearningServingLlmMessageMetadata</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new LearningServingLlmMessageMetadata();

            if (data.hasOwnProperty('classifierSummary')) {
                obj['classifierSummary'] = LearningGenaiRootClassifierOutputSummary.constructFromObject(data['classifierSummary']);
            }
            if (data.hasOwnProperty('codeyOutput')) {
                obj['codeyOutput'] = LearningGenaiRootCodeyOutput.constructFromObject(data['codeyOutput']);
            }
            if (data.hasOwnProperty('currentStreamTextLength')) {
                obj['currentStreamTextLength'] = ApiClient.convertToType(data['currentStreamTextLength'], 'Number');
            }
            if (data.hasOwnProperty('deleted')) {
                obj['deleted'] = ApiClient.convertToType(data['deleted'], 'Boolean');
            }
            if (data.hasOwnProperty('filterMeta')) {
                obj['filterMeta'] = ApiClient.convertToType(data['filterMeta'], [LearningGenaiRootFilterMetadata]);
            }
            if (data.hasOwnProperty('finalMessageScore')) {
                obj['finalMessageScore'] = LearningGenaiRootScore.constructFromObject(data['finalMessageScore']);
            }
            if (data.hasOwnProperty('finishReason')) {
                obj['finishReason'] = ApiClient.convertToType(data['finishReason'], 'String');
            }
            if (data.hasOwnProperty('groundingMetadata')) {
                obj['groundingMetadata'] = LearningGenaiRootGroundingMetadata.constructFromObject(data['groundingMetadata']);
            }
            if (data.hasOwnProperty('isCode')) {
                obj['isCode'] = ApiClient.convertToType(data['isCode'], 'Boolean');
            }
            if (data.hasOwnProperty('isFallback')) {
                obj['isFallback'] = ApiClient.convertToType(data['isFallback'], 'Boolean');
            }
            if (data.hasOwnProperty('langidResult')) {
                obj['langidResult'] = NlpSaftLangIdResult.constructFromObject(data['langidResult']);
            }
            if (data.hasOwnProperty('language')) {
                obj['language'] = ApiClient.convertToType(data['language'], 'String');
            }
            if (data.hasOwnProperty('lmPrefix')) {
                obj['lmPrefix'] = ApiClient.convertToType(data['lmPrefix'], 'String');
            }
            if (data.hasOwnProperty('originalText')) {
                obj['originalText'] = ApiClient.convertToType(data['originalText'], 'String');
            }
            if (data.hasOwnProperty('perStreamDecodedTokenCount')) {
                obj['perStreamDecodedTokenCount'] = ApiClient.convertToType(data['perStreamDecodedTokenCount'], 'Number');
            }
            if (data.hasOwnProperty('raiOutputs')) {
                obj['raiOutputs'] = ApiClient.convertToType(data['raiOutputs'], [LearningGenaiRootRAIOutput]);
            }
            if (data.hasOwnProperty('recitationResult')) {
                obj['recitationResult'] = LearningGenaiRecitationRecitationResult.constructFromObject(data['recitationResult']);
            }
            if (data.hasOwnProperty('returnTokenCount')) {
                obj['returnTokenCount'] = ApiClient.convertToType(data['returnTokenCount'], 'Number');
            }
            if (data.hasOwnProperty('scores')) {
                obj['scores'] = ApiClient.convertToType(data['scores'], [LearningGenaiRootScore]);
            }
            if (data.hasOwnProperty('streamTerminated')) {
                obj['streamTerminated'] = ApiClient.convertToType(data['streamTerminated'], 'Boolean');
            }
            if (data.hasOwnProperty('totalDecodedTokenCount')) {
                obj['totalDecodedTokenCount'] = ApiClient.convertToType(data['totalDecodedTokenCount'], 'Number');
            }
            if (data.hasOwnProperty('translatedUserPrompts')) {
                obj['translatedUserPrompts'] = ApiClient.convertToType(data['translatedUserPrompts'], ['String']);
            }
            if (data.hasOwnProperty('vertexRaiResult')) {
                obj['vertexRaiResult'] = CloudAiNlLlmProtoServiceRaiResult.constructFromObject(data['vertexRaiResult']);
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>LearningServingLlmMessageMetadata</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>LearningServingLlmMessageMetadata</code>.
     */
    static validateJSON(data) {
        // validate the optional field `classifierSummary`
        if (data['classifierSummary']) { // data not null
          LearningGenaiRootClassifierOutputSummary.validateJSON(data['classifierSummary']);
        }
        // validate the optional field `codeyOutput`
        if (data['codeyOutput']) { // data not null
          LearningGenaiRootCodeyOutput.validateJSON(data['codeyOutput']);
        }
        if (data['filterMeta']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['filterMeta'])) {
                throw new Error("Expected the field `filterMeta` to be an array in the JSON data but got " + data['filterMeta']);
            }
            // validate the optional field `filterMeta` (array)
            for (const item of data['filterMeta']) {
                LearningGenaiRootFilterMetadata.validateJSON(item);
            };
        }
        // validate the optional field `finalMessageScore`
        if (data['finalMessageScore']) { // data not null
          LearningGenaiRootScore.validateJSON(data['finalMessageScore']);
        }
        // ensure the json data is a string
        if (data['finishReason'] && !(typeof data['finishReason'] === 'string' || data['finishReason'] instanceof String)) {
            throw new Error("Expected the field `finishReason` to be a primitive type in the JSON string but got " + data['finishReason']);
        }
        // validate the optional field `groundingMetadata`
        if (data['groundingMetadata']) { // data not null
          LearningGenaiRootGroundingMetadata.validateJSON(data['groundingMetadata']);
        }
        // validate the optional field `langidResult`
        if (data['langidResult']) { // data not null
          NlpSaftLangIdResult.validateJSON(data['langidResult']);
        }
        // ensure the json data is a string
        if (data['language'] && !(typeof data['language'] === 'string' || data['language'] instanceof String)) {
            throw new Error("Expected the field `language` to be a primitive type in the JSON string but got " + data['language']);
        }
        // ensure the json data is a string
        if (data['lmPrefix'] && !(typeof data['lmPrefix'] === 'string' || data['lmPrefix'] instanceof String)) {
            throw new Error("Expected the field `lmPrefix` to be a primitive type in the JSON string but got " + data['lmPrefix']);
        }
        // ensure the json data is a string
        if (data['originalText'] && !(typeof data['originalText'] === 'string' || data['originalText'] instanceof String)) {
            throw new Error("Expected the field `originalText` to be a primitive type in the JSON string but got " + data['originalText']);
        }
        if (data['raiOutputs']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['raiOutputs'])) {
                throw new Error("Expected the field `raiOutputs` to be an array in the JSON data but got " + data['raiOutputs']);
            }
            // validate the optional field `raiOutputs` (array)
            for (const item of data['raiOutputs']) {
                LearningGenaiRootRAIOutput.validateJSON(item);
            };
        }
        // validate the optional field `recitationResult`
        if (data['recitationResult']) { // data not null
          LearningGenaiRecitationRecitationResult.validateJSON(data['recitationResult']);
        }
        if (data['scores']) { // data not null
            // ensure the json data is an array
            if (!Array.isArray(data['scores'])) {
                throw new Error("Expected the field `scores` to be an array in the JSON data but got " + data['scores']);
            }
            // validate the optional field `scores` (array)
            for (const item of data['scores']) {
                LearningGenaiRootScore.validateJSON(item);
            };
        }
        // ensure the json data is an array
        if (!Array.isArray(data['translatedUserPrompts'])) {
            throw new Error("Expected the field `translatedUserPrompts` to be an array in the JSON data but got " + data['translatedUserPrompts']);
        }
        // validate the optional field `vertexRaiResult`
        if (data['vertexRaiResult']) { // data not null
          CloudAiNlLlmProtoServiceRaiResult.validateJSON(data['vertexRaiResult']);
        }

        return true;
    }


}



/**
 * @member {module:model/LearningGenaiRootClassifierOutputSummary} classifierSummary
 */
LearningServingLlmMessageMetadata.prototype['classifierSummary'] = undefined;

/**
 * @member {module:model/LearningGenaiRootCodeyOutput} codeyOutput
 */
LearningServingLlmMessageMetadata.prototype['codeyOutput'] = undefined;

/**
 * @member {Number} currentStreamTextLength
 */
LearningServingLlmMessageMetadata.prototype['currentStreamTextLength'] = undefined;

/**
 * Whether the corresponding message has been deleted.
 * @member {Boolean} deleted
 */
LearningServingLlmMessageMetadata.prototype['deleted'] = undefined;

/**
 * Metadata for filters that triggered.
 * @member {Array.<module:model/LearningGenaiRootFilterMetadata>} filterMeta
 */
LearningServingLlmMessageMetadata.prototype['filterMeta'] = undefined;

/**
 * @member {module:model/LearningGenaiRootScore} finalMessageScore
 */
LearningServingLlmMessageMetadata.prototype['finalMessageScore'] = undefined;

/**
 * NOT YET IMPLEMENTED.
 * @member {module:model/LearningServingLlmMessageMetadata.FinishReasonEnum} finishReason
 */
LearningServingLlmMessageMetadata.prototype['finishReason'] = undefined;

/**
 * @member {module:model/LearningGenaiRootGroundingMetadata} groundingMetadata
 */
LearningServingLlmMessageMetadata.prototype['groundingMetadata'] = undefined;

/**
 * Applies to streaming response message only. Whether the message is a code.
 * @member {Boolean} isCode
 */
LearningServingLlmMessageMetadata.prototype['isCode'] = undefined;

/**
 * Applies to Response message only. Indicates whether the message is a fallback and the response would have otherwise been empty.
 * @member {Boolean} isFallback
 */
LearningServingLlmMessageMetadata.prototype['isFallback'] = undefined;

/**
 * @member {module:model/NlpSaftLangIdResult} langidResult
 */
LearningServingLlmMessageMetadata.prototype['langidResult'] = undefined;

/**
 * Detected language.
 * @member {String} language
 */
LearningServingLlmMessageMetadata.prototype['language'] = undefined;

/**
 * The LM prefix used to generate this response.
 * @member {String} lmPrefix
 */
LearningServingLlmMessageMetadata.prototype['lmPrefix'] = undefined;

/**
 * The original text generated by LLM. This is the raw output for debugging purposes.
 * @member {String} originalText
 */
LearningServingLlmMessageMetadata.prototype['originalText'] = undefined;

/**
 * NOT YET IMPLEMENTED. Applies to streaming only. Number of tokens decoded / emitted by the model as part of this stream. This may be different from token_count, which contains number of tokens returned in this response after any response rewriting / truncation.
 * @member {Number} perStreamDecodedTokenCount
 */
LearningServingLlmMessageMetadata.prototype['perStreamDecodedTokenCount'] = undefined;

/**
 * Results of running RAI on the query or this response candidate. One output per rai_config. It will be populated regardless of whether the threshold is exceeded or not.
 * @member {Array.<module:model/LearningGenaiRootRAIOutput>} raiOutputs
 */
LearningServingLlmMessageMetadata.prototype['raiOutputs'] = undefined;

/**
 * @member {module:model/LearningGenaiRecitationRecitationResult} recitationResult
 */
LearningServingLlmMessageMetadata.prototype['recitationResult'] = undefined;

/**
 * NOT YET IMPLEMENTED. Number of tokens returned as part of this candidate.
 * @member {Number} returnTokenCount
 */
LearningServingLlmMessageMetadata.prototype['returnTokenCount'] = undefined;

/**
 * All the different scores for a message are logged here.
 * @member {Array.<module:model/LearningGenaiRootScore>} scores
 */
LearningServingLlmMessageMetadata.prototype['scores'] = undefined;

/**
 * Whether the response is terminated during streaming return. Only used for streaming requests.
 * @member {Boolean} streamTerminated
 */
LearningServingLlmMessageMetadata.prototype['streamTerminated'] = undefined;

/**
 * NOT YET IMPLEMENTED. Aggregated number of total tokens decoded so far. For streaming, this is sum of all the tokens decoded so far i.e. aggregated count.
 * @member {Number} totalDecodedTokenCount
 */
LearningServingLlmMessageMetadata.prototype['totalDecodedTokenCount'] = undefined;

/**
 * Translated user-prompt used for RAI post processing. This is for internal processing only. We will translate in pre-processor and pass the translated text to the post processor using this field. It will be empty if non of the signals requested need translation.
 * @member {Array.<String>} translatedUserPrompts
 */
LearningServingLlmMessageMetadata.prototype['translatedUserPrompts'] = undefined;

/**
 * @member {module:model/CloudAiNlLlmProtoServiceRaiResult} vertexRaiResult
 */
LearningServingLlmMessageMetadata.prototype['vertexRaiResult'] = undefined;





/**
 * Allowed values for the <code>finishReason</code> property.
 * @enum {String}
 * @readonly
 */
LearningServingLlmMessageMetadata['FinishReasonEnum'] = {

    /**
     * value: "UNSPECIFIED"
     * @const
     */
    "UNSPECIFIED": "UNSPECIFIED",

    /**
     * value: "RETURN"
     * @const
     */
    "RETURN": "RETURN",

    /**
     * value: "STOP"
     * @const
     */
    "STOP": "STOP",

    /**
     * value: "MAX_TOKENS"
     * @const
     */
    "MAX_TOKENS": "MAX_TOKENS",

    /**
     * value: "FILTER"
     * @const
     */
    "FILTER": "FILTER"
};



export default LearningServingLlmMessageMetadata;

