/*
 * Vertex AI API
 * Train high-quality custom machine learning models with minimal machine learning expertise and effort.
 *
 * The version of the OpenAPI document: v1
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * Configuration defining how to transform batch prediction input instances to the instances that the Model accepts.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T11:33:33.164817-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig {
  public static final String SERIALIZED_NAME_EXCLUDED_FIELDS = "excludedFields";
  @SerializedName(SERIALIZED_NAME_EXCLUDED_FIELDS)
  private List<String> excludedFields = new ArrayList<>();

  public static final String SERIALIZED_NAME_INCLUDED_FIELDS = "includedFields";
  @SerializedName(SERIALIZED_NAME_INCLUDED_FIELDS)
  private List<String> includedFields = new ArrayList<>();

  public static final String SERIALIZED_NAME_INSTANCE_TYPE = "instanceType";
  @SerializedName(SERIALIZED_NAME_INSTANCE_TYPE)
  private String instanceType;

  public static final String SERIALIZED_NAME_KEY_FIELD = "keyField";
  @SerializedName(SERIALIZED_NAME_KEY_FIELD)
  private String keyField;

  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig() {
  }

  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig excludedFields(List<String> excludedFields) {
    this.excludedFields = excludedFields;
    return this;
  }

  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig addExcludedFieldsItem(String excludedFieldsItem) {
    if (this.excludedFields == null) {
      this.excludedFields = new ArrayList<>();
    }
    this.excludedFields.add(excludedFieldsItem);
    return this;
  }

  /**
   * Fields that will be excluded in the prediction instance that is sent to the Model. Excluded will be attached to the batch prediction output if key_field is not specified. When excluded_fields is populated, included_fields must be empty. The input must be JSONL with objects at each line, BigQuery or TfRecord.
   * @return excludedFields
   */
  @javax.annotation.Nullable
  public List<String> getExcludedFields() {
    return excludedFields;
  }

  public void setExcludedFields(List<String> excludedFields) {
    this.excludedFields = excludedFields;
  }


  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig includedFields(List<String> includedFields) {
    this.includedFields = includedFields;
    return this;
  }

  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig addIncludedFieldsItem(String includedFieldsItem) {
    if (this.includedFields == null) {
      this.includedFields = new ArrayList<>();
    }
    this.includedFields.add(includedFieldsItem);
    return this;
  }

  /**
   * Fields that will be included in the prediction instance that is sent to the Model. If instance_type is &#x60;array&#x60;, the order of field names in included_fields also determines the order of the values in the array. When included_fields is populated, excluded_fields must be empty. The input must be JSONL with objects at each line, BigQuery or TfRecord.
   * @return includedFields
   */
  @javax.annotation.Nullable
  public List<String> getIncludedFields() {
    return includedFields;
  }

  public void setIncludedFields(List<String> includedFields) {
    this.includedFields = includedFields;
  }


  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig instanceType(String instanceType) {
    this.instanceType = instanceType;
    return this;
  }

  /**
   * The format of the instance that the Model accepts. Vertex AI will convert compatible batch prediction input instance formats to the specified format. Supported values are: * &#x60;object&#x60;: Each input is converted to JSON object format. * For &#x60;bigquery&#x60;, each row is converted to an object. * For &#x60;jsonl&#x60;, each line of the JSONL input must be an object. * Does not apply to &#x60;csv&#x60;, &#x60;file-list&#x60;, &#x60;tf-record&#x60;, or &#x60;tf-record-gzip&#x60;. * &#x60;array&#x60;: Each input is converted to JSON array format. * For &#x60;bigquery&#x60;, each row is converted to an array. The order of columns is determined by the BigQuery column order, unless included_fields is populated. included_fields must be populated for specifying field orders. * For &#x60;jsonl&#x60;, if each line of the JSONL input is an object, included_fields must be populated for specifying field orders. * Does not apply to &#x60;csv&#x60;, &#x60;file-list&#x60;, &#x60;tf-record&#x60;, or &#x60;tf-record-gzip&#x60;. If not specified, Vertex AI converts the batch prediction input as follows: * For &#x60;bigquery&#x60; and &#x60;csv&#x60;, the behavior is the same as &#x60;array&#x60;. The order of columns is the same as defined in the file or table, unless included_fields is populated. * For &#x60;jsonl&#x60;, the prediction instance format is determined by each line of the input. * For &#x60;tf-record&#x60;/&#x60;tf-record-gzip&#x60;, each record will be converted to an object in the format of &#x60;{\&quot;b64\&quot;: }&#x60;, where &#x60;&#x60; is the Base64-encoded string of the content of the record. * For &#x60;file-list&#x60;, each file in the list will be converted to an object in the format of &#x60;{\&quot;b64\&quot;: }&#x60;, where &#x60;&#x60; is the Base64-encoded string of the content of the file.
   * @return instanceType
   */
  @javax.annotation.Nullable
  public String getInstanceType() {
    return instanceType;
  }

  public void setInstanceType(String instanceType) {
    this.instanceType = instanceType;
  }


  public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig keyField(String keyField) {
    this.keyField = keyField;
    return this;
  }

  /**
   * The name of the field that is considered as a key. The values identified by the key field is not included in the transformed instances that is sent to the Model. This is similar to specifying this name of the field in excluded_fields. In addition, the batch prediction output will not include the instances. Instead the output will only include the value of the key field, in a field named &#x60;key&#x60; in the output: * For &#x60;jsonl&#x60; output format, the output will have a &#x60;key&#x60; field instead of the &#x60;instance&#x60; field. * For &#x60;csv&#x60;/&#x60;bigquery&#x60; output format, the output will have have a &#x60;key&#x60; column instead of the instance feature columns. The input must be JSONL with objects at each line, CSV, BigQuery or TfRecord.
   * @return keyField
   */
  @javax.annotation.Nullable
  public String getKeyField() {
    return keyField;
  }

  public void setKeyField(String keyField) {
    this.keyField = keyField;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig googleCloudAiplatformV1BatchPredictionJobInstanceConfig = (GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig) o;
    return Objects.equals(this.excludedFields, googleCloudAiplatformV1BatchPredictionJobInstanceConfig.excludedFields) &&
        Objects.equals(this.includedFields, googleCloudAiplatformV1BatchPredictionJobInstanceConfig.includedFields) &&
        Objects.equals(this.instanceType, googleCloudAiplatformV1BatchPredictionJobInstanceConfig.instanceType) &&
        Objects.equals(this.keyField, googleCloudAiplatformV1BatchPredictionJobInstanceConfig.keyField);
  }

  @Override
  public int hashCode() {
    return Objects.hash(excludedFields, includedFields, instanceType, keyField);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig {\n");
    sb.append("    excludedFields: ").append(toIndentedString(excludedFields)).append("\n");
    sb.append("    includedFields: ").append(toIndentedString(includedFields)).append("\n");
    sb.append("    instanceType: ").append(toIndentedString(instanceType)).append("\n");
    sb.append("    keyField: ").append(toIndentedString(keyField)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("excludedFields");
    openapiFields.add("includedFields");
    openapiFields.add("instanceType");
    openapiFields.add("keyField");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig is not found in the empty JSON string", GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // ensure the optional json data is an array if present
      if (jsonObj.get("excludedFields") != null && !jsonObj.get("excludedFields").isJsonNull() && !jsonObj.get("excludedFields").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `excludedFields` to be an array in the JSON string but got `%s`", jsonObj.get("excludedFields").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("includedFields") != null && !jsonObj.get("includedFields").isJsonNull() && !jsonObj.get("includedFields").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `includedFields` to be an array in the JSON string but got `%s`", jsonObj.get("includedFields").toString()));
      }
      if ((jsonObj.get("instanceType") != null && !jsonObj.get("instanceType").isJsonNull()) && !jsonObj.get("instanceType").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `instanceType` to be a primitive type in the JSON string but got `%s`", jsonObj.get("instanceType").toString()));
      }
      if ((jsonObj.get("keyField") != null && !jsonObj.get("keyField").isJsonNull()) && !jsonObj.get("keyField").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `keyField` to be a primitive type in the JSON string but got `%s`", jsonObj.get("keyField").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.class));

       return (TypeAdapter<T>) new TypeAdapter<GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig>() {
           @Override
           public void write(JsonWriter out, GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig
   * @throws IOException if the JSON string is invalid with respect to GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig
   */
  public static GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.class);
  }

  /**
   * Convert an instance of GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

