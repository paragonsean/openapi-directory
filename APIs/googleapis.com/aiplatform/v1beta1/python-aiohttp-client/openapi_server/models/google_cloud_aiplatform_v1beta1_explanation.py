# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server.models.google_cloud_aiplatform_v1beta1_attribution import GoogleCloudAiplatformV1beta1Attribution
from openapi_server.models.google_cloud_aiplatform_v1beta1_neighbor import GoogleCloudAiplatformV1beta1Neighbor
from openapi_server import util


class GoogleCloudAiplatformV1beta1Explanation(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, attributions: List[GoogleCloudAiplatformV1beta1Attribution]=None, neighbors: List[GoogleCloudAiplatformV1beta1Neighbor]=None):
        """GoogleCloudAiplatformV1beta1Explanation - a model defined in OpenAPI

        :param attributions: The attributions of this GoogleCloudAiplatformV1beta1Explanation.
        :param neighbors: The neighbors of this GoogleCloudAiplatformV1beta1Explanation.
        """
        self.openapi_types = {
            'attributions': List[GoogleCloudAiplatformV1beta1Attribution],
            'neighbors': List[GoogleCloudAiplatformV1beta1Neighbor]
        }

        self.attribute_map = {
            'attributions': 'attributions',
            'neighbors': 'neighbors'
        }

        self._attributions = attributions
        self._neighbors = neighbors

    @classmethod
    def from_dict(cls, dikt: dict) -> 'GoogleCloudAiplatformV1beta1Explanation':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The GoogleCloudAiplatformV1beta1Explanation of this GoogleCloudAiplatformV1beta1Explanation.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def attributions(self):
        """Gets the attributions of this GoogleCloudAiplatformV1beta1Explanation.

        Output only. Feature attributions grouped by predicted outputs. For Models that predict only one output, such as regression Models that predict only one score, there is only one attibution that explains the predicted output. For Models that predict multiple outputs, such as multiclass Models that predict multiple classes, each element explains one specific item. Attribution.output_index can be used to identify which output this attribution is explaining. By default, we provide Shapley values for the predicted class. However, you can configure the explanation request to generate Shapley values for any other classes too. For example, if a model predicts a probability of `0.4` for approving a loan application, the model's decision is to reject the application since `p(reject) = 0.6 > p(approve) = 0.4`, and the default Shapley values would be computed for rejection decision and not approval, even though the latter might be the positive class. If users set ExplanationParameters.top_k, the attributions are sorted by instance_output_value in descending order. If ExplanationParameters.output_indices is specified, the attributions are stored by Attribution.output_index in the same order as they appear in the output_indices.

        :return: The attributions of this GoogleCloudAiplatformV1beta1Explanation.
        :rtype: List[GoogleCloudAiplatformV1beta1Attribution]
        """
        return self._attributions

    @attributions.setter
    def attributions(self, attributions):
        """Sets the attributions of this GoogleCloudAiplatformV1beta1Explanation.

        Output only. Feature attributions grouped by predicted outputs. For Models that predict only one output, such as regression Models that predict only one score, there is only one attibution that explains the predicted output. For Models that predict multiple outputs, such as multiclass Models that predict multiple classes, each element explains one specific item. Attribution.output_index can be used to identify which output this attribution is explaining. By default, we provide Shapley values for the predicted class. However, you can configure the explanation request to generate Shapley values for any other classes too. For example, if a model predicts a probability of `0.4` for approving a loan application, the model's decision is to reject the application since `p(reject) = 0.6 > p(approve) = 0.4`, and the default Shapley values would be computed for rejection decision and not approval, even though the latter might be the positive class. If users set ExplanationParameters.top_k, the attributions are sorted by instance_output_value in descending order. If ExplanationParameters.output_indices is specified, the attributions are stored by Attribution.output_index in the same order as they appear in the output_indices.

        :param attributions: The attributions of this GoogleCloudAiplatformV1beta1Explanation.
        :type attributions: List[GoogleCloudAiplatformV1beta1Attribution]
        """

        self._attributions = attributions

    @property
    def neighbors(self):
        """Gets the neighbors of this GoogleCloudAiplatformV1beta1Explanation.

        Output only. List of the nearest neighbors for example-based explanations. For models deployed with the examples explanations feature enabled, the attributions field is empty and instead the neighbors field is populated.

        :return: The neighbors of this GoogleCloudAiplatformV1beta1Explanation.
        :rtype: List[GoogleCloudAiplatformV1beta1Neighbor]
        """
        return self._neighbors

    @neighbors.setter
    def neighbors(self, neighbors):
        """Sets the neighbors of this GoogleCloudAiplatformV1beta1Explanation.

        Output only. List of the nearest neighbors for example-based explanations. For models deployed with the examples explanations feature enabled, the attributions field is empty and instead the neighbors field is populated.

        :param neighbors: The neighbors of this GoogleCloudAiplatformV1beta1Explanation.
        :type neighbors: List[GoogleCloudAiplatformV1beta1Neighbor]
        """

        self._neighbors = neighbors
