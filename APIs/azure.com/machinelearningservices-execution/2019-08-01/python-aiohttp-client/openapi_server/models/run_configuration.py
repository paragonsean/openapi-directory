# coding: utf-8

from datetime import date, datetime

from typing import List, Dict, Type

from openapi_server.models.base_model import Model
from openapi_server.models.data_reference_configuration import DataReferenceConfiguration
from openapi_server.models.environment_definition import EnvironmentDefinition
from openapi_server.models.hdi_configuration import HdiConfiguration
from openapi_server.models.history_configuration import HistoryConfiguration
from openapi_server.models.mpi_configuration import MpiConfiguration
from openapi_server.models.spark_configuration import SparkConfiguration
from openapi_server.models.tensorflow_configuration import TensorflowConfiguration
from openapi_server import util


class RunConfiguration(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, arguments: List[str]=None, communicator: str=None, data_references: Dict[str, DataReferenceConfiguration]=None, environment: EnvironmentDefinition=None, framework: str=None, hdi: HdiConfiguration=None, history: HistoryConfiguration=None, job_name: str=None, max_run_duration_seconds: int=None, mpi: MpiConfiguration=None, node_count: int=None, script: str=None, spark: SparkConfiguration=None, target: str=None, tensorflow: TensorflowConfiguration=None):
        """RunConfiguration - a model defined in OpenAPI

        :param arguments: The arguments of this RunConfiguration.
        :param communicator: The communicator of this RunConfiguration.
        :param data_references: The data_references of this RunConfiguration.
        :param environment: The environment of this RunConfiguration.
        :param framework: The framework of this RunConfiguration.
        :param hdi: The hdi of this RunConfiguration.
        :param history: The history of this RunConfiguration.
        :param job_name: The job_name of this RunConfiguration.
        :param max_run_duration_seconds: The max_run_duration_seconds of this RunConfiguration.
        :param mpi: The mpi of this RunConfiguration.
        :param node_count: The node_count of this RunConfiguration.
        :param script: The script of this RunConfiguration.
        :param spark: The spark of this RunConfiguration.
        :param target: The target of this RunConfiguration.
        :param tensorflow: The tensorflow of this RunConfiguration.
        """
        self.openapi_types = {
            'arguments': List[str],
            'communicator': str,
            'data_references': Dict[str, DataReferenceConfiguration],
            'environment': EnvironmentDefinition,
            'framework': str,
            'hdi': HdiConfiguration,
            'history': HistoryConfiguration,
            'job_name': str,
            'max_run_duration_seconds': int,
            'mpi': MpiConfiguration,
            'node_count': int,
            'script': str,
            'spark': SparkConfiguration,
            'target': str,
            'tensorflow': TensorflowConfiguration
        }

        self.attribute_map = {
            'arguments': 'arguments',
            'communicator': 'communicator',
            'data_references': 'dataReferences',
            'environment': 'environment',
            'framework': 'framework',
            'hdi': 'hdi',
            'history': 'history',
            'job_name': 'jobName',
            'max_run_duration_seconds': 'maxRunDurationSeconds',
            'mpi': 'mpi',
            'node_count': 'nodeCount',
            'script': 'script',
            'spark': 'spark',
            'target': 'target',
            'tensorflow': 'tensorflow'
        }

        self._arguments = arguments
        self._communicator = communicator
        self._data_references = data_references
        self._environment = environment
        self._framework = framework
        self._hdi = hdi
        self._history = history
        self._job_name = job_name
        self._max_run_duration_seconds = max_run_duration_seconds
        self._mpi = mpi
        self._node_count = node_count
        self._script = script
        self._spark = spark
        self._target = target
        self._tensorflow = tensorflow

    @classmethod
    def from_dict(cls, dikt: dict) -> 'RunConfiguration':
        """Returns the dict as a model

        :param dikt: A dict.
        :return: The RunConfiguration of this RunConfiguration.
        """
        return util.deserialize_model(dikt, cls)

    @property
    def arguments(self):
        """Gets the arguments of this RunConfiguration.

        Command line arguments for the python script file.

        :return: The arguments of this RunConfiguration.
        :rtype: List[str]
        """
        return self._arguments

    @arguments.setter
    def arguments(self, arguments):
        """Sets the arguments of this RunConfiguration.

        Command line arguments for the python script file.

        :param arguments: The arguments of this RunConfiguration.
        :type arguments: List[str]
        """

        self._arguments = arguments

    @property
    def communicator(self):
        """Gets the communicator of this RunConfiguration.

        The supported communicators are None, ParameterServer, OpenMpi, and IntelMpi Keep in mind that OpenMpi requires a custom image with OpenMpi installed.  Use ParameterServer or OpenMpi for AmlCompute clusters. Use IntelMpi for distributed training jobs.

        :return: The communicator of this RunConfiguration.
        :rtype: str
        """
        return self._communicator

    @communicator.setter
    def communicator(self, communicator):
        """Sets the communicator of this RunConfiguration.

        The supported communicators are None, ParameterServer, OpenMpi, and IntelMpi Keep in mind that OpenMpi requires a custom image with OpenMpi installed.  Use ParameterServer or OpenMpi for AmlCompute clusters. Use IntelMpi for distributed training jobs.

        :param communicator: The communicator of this RunConfiguration.
        :type communicator: str
        """
        allowed_values = ["None", "ParameterServer", "Gloo", "Mpi", "Nccl"]  # noqa: E501
        if communicator not in allowed_values:
            raise ValueError(
                "Invalid value for `communicator` ({0}), must be one of {1}"
                .format(communicator, allowed_values)
            )

        self._communicator = communicator

    @property
    def data_references(self):
        """Gets the data_references of this RunConfiguration.

        All the data sources are made available to the run during execution based on each configuration.

        :return: The data_references of this RunConfiguration.
        :rtype: Dict[str, DataReferenceConfiguration]
        """
        return self._data_references

    @data_references.setter
    def data_references(self, data_references):
        """Sets the data_references of this RunConfiguration.

        All the data sources are made available to the run during execution based on each configuration.

        :param data_references: The data_references of this RunConfiguration.
        :type data_references: Dict[str, DataReferenceConfiguration]
        """

        self._data_references = data_references

    @property
    def environment(self):
        """Gets the environment of this RunConfiguration.


        :return: The environment of this RunConfiguration.
        :rtype: EnvironmentDefinition
        """
        return self._environment

    @environment.setter
    def environment(self, environment):
        """Sets the environment of this RunConfiguration.


        :param environment: The environment of this RunConfiguration.
        :type environment: EnvironmentDefinition
        """

        self._environment = environment

    @property
    def framework(self):
        """Gets the framework of this RunConfiguration.

        The supported frameworks are Python, PySpark, CNTK, TensorFlow, and PyTorch. Use Tensorflow for AmlCompute clusters, and Python for distributed training jobs.

        :return: The framework of this RunConfiguration.
        :rtype: str
        """
        return self._framework

    @framework.setter
    def framework(self, framework):
        """Sets the framework of this RunConfiguration.

        The supported frameworks are Python, PySpark, CNTK, TensorFlow, and PyTorch. Use Tensorflow for AmlCompute clusters, and Python for distributed training jobs.

        :param framework: The framework of this RunConfiguration.
        :type framework: str
        """
        allowed_values = ["Python", "PySpark", "Cntk", "TensorFlow", "PyTorch"]  # noqa: E501
        if framework not in allowed_values:
            raise ValueError(
                "Invalid value for `framework` ({0}), must be one of {1}"
                .format(framework, allowed_values)
            )

        self._framework = framework

    @property
    def hdi(self):
        """Gets the hdi of this RunConfiguration.


        :return: The hdi of this RunConfiguration.
        :rtype: HdiConfiguration
        """
        return self._hdi

    @hdi.setter
    def hdi(self, hdi):
        """Sets the hdi of this RunConfiguration.


        :param hdi: The hdi of this RunConfiguration.
        :type hdi: HdiConfiguration
        """

        self._hdi = hdi

    @property
    def history(self):
        """Gets the history of this RunConfiguration.


        :return: The history of this RunConfiguration.
        :rtype: HistoryConfiguration
        """
        return self._history

    @history.setter
    def history(self, history):
        """Sets the history of this RunConfiguration.


        :param history: The history of this RunConfiguration.
        :type history: HistoryConfiguration
        """

        self._history = history

    @property
    def job_name(self):
        """Gets the job_name of this RunConfiguration.

        This is primarily intended for notebooks to override the default job name.  Defaults to ArgumentVector[0] if not specified.

        :return: The job_name of this RunConfiguration.
        :rtype: str
        """
        return self._job_name

    @job_name.setter
    def job_name(self, job_name):
        """Sets the job_name of this RunConfiguration.

        This is primarily intended for notebooks to override the default job name.  Defaults to ArgumentVector[0] if not specified.

        :param job_name: The job_name of this RunConfiguration.
        :type job_name: str
        """

        self._job_name = job_name

    @property
    def max_run_duration_seconds(self):
        """Gets the max_run_duration_seconds of this RunConfiguration.

        Maximum allowed time for the run. The system will attempt to automatically cancel the run if it took longer than this value.  MaxRunDurationSeconds=null means infinite duration.

        :return: The max_run_duration_seconds of this RunConfiguration.
        :rtype: int
        """
        return self._max_run_duration_seconds

    @max_run_duration_seconds.setter
    def max_run_duration_seconds(self, max_run_duration_seconds):
        """Sets the max_run_duration_seconds of this RunConfiguration.

        Maximum allowed time for the run. The system will attempt to automatically cancel the run if it took longer than this value.  MaxRunDurationSeconds=null means infinite duration.

        :param max_run_duration_seconds: The max_run_duration_seconds of this RunConfiguration.
        :type max_run_duration_seconds: int
        """

        self._max_run_duration_seconds = max_run_duration_seconds

    @property
    def mpi(self):
        """Gets the mpi of this RunConfiguration.


        :return: The mpi of this RunConfiguration.
        :rtype: MpiConfiguration
        """
        return self._mpi

    @mpi.setter
    def mpi(self, mpi):
        """Sets the mpi of this RunConfiguration.


        :param mpi: The mpi of this RunConfiguration.
        :type mpi: MpiConfiguration
        """

        self._mpi = mpi

    @property
    def node_count(self):
        """Gets the node_count of this RunConfiguration.

        Number of compute nodes to run the job on. Only applies to AMLCompute.

        :return: The node_count of this RunConfiguration.
        :rtype: int
        """
        return self._node_count

    @node_count.setter
    def node_count(self, node_count):
        """Sets the node_count of this RunConfiguration.

        Number of compute nodes to run the job on. Only applies to AMLCompute.

        :param node_count: The node_count of this RunConfiguration.
        :type node_count: int
        """

        self._node_count = node_count

    @property
    def script(self):
        """Gets the script of this RunConfiguration.

        The relative path to the python script file. The file path is relative to the source_directory passed to submit run.

        :return: The script of this RunConfiguration.
        :rtype: str
        """
        return self._script

    @script.setter
    def script(self, script):
        """Sets the script of this RunConfiguration.

        The relative path to the python script file. The file path is relative to the source_directory passed to submit run.

        :param script: The script of this RunConfiguration.
        :type script: str
        """

        self._script = script

    @property
    def spark(self):
        """Gets the spark of this RunConfiguration.


        :return: The spark of this RunConfiguration.
        :rtype: SparkConfiguration
        """
        return self._spark

    @spark.setter
    def spark(self, spark):
        """Sets the spark of this RunConfiguration.


        :param spark: The spark of this RunConfiguration.
        :type spark: SparkConfiguration
        """

        self._spark = spark

    @property
    def target(self):
        """Gets the target of this RunConfiguration.

        Target refers to compute where the job is scheduled for execution. The default target is \"local\" referring to the local machine.

        :return: The target of this RunConfiguration.
        :rtype: str
        """
        return self._target

    @target.setter
    def target(self, target):
        """Sets the target of this RunConfiguration.

        Target refers to compute where the job is scheduled for execution. The default target is \"local\" referring to the local machine.

        :param target: The target of this RunConfiguration.
        :type target: str
        """

        self._target = target

    @property
    def tensorflow(self):
        """Gets the tensorflow of this RunConfiguration.


        :return: The tensorflow of this RunConfiguration.
        :rtype: TensorflowConfiguration
        """
        return self._tensorflow

    @tensorflow.setter
    def tensorflow(self, tensorflow):
        """Sets the tensorflow of this RunConfiguration.


        :param tensorflow: The tensorflow of this RunConfiguration.
        :type tensorflow: TensorflowConfiguration
        """

        self._tensorflow = tensorflow
