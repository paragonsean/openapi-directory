/*
 * Amazon Kinesis Firehose
 * <fullname>Amazon Kinesis Data Firehose API Reference</fullname> <p>Amazon Kinesis Data Firehose is a fully managed service that delivers real-time streaming data to destinations such as Amazon Simple Storage Service (Amazon S3), Amazon OpenSearch Service, Amazon Redshift, Splunk, and various other supportd destinations.</p>
 *
 * The version of the OpenAPI document: 2015-08-04
 * Contact: mike.ralphson@gmail.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.Arrays;
import org.openapitools.client.model.ParquetCompression;
import org.openapitools.client.model.ParquetWriterVersion;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * A serializer to use for converting data to the Parquet format before storing it in Amazon S3. For more information, see &lt;a href&#x3D;\&quot;https://parquet.apache.org/documentation/latest/\&quot;&gt;Apache Parquet&lt;/a&gt;.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T12:09:11.989141-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class ParquetSerDe {
  public static final String SERIALIZED_NAME_BLOCK_SIZE_BYTES = "BlockSizeBytes";
  @SerializedName(SERIALIZED_NAME_BLOCK_SIZE_BYTES)
  private Integer blockSizeBytes;

  public static final String SERIALIZED_NAME_PAGE_SIZE_BYTES = "PageSizeBytes";
  @SerializedName(SERIALIZED_NAME_PAGE_SIZE_BYTES)
  private Integer pageSizeBytes;

  public static final String SERIALIZED_NAME_COMPRESSION = "Compression";
  @SerializedName(SERIALIZED_NAME_COMPRESSION)
  private ParquetCompression compression;

  public static final String SERIALIZED_NAME_ENABLE_DICTIONARY_COMPRESSION = "EnableDictionaryCompression";
  @SerializedName(SERIALIZED_NAME_ENABLE_DICTIONARY_COMPRESSION)
  private Boolean enableDictionaryCompression;

  public static final String SERIALIZED_NAME_MAX_PADDING_BYTES = "MaxPaddingBytes";
  @SerializedName(SERIALIZED_NAME_MAX_PADDING_BYTES)
  private Integer maxPaddingBytes;

  public static final String SERIALIZED_NAME_WRITER_VERSION = "WriterVersion";
  @SerializedName(SERIALIZED_NAME_WRITER_VERSION)
  private ParquetWriterVersion writerVersion;

  public ParquetSerDe() {
  }

  public ParquetSerDe blockSizeBytes(Integer blockSizeBytes) {
    this.blockSizeBytes = blockSizeBytes;
    return this;
  }

  /**
   * Get blockSizeBytes
   * @return blockSizeBytes
   */
  @javax.annotation.Nullable
  public Integer getBlockSizeBytes() {
    return blockSizeBytes;
  }

  public void setBlockSizeBytes(Integer blockSizeBytes) {
    this.blockSizeBytes = blockSizeBytes;
  }


  public ParquetSerDe pageSizeBytes(Integer pageSizeBytes) {
    this.pageSizeBytes = pageSizeBytes;
    return this;
  }

  /**
   * Get pageSizeBytes
   * @return pageSizeBytes
   */
  @javax.annotation.Nullable
  public Integer getPageSizeBytes() {
    return pageSizeBytes;
  }

  public void setPageSizeBytes(Integer pageSizeBytes) {
    this.pageSizeBytes = pageSizeBytes;
  }


  public ParquetSerDe compression(ParquetCompression compression) {
    this.compression = compression;
    return this;
  }

  /**
   * Get compression
   * @return compression
   */
  @javax.annotation.Nullable
  public ParquetCompression getCompression() {
    return compression;
  }

  public void setCompression(ParquetCompression compression) {
    this.compression = compression;
  }


  public ParquetSerDe enableDictionaryCompression(Boolean enableDictionaryCompression) {
    this.enableDictionaryCompression = enableDictionaryCompression;
    return this;
  }

  /**
   * Get enableDictionaryCompression
   * @return enableDictionaryCompression
   */
  @javax.annotation.Nullable
  public Boolean getEnableDictionaryCompression() {
    return enableDictionaryCompression;
  }

  public void setEnableDictionaryCompression(Boolean enableDictionaryCompression) {
    this.enableDictionaryCompression = enableDictionaryCompression;
  }


  public ParquetSerDe maxPaddingBytes(Integer maxPaddingBytes) {
    this.maxPaddingBytes = maxPaddingBytes;
    return this;
  }

  /**
   * Get maxPaddingBytes
   * @return maxPaddingBytes
   */
  @javax.annotation.Nullable
  public Integer getMaxPaddingBytes() {
    return maxPaddingBytes;
  }

  public void setMaxPaddingBytes(Integer maxPaddingBytes) {
    this.maxPaddingBytes = maxPaddingBytes;
  }


  public ParquetSerDe writerVersion(ParquetWriterVersion writerVersion) {
    this.writerVersion = writerVersion;
    return this;
  }

  /**
   * Get writerVersion
   * @return writerVersion
   */
  @javax.annotation.Nullable
  public ParquetWriterVersion getWriterVersion() {
    return writerVersion;
  }

  public void setWriterVersion(ParquetWriterVersion writerVersion) {
    this.writerVersion = writerVersion;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    ParquetSerDe parquetSerDe = (ParquetSerDe) o;
    return Objects.equals(this.blockSizeBytes, parquetSerDe.blockSizeBytes) &&
        Objects.equals(this.pageSizeBytes, parquetSerDe.pageSizeBytes) &&
        Objects.equals(this.compression, parquetSerDe.compression) &&
        Objects.equals(this.enableDictionaryCompression, parquetSerDe.enableDictionaryCompression) &&
        Objects.equals(this.maxPaddingBytes, parquetSerDe.maxPaddingBytes) &&
        Objects.equals(this.writerVersion, parquetSerDe.writerVersion);
  }

  @Override
  public int hashCode() {
    return Objects.hash(blockSizeBytes, pageSizeBytes, compression, enableDictionaryCompression, maxPaddingBytes, writerVersion);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class ParquetSerDe {\n");
    sb.append("    blockSizeBytes: ").append(toIndentedString(blockSizeBytes)).append("\n");
    sb.append("    pageSizeBytes: ").append(toIndentedString(pageSizeBytes)).append("\n");
    sb.append("    compression: ").append(toIndentedString(compression)).append("\n");
    sb.append("    enableDictionaryCompression: ").append(toIndentedString(enableDictionaryCompression)).append("\n");
    sb.append("    maxPaddingBytes: ").append(toIndentedString(maxPaddingBytes)).append("\n");
    sb.append("    writerVersion: ").append(toIndentedString(writerVersion)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("BlockSizeBytes");
    openapiFields.add("PageSizeBytes");
    openapiFields.add("Compression");
    openapiFields.add("EnableDictionaryCompression");
    openapiFields.add("MaxPaddingBytes");
    openapiFields.add("WriterVersion");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to ParquetSerDe
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!ParquetSerDe.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in ParquetSerDe is not found in the empty JSON string", ParquetSerDe.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!ParquetSerDe.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `ParquetSerDe` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // validate the optional field `BlockSizeBytes`
      if (jsonObj.get("BlockSizeBytes") != null && !jsonObj.get("BlockSizeBytes").isJsonNull()) {
        Integer.validateJsonElement(jsonObj.get("BlockSizeBytes"));
      }
      // validate the optional field `PageSizeBytes`
      if (jsonObj.get("PageSizeBytes") != null && !jsonObj.get("PageSizeBytes").isJsonNull()) {
        Integer.validateJsonElement(jsonObj.get("PageSizeBytes"));
      }
      // validate the optional field `Compression`
      if (jsonObj.get("Compression") != null && !jsonObj.get("Compression").isJsonNull()) {
        ParquetCompression.validateJsonElement(jsonObj.get("Compression"));
      }
      // validate the optional field `EnableDictionaryCompression`
      if (jsonObj.get("EnableDictionaryCompression") != null && !jsonObj.get("EnableDictionaryCompression").isJsonNull()) {
        Boolean.validateJsonElement(jsonObj.get("EnableDictionaryCompression"));
      }
      // validate the optional field `MaxPaddingBytes`
      if (jsonObj.get("MaxPaddingBytes") != null && !jsonObj.get("MaxPaddingBytes").isJsonNull()) {
        Integer.validateJsonElement(jsonObj.get("MaxPaddingBytes"));
      }
      // validate the optional field `WriterVersion`
      if (jsonObj.get("WriterVersion") != null && !jsonObj.get("WriterVersion").isJsonNull()) {
        ParquetWriterVersion.validateJsonElement(jsonObj.get("WriterVersion"));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!ParquetSerDe.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'ParquetSerDe' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<ParquetSerDe> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(ParquetSerDe.class));

       return (TypeAdapter<T>) new TypeAdapter<ParquetSerDe>() {
           @Override
           public void write(JsonWriter out, ParquetSerDe value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public ParquetSerDe read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of ParquetSerDe given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of ParquetSerDe
   * @throws IOException if the JSON string is invalid with respect to ParquetSerDe
   */
  public static ParquetSerDe fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, ParquetSerDe.class);
  }

  /**
   * Convert an instance of ParquetSerDe to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

