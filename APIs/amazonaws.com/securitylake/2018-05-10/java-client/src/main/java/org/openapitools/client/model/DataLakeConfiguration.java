/*
 * Amazon Security Lake
 * <p>Amazon Security Lake is a fully managed security data lake service. You can use Security Lake to automatically centralize security data from cloud, on-premises, and custom sources into a data lake that's stored in your Amazon Web Services account. Amazon Web Services Organizations is an account management service that lets you consolidate multiple Amazon Web Services accounts into an organization that you create and centrally manage. With Organizations, you can create member accounts and invite existing accounts to join your organization. Security Lake helps you analyze security data for a more complete understanding of your security posture across the entire organization. It can also help you improve the protection of your workloads, applications, and data.</p> <p>The data lake is backed by Amazon Simple Storage Service (Amazon S3) buckets, and you retain ownership over your data.</p> <p>Amazon Security Lake integrates with CloudTrail, a service that provides a record of actions taken by a user, role, or an Amazon Web Services service. In Security Lake, CloudTrail captures API calls for Security Lake as events. The calls captured include calls from the Security Lake console and code calls to the Security Lake API operations. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Security Lake. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history. Using the information collected by CloudTrail you can determine the request that was made to Security Lake, the IP address from which the request was made, who made the request, when it was made, and additional details. To learn more about Security Lake information in CloudTrail, see the <a href=\"https://docs.aws.amazon.com/security-lake/latest/userguide/securitylake-cloudtrail.html\">Amazon Security Lake User Guide</a>.</p> <p>Security Lake automates the collection of security-related log and event data from integrated Amazon Web Services and third-party services. It also helps you manage the lifecycle of data with customizable retention and replication settings. Security Lake converts ingested data into Apache Parquet format and a standard open-source schema called the Open Cybersecurity Schema Framework (OCSF).</p> <p>Other Amazon Web Services and third-party services can subscribe to the data that's stored in Security Lake for incident response and security data analytics.</p>
 *
 * The version of the OpenAPI document: 2018-05-10
 * Contact: mike.ralphson@gmail.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.Arrays;
import org.openapitools.client.model.DataLakeConfigurationEncryptionConfiguration;
import org.openapitools.client.model.DataLakeConfigurationLifecycleConfiguration;
import org.openapitools.client.model.DataLakeConfigurationReplicationConfiguration;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * Provides details of Amazon Security Lake object.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T12:09:52.370107-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class DataLakeConfiguration {
  public static final String SERIALIZED_NAME_ENCRYPTION_CONFIGURATION = "encryptionConfiguration";
  @SerializedName(SERIALIZED_NAME_ENCRYPTION_CONFIGURATION)
  private DataLakeConfigurationEncryptionConfiguration encryptionConfiguration;

  public static final String SERIALIZED_NAME_LIFECYCLE_CONFIGURATION = "lifecycleConfiguration";
  @SerializedName(SERIALIZED_NAME_LIFECYCLE_CONFIGURATION)
  private DataLakeConfigurationLifecycleConfiguration lifecycleConfiguration;

  public static final String SERIALIZED_NAME_REGION = "region";
  @SerializedName(SERIALIZED_NAME_REGION)
  private String region;

  public static final String SERIALIZED_NAME_REPLICATION_CONFIGURATION = "replicationConfiguration";
  @SerializedName(SERIALIZED_NAME_REPLICATION_CONFIGURATION)
  private DataLakeConfigurationReplicationConfiguration replicationConfiguration;

  public DataLakeConfiguration() {
  }

  public DataLakeConfiguration encryptionConfiguration(DataLakeConfigurationEncryptionConfiguration encryptionConfiguration) {
    this.encryptionConfiguration = encryptionConfiguration;
    return this;
  }

  /**
   * Get encryptionConfiguration
   * @return encryptionConfiguration
   */
  @javax.annotation.Nullable
  public DataLakeConfigurationEncryptionConfiguration getEncryptionConfiguration() {
    return encryptionConfiguration;
  }

  public void setEncryptionConfiguration(DataLakeConfigurationEncryptionConfiguration encryptionConfiguration) {
    this.encryptionConfiguration = encryptionConfiguration;
  }


  public DataLakeConfiguration lifecycleConfiguration(DataLakeConfigurationLifecycleConfiguration lifecycleConfiguration) {
    this.lifecycleConfiguration = lifecycleConfiguration;
    return this;
  }

  /**
   * Get lifecycleConfiguration
   * @return lifecycleConfiguration
   */
  @javax.annotation.Nullable
  public DataLakeConfigurationLifecycleConfiguration getLifecycleConfiguration() {
    return lifecycleConfiguration;
  }

  public void setLifecycleConfiguration(DataLakeConfigurationLifecycleConfiguration lifecycleConfiguration) {
    this.lifecycleConfiguration = lifecycleConfiguration;
  }


  public DataLakeConfiguration region(String region) {
    this.region = region;
    return this;
  }

  /**
   * Get region
   * @return region
   */
  @javax.annotation.Nonnull
  public String getRegion() {
    return region;
  }

  public void setRegion(String region) {
    this.region = region;
  }


  public DataLakeConfiguration replicationConfiguration(DataLakeConfigurationReplicationConfiguration replicationConfiguration) {
    this.replicationConfiguration = replicationConfiguration;
    return this;
  }

  /**
   * Get replicationConfiguration
   * @return replicationConfiguration
   */
  @javax.annotation.Nullable
  public DataLakeConfigurationReplicationConfiguration getReplicationConfiguration() {
    return replicationConfiguration;
  }

  public void setReplicationConfiguration(DataLakeConfigurationReplicationConfiguration replicationConfiguration) {
    this.replicationConfiguration = replicationConfiguration;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    DataLakeConfiguration dataLakeConfiguration = (DataLakeConfiguration) o;
    return Objects.equals(this.encryptionConfiguration, dataLakeConfiguration.encryptionConfiguration) &&
        Objects.equals(this.lifecycleConfiguration, dataLakeConfiguration.lifecycleConfiguration) &&
        Objects.equals(this.region, dataLakeConfiguration.region) &&
        Objects.equals(this.replicationConfiguration, dataLakeConfiguration.replicationConfiguration);
  }

  @Override
  public int hashCode() {
    return Objects.hash(encryptionConfiguration, lifecycleConfiguration, region, replicationConfiguration);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class DataLakeConfiguration {\n");
    sb.append("    encryptionConfiguration: ").append(toIndentedString(encryptionConfiguration)).append("\n");
    sb.append("    lifecycleConfiguration: ").append(toIndentedString(lifecycleConfiguration)).append("\n");
    sb.append("    region: ").append(toIndentedString(region)).append("\n");
    sb.append("    replicationConfiguration: ").append(toIndentedString(replicationConfiguration)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("encryptionConfiguration");
    openapiFields.add("lifecycleConfiguration");
    openapiFields.add("region");
    openapiFields.add("replicationConfiguration");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
    openapiRequiredFields.add("region");
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to DataLakeConfiguration
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!DataLakeConfiguration.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in DataLakeConfiguration is not found in the empty JSON string", DataLakeConfiguration.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!DataLakeConfiguration.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `DataLakeConfiguration` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }

      // check to make sure all required properties/fields are present in the JSON string
      for (String requiredField : DataLakeConfiguration.openapiRequiredFields) {
        if (jsonElement.getAsJsonObject().get(requiredField) == null) {
          throw new IllegalArgumentException(String.format("The required field `%s` is not found in the JSON string: %s", requiredField, jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // validate the optional field `encryptionConfiguration`
      if (jsonObj.get("encryptionConfiguration") != null && !jsonObj.get("encryptionConfiguration").isJsonNull()) {
        DataLakeConfigurationEncryptionConfiguration.validateJsonElement(jsonObj.get("encryptionConfiguration"));
      }
      // validate the optional field `lifecycleConfiguration`
      if (jsonObj.get("lifecycleConfiguration") != null && !jsonObj.get("lifecycleConfiguration").isJsonNull()) {
        DataLakeConfigurationLifecycleConfiguration.validateJsonElement(jsonObj.get("lifecycleConfiguration"));
      }
      // validate the required field `region`
      String.validateJsonElement(jsonObj.get("region"));
      // validate the optional field `replicationConfiguration`
      if (jsonObj.get("replicationConfiguration") != null && !jsonObj.get("replicationConfiguration").isJsonNull()) {
        DataLakeConfigurationReplicationConfiguration.validateJsonElement(jsonObj.get("replicationConfiguration"));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!DataLakeConfiguration.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'DataLakeConfiguration' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<DataLakeConfiguration> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(DataLakeConfiguration.class));

       return (TypeAdapter<T>) new TypeAdapter<DataLakeConfiguration>() {
           @Override
           public void write(JsonWriter out, DataLakeConfiguration value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public DataLakeConfiguration read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of DataLakeConfiguration given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of DataLakeConfiguration
   * @throws IOException if the JSON string is invalid with respect to DataLakeConfiguration
   */
  public static DataLakeConfiguration fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, DataLakeConfiguration.class);
  }

  /**
   * Convert an instance of DataLakeConfiguration to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

