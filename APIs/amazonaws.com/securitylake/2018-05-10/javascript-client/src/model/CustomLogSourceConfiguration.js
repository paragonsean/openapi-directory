/**
 * Amazon Security Lake
 * <p>Amazon Security Lake is a fully managed security data lake service. You can use Security Lake to automatically centralize security data from cloud, on-premises, and custom sources into a data lake that's stored in your Amazon Web Services account. Amazon Web Services Organizations is an account management service that lets you consolidate multiple Amazon Web Services accounts into an organization that you create and centrally manage. With Organizations, you can create member accounts and invite existing accounts to join your organization. Security Lake helps you analyze security data for a more complete understanding of your security posture across the entire organization. It can also help you improve the protection of your workloads, applications, and data.</p> <p>The data lake is backed by Amazon Simple Storage Service (Amazon S3) buckets, and you retain ownership over your data.</p> <p>Amazon Security Lake integrates with CloudTrail, a service that provides a record of actions taken by a user, role, or an Amazon Web Services service. In Security Lake, CloudTrail captures API calls for Security Lake as events. The calls captured include calls from the Security Lake console and code calls to the Security Lake API operations. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Security Lake. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history. Using the information collected by CloudTrail you can determine the request that was made to Security Lake, the IP address from which the request was made, who made the request, when it was made, and additional details. To learn more about Security Lake information in CloudTrail, see the <a href=\"https://docs.aws.amazon.com/security-lake/latest/userguide/securitylake-cloudtrail.html\">Amazon Security Lake User Guide</a>.</p> <p>Security Lake automates the collection of security-related log and event data from integrated Amazon Web Services and third-party services. It also helps you manage the lifecycle of data with customizable retention and replication settings. Security Lake converts ingested data into Apache Parquet format and a standard open-source schema called the Open Cybersecurity Schema Framework (OCSF).</p> <p>Other Amazon Web Services and third-party services can subscribe to the data that's stored in Security Lake for incident response and security data analytics.</p>
 *
 * The version of the OpenAPI document: 2018-05-10
 * Contact: mike.ralphson@gmail.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';
import CreateCustomLogSourceRequestConfigurationCrawlerConfiguration from './CreateCustomLogSourceRequestConfigurationCrawlerConfiguration';
import CreateCustomLogSourceRequestConfigurationProviderIdentity from './CreateCustomLogSourceRequestConfigurationProviderIdentity';

/**
 * The CustomLogSourceConfiguration model module.
 * @module model/CustomLogSourceConfiguration
 * @version 2018-05-10
 */
class CustomLogSourceConfiguration {
    /**
     * Constructs a new <code>CustomLogSourceConfiguration</code>.
     * The configuration for the third-party custom source.
     * @alias module:model/CustomLogSourceConfiguration
     * @param crawlerConfiguration {module:model/CreateCustomLogSourceRequestConfigurationCrawlerConfiguration} 
     * @param providerIdentity {module:model/CreateCustomLogSourceRequestConfigurationProviderIdentity} 
     */
    constructor(crawlerConfiguration, providerIdentity) { 
        
        CustomLogSourceConfiguration.initialize(this, crawlerConfiguration, providerIdentity);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj, crawlerConfiguration, providerIdentity) { 
        obj['crawlerConfiguration'] = crawlerConfiguration;
        obj['providerIdentity'] = providerIdentity;
    }

    /**
     * Constructs a <code>CustomLogSourceConfiguration</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/CustomLogSourceConfiguration} obj Optional instance to populate.
     * @return {module:model/CustomLogSourceConfiguration} The populated <code>CustomLogSourceConfiguration</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new CustomLogSourceConfiguration();

            if (data.hasOwnProperty('crawlerConfiguration')) {
                obj['crawlerConfiguration'] = CreateCustomLogSourceRequestConfigurationCrawlerConfiguration.constructFromObject(data['crawlerConfiguration']);
            }
            if (data.hasOwnProperty('providerIdentity')) {
                obj['providerIdentity'] = CreateCustomLogSourceRequestConfigurationProviderIdentity.constructFromObject(data['providerIdentity']);
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>CustomLogSourceConfiguration</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>CustomLogSourceConfiguration</code>.
     */
    static validateJSON(data) {
        // check to make sure all required properties are present in the JSON string
        for (const property of CustomLogSourceConfiguration.RequiredProperties) {
            if (!data.hasOwnProperty(property)) {
                throw new Error("The required field `" + property + "` is not found in the JSON data: " + JSON.stringify(data));
            }
        }
        // validate the optional field `crawlerConfiguration`
        if (data['crawlerConfiguration']) { // data not null
          CreateCustomLogSourceRequestConfigurationCrawlerConfiguration.validateJSON(data['crawlerConfiguration']);
        }
        // validate the optional field `providerIdentity`
        if (data['providerIdentity']) { // data not null
          CreateCustomLogSourceRequestConfigurationProviderIdentity.validateJSON(data['providerIdentity']);
        }

        return true;
    }


}

CustomLogSourceConfiguration.RequiredProperties = ["crawlerConfiguration", "providerIdentity"];

/**
 * @member {module:model/CreateCustomLogSourceRequestConfigurationCrawlerConfiguration} crawlerConfiguration
 */
CustomLogSourceConfiguration.prototype['crawlerConfiguration'] = undefined;

/**
 * @member {module:model/CreateCustomLogSourceRequestConfigurationProviderIdentity} providerIdentity
 */
CustomLogSourceConfiguration.prototype['providerIdentity'] = undefined;






export default CustomLogSourceConfiguration;

