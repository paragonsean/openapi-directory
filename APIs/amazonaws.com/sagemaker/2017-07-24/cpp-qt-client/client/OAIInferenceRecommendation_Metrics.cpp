/**
 * Amazon SageMaker Service
 * <p>Provides APIs for creating and managing SageMaker resources. </p> <p>Other Resources:</p> <ul> <li> <p> <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html#first-time-user\">SageMaker Developer Guide</a> </p> </li> <li> <p> <a href=\"https://docs.aws.amazon.com/augmented-ai/2019-11-07/APIReference/Welcome.html\">Amazon Augmented AI Runtime API Reference</a> </p> </li> </ul>
 *
 * The version of the OpenAPI document: 2017-07-24
 * Contact: mike.ralphson@gmail.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

#include "OAIInferenceRecommendation_Metrics.h"

#include <QDebug>
#include <QJsonArray>
#include <QJsonDocument>
#include <QObject>

#include "OAIHelpers.h"

namespace OpenAPI {

OAIInferenceRecommendation_Metrics::OAIInferenceRecommendation_Metrics(QString json) {
    this->initializeModel();
    this->fromJson(json);
}

OAIInferenceRecommendation_Metrics::OAIInferenceRecommendation_Metrics() {
    this->initializeModel();
}

OAIInferenceRecommendation_Metrics::~OAIInferenceRecommendation_Metrics() {}

void OAIInferenceRecommendation_Metrics::initializeModel() {

    m_cost_per_hour_isSet = false;
    m_cost_per_hour_isValid = false;

    m_cost_per_inference_isSet = false;
    m_cost_per_inference_isValid = false;

    m_max_invocations_isSet = false;
    m_max_invocations_isValid = false;

    m_model_latency_isSet = false;
    m_model_latency_isValid = false;

    m_cpu_utilization_isSet = false;
    m_cpu_utilization_isValid = false;

    m_memory_utilization_isSet = false;
    m_memory_utilization_isValid = false;

    m_model_setup_time_isSet = false;
    m_model_setup_time_isValid = false;
}

void OAIInferenceRecommendation_Metrics::fromJson(QString jsonString) {
    QByteArray array(jsonString.toStdString().c_str());
    QJsonDocument doc = QJsonDocument::fromJson(array);
    QJsonObject jsonObject = doc.object();
    this->fromJsonObject(jsonObject);
}

void OAIInferenceRecommendation_Metrics::fromJsonObject(QJsonObject json) {

    m_cost_per_hour_isValid = ::OpenAPI::fromJsonValue(m_cost_per_hour, json[QString("CostPerHour")]);
    m_cost_per_hour_isSet = !json[QString("CostPerHour")].isNull() && m_cost_per_hour_isValid;

    m_cost_per_inference_isValid = ::OpenAPI::fromJsonValue(m_cost_per_inference, json[QString("CostPerInference")]);
    m_cost_per_inference_isSet = !json[QString("CostPerInference")].isNull() && m_cost_per_inference_isValid;

    m_max_invocations_isValid = ::OpenAPI::fromJsonValue(m_max_invocations, json[QString("MaxInvocations")]);
    m_max_invocations_isSet = !json[QString("MaxInvocations")].isNull() && m_max_invocations_isValid;

    m_model_latency_isValid = ::OpenAPI::fromJsonValue(m_model_latency, json[QString("ModelLatency")]);
    m_model_latency_isSet = !json[QString("ModelLatency")].isNull() && m_model_latency_isValid;

    m_cpu_utilization_isValid = ::OpenAPI::fromJsonValue(m_cpu_utilization, json[QString("CpuUtilization")]);
    m_cpu_utilization_isSet = !json[QString("CpuUtilization")].isNull() && m_cpu_utilization_isValid;

    m_memory_utilization_isValid = ::OpenAPI::fromJsonValue(m_memory_utilization, json[QString("MemoryUtilization")]);
    m_memory_utilization_isSet = !json[QString("MemoryUtilization")].isNull() && m_memory_utilization_isValid;

    m_model_setup_time_isValid = ::OpenAPI::fromJsonValue(m_model_setup_time, json[QString("ModelSetupTime")]);
    m_model_setup_time_isSet = !json[QString("ModelSetupTime")].isNull() && m_model_setup_time_isValid;
}

QString OAIInferenceRecommendation_Metrics::asJson() const {
    QJsonObject obj = this->asJsonObject();
    QJsonDocument doc(obj);
    QByteArray bytes = doc.toJson();
    return QString(bytes);
}

QJsonObject OAIInferenceRecommendation_Metrics::asJsonObject() const {
    QJsonObject obj;
    if (m_cost_per_hour_isSet) {
        obj.insert(QString("CostPerHour"), ::OpenAPI::toJsonValue(m_cost_per_hour));
    }
    if (m_cost_per_inference_isSet) {
        obj.insert(QString("CostPerInference"), ::OpenAPI::toJsonValue(m_cost_per_inference));
    }
    if (m_max_invocations_isSet) {
        obj.insert(QString("MaxInvocations"), ::OpenAPI::toJsonValue(m_max_invocations));
    }
    if (m_model_latency_isSet) {
        obj.insert(QString("ModelLatency"), ::OpenAPI::toJsonValue(m_model_latency));
    }
    if (m_cpu_utilization_isSet) {
        obj.insert(QString("CpuUtilization"), ::OpenAPI::toJsonValue(m_cpu_utilization));
    }
    if (m_memory_utilization_isSet) {
        obj.insert(QString("MemoryUtilization"), ::OpenAPI::toJsonValue(m_memory_utilization));
    }
    if (m_model_setup_time_isSet) {
        obj.insert(QString("ModelSetupTime"), ::OpenAPI::toJsonValue(m_model_setup_time));
    }
    return obj;
}

float OAIInferenceRecommendation_Metrics::getCostPerHour() const {
    return m_cost_per_hour;
}
void OAIInferenceRecommendation_Metrics::setCostPerHour(const float &cost_per_hour) {
    m_cost_per_hour = cost_per_hour;
    m_cost_per_hour_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_cost_per_hour_Set() const{
    return m_cost_per_hour_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_cost_per_hour_Valid() const{
    return m_cost_per_hour_isValid;
}

float OAIInferenceRecommendation_Metrics::getCostPerInference() const {
    return m_cost_per_inference;
}
void OAIInferenceRecommendation_Metrics::setCostPerInference(const float &cost_per_inference) {
    m_cost_per_inference = cost_per_inference;
    m_cost_per_inference_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_cost_per_inference_Set() const{
    return m_cost_per_inference_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_cost_per_inference_Valid() const{
    return m_cost_per_inference_isValid;
}

qint32 OAIInferenceRecommendation_Metrics::getMaxInvocations() const {
    return m_max_invocations;
}
void OAIInferenceRecommendation_Metrics::setMaxInvocations(const qint32 &max_invocations) {
    m_max_invocations = max_invocations;
    m_max_invocations_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_max_invocations_Set() const{
    return m_max_invocations_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_max_invocations_Valid() const{
    return m_max_invocations_isValid;
}

qint32 OAIInferenceRecommendation_Metrics::getModelLatency() const {
    return m_model_latency;
}
void OAIInferenceRecommendation_Metrics::setModelLatency(const qint32 &model_latency) {
    m_model_latency = model_latency;
    m_model_latency_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_model_latency_Set() const{
    return m_model_latency_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_model_latency_Valid() const{
    return m_model_latency_isValid;
}

float OAIInferenceRecommendation_Metrics::getCpuUtilization() const {
    return m_cpu_utilization;
}
void OAIInferenceRecommendation_Metrics::setCpuUtilization(const float &cpu_utilization) {
    m_cpu_utilization = cpu_utilization;
    m_cpu_utilization_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_cpu_utilization_Set() const{
    return m_cpu_utilization_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_cpu_utilization_Valid() const{
    return m_cpu_utilization_isValid;
}

float OAIInferenceRecommendation_Metrics::getMemoryUtilization() const {
    return m_memory_utilization;
}
void OAIInferenceRecommendation_Metrics::setMemoryUtilization(const float &memory_utilization) {
    m_memory_utilization = memory_utilization;
    m_memory_utilization_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_memory_utilization_Set() const{
    return m_memory_utilization_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_memory_utilization_Valid() const{
    return m_memory_utilization_isValid;
}

qint32 OAIInferenceRecommendation_Metrics::getModelSetupTime() const {
    return m_model_setup_time;
}
void OAIInferenceRecommendation_Metrics::setModelSetupTime(const qint32 &model_setup_time) {
    m_model_setup_time = model_setup_time;
    m_model_setup_time_isSet = true;
}

bool OAIInferenceRecommendation_Metrics::is_model_setup_time_Set() const{
    return m_model_setup_time_isSet;
}

bool OAIInferenceRecommendation_Metrics::is_model_setup_time_Valid() const{
    return m_model_setup_time_isValid;
}

bool OAIInferenceRecommendation_Metrics::isSet() const {
    bool isObjectUpdated = false;
    do {
        if (m_cost_per_hour_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_cost_per_inference_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_max_invocations_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_model_latency_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_cpu_utilization_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_memory_utilization_isSet) {
            isObjectUpdated = true;
            break;
        }

        if (m_model_setup_time_isSet) {
            isObjectUpdated = true;
            break;
        }
    } while (false);
    return isObjectUpdated;
}

bool OAIInferenceRecommendation_Metrics::isValid() const {
    // only required properties are required for the object to be considered valid
    return m_cost_per_hour_isValid && m_cost_per_inference_isValid && m_max_invocations_isValid && m_model_latency_isValid && true;
}

} // namespace OpenAPI
