/*
 * Amazon EventBridge Pipes
 * Amazon EventBridge Pipes connects event sources to targets. Pipes reduces the need for specialized knowledge and integration code when developing event driven architectures. This helps ensures consistency across your companyâ€™s applications. With Pipes, the target can be any available EventBridge target. To set up a pipe, you select the event source, add optional event filtering, define optional enrichment, and select the target for the event data. 
 *
 * The version of the OpenAPI document: 2015-10-07
 * Contact: mike.ralphson@gmail.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.Arrays;
import org.openapitools.client.model.MSKStartPosition;
import org.openapitools.client.model.PipeSourceManagedStreamingKafkaParametersCredentials;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.openapitools.client.JSON;

/**
 * The parameters for using an MSK stream as a source.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-10-12T12:02:08.188199-04:00[America/New_York]", comments = "Generator version: 7.9.0")
public class PipeSourceManagedStreamingKafkaParameters {
  public static final String SERIALIZED_NAME_BATCH_SIZE = "BatchSize";
  @SerializedName(SERIALIZED_NAME_BATCH_SIZE)
  private Integer batchSize;

  public static final String SERIALIZED_NAME_CONSUMER_GROUP_I_D = "ConsumerGroupID";
  @SerializedName(SERIALIZED_NAME_CONSUMER_GROUP_I_D)
  private String consumerGroupID;

  public static final String SERIALIZED_NAME_CREDENTIALS = "Credentials";
  @SerializedName(SERIALIZED_NAME_CREDENTIALS)
  private PipeSourceManagedStreamingKafkaParametersCredentials credentials;

  public static final String SERIALIZED_NAME_MAXIMUM_BATCHING_WINDOW_IN_SECONDS = "MaximumBatchingWindowInSeconds";
  @SerializedName(SERIALIZED_NAME_MAXIMUM_BATCHING_WINDOW_IN_SECONDS)
  private Integer maximumBatchingWindowInSeconds;

  public static final String SERIALIZED_NAME_STARTING_POSITION = "StartingPosition";
  @SerializedName(SERIALIZED_NAME_STARTING_POSITION)
  private MSKStartPosition startingPosition;

  public static final String SERIALIZED_NAME_TOPIC_NAME = "TopicName";
  @SerializedName(SERIALIZED_NAME_TOPIC_NAME)
  private String topicName;

  public PipeSourceManagedStreamingKafkaParameters() {
  }

  public PipeSourceManagedStreamingKafkaParameters batchSize(Integer batchSize) {
    this.batchSize = batchSize;
    return this;
  }

  /**
   * Get batchSize
   * @return batchSize
   */
  @javax.annotation.Nullable
  public Integer getBatchSize() {
    return batchSize;
  }

  public void setBatchSize(Integer batchSize) {
    this.batchSize = batchSize;
  }


  public PipeSourceManagedStreamingKafkaParameters consumerGroupID(String consumerGroupID) {
    this.consumerGroupID = consumerGroupID;
    return this;
  }

  /**
   * Get consumerGroupID
   * @return consumerGroupID
   */
  @javax.annotation.Nullable
  public String getConsumerGroupID() {
    return consumerGroupID;
  }

  public void setConsumerGroupID(String consumerGroupID) {
    this.consumerGroupID = consumerGroupID;
  }


  public PipeSourceManagedStreamingKafkaParameters credentials(PipeSourceManagedStreamingKafkaParametersCredentials credentials) {
    this.credentials = credentials;
    return this;
  }

  /**
   * Get credentials
   * @return credentials
   */
  @javax.annotation.Nullable
  public PipeSourceManagedStreamingKafkaParametersCredentials getCredentials() {
    return credentials;
  }

  public void setCredentials(PipeSourceManagedStreamingKafkaParametersCredentials credentials) {
    this.credentials = credentials;
  }


  public PipeSourceManagedStreamingKafkaParameters maximumBatchingWindowInSeconds(Integer maximumBatchingWindowInSeconds) {
    this.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds;
    return this;
  }

  /**
   * Get maximumBatchingWindowInSeconds
   * @return maximumBatchingWindowInSeconds
   */
  @javax.annotation.Nullable
  public Integer getMaximumBatchingWindowInSeconds() {
    return maximumBatchingWindowInSeconds;
  }

  public void setMaximumBatchingWindowInSeconds(Integer maximumBatchingWindowInSeconds) {
    this.maximumBatchingWindowInSeconds = maximumBatchingWindowInSeconds;
  }


  public PipeSourceManagedStreamingKafkaParameters startingPosition(MSKStartPosition startingPosition) {
    this.startingPosition = startingPosition;
    return this;
  }

  /**
   * Get startingPosition
   * @return startingPosition
   */
  @javax.annotation.Nullable
  public MSKStartPosition getStartingPosition() {
    return startingPosition;
  }

  public void setStartingPosition(MSKStartPosition startingPosition) {
    this.startingPosition = startingPosition;
  }


  public PipeSourceManagedStreamingKafkaParameters topicName(String topicName) {
    this.topicName = topicName;
    return this;
  }

  /**
   * Get topicName
   * @return topicName
   */
  @javax.annotation.Nonnull
  public String getTopicName() {
    return topicName;
  }

  public void setTopicName(String topicName) {
    this.topicName = topicName;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    PipeSourceManagedStreamingKafkaParameters pipeSourceManagedStreamingKafkaParameters = (PipeSourceManagedStreamingKafkaParameters) o;
    return Objects.equals(this.batchSize, pipeSourceManagedStreamingKafkaParameters.batchSize) &&
        Objects.equals(this.consumerGroupID, pipeSourceManagedStreamingKafkaParameters.consumerGroupID) &&
        Objects.equals(this.credentials, pipeSourceManagedStreamingKafkaParameters.credentials) &&
        Objects.equals(this.maximumBatchingWindowInSeconds, pipeSourceManagedStreamingKafkaParameters.maximumBatchingWindowInSeconds) &&
        Objects.equals(this.startingPosition, pipeSourceManagedStreamingKafkaParameters.startingPosition) &&
        Objects.equals(this.topicName, pipeSourceManagedStreamingKafkaParameters.topicName);
  }

  @Override
  public int hashCode() {
    return Objects.hash(batchSize, consumerGroupID, credentials, maximumBatchingWindowInSeconds, startingPosition, topicName);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class PipeSourceManagedStreamingKafkaParameters {\n");
    sb.append("    batchSize: ").append(toIndentedString(batchSize)).append("\n");
    sb.append("    consumerGroupID: ").append(toIndentedString(consumerGroupID)).append("\n");
    sb.append("    credentials: ").append(toIndentedString(credentials)).append("\n");
    sb.append("    maximumBatchingWindowInSeconds: ").append(toIndentedString(maximumBatchingWindowInSeconds)).append("\n");
    sb.append("    startingPosition: ").append(toIndentedString(startingPosition)).append("\n");
    sb.append("    topicName: ").append(toIndentedString(topicName)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("BatchSize");
    openapiFields.add("ConsumerGroupID");
    openapiFields.add("Credentials");
    openapiFields.add("MaximumBatchingWindowInSeconds");
    openapiFields.add("StartingPosition");
    openapiFields.add("TopicName");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
    openapiRequiredFields.add("TopicName");
  }

  /**
   * Validates the JSON Element and throws an exception if issues found
   *
   * @param jsonElement JSON Element
   * @throws IOException if the JSON Element is invalid with respect to PipeSourceManagedStreamingKafkaParameters
   */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!PipeSourceManagedStreamingKafkaParameters.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in PipeSourceManagedStreamingKafkaParameters is not found in the empty JSON string", PipeSourceManagedStreamingKafkaParameters.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!PipeSourceManagedStreamingKafkaParameters.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `PipeSourceManagedStreamingKafkaParameters` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }

      // check to make sure all required properties/fields are present in the JSON string
      for (String requiredField : PipeSourceManagedStreamingKafkaParameters.openapiRequiredFields) {
        if (jsonElement.getAsJsonObject().get(requiredField) == null) {
          throw new IllegalArgumentException(String.format("The required field `%s` is not found in the JSON string: %s", requiredField, jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      // validate the optional field `BatchSize`
      if (jsonObj.get("BatchSize") != null && !jsonObj.get("BatchSize").isJsonNull()) {
        Integer.validateJsonElement(jsonObj.get("BatchSize"));
      }
      // validate the optional field `ConsumerGroupID`
      if (jsonObj.get("ConsumerGroupID") != null && !jsonObj.get("ConsumerGroupID").isJsonNull()) {
        String.validateJsonElement(jsonObj.get("ConsumerGroupID"));
      }
      // validate the optional field `Credentials`
      if (jsonObj.get("Credentials") != null && !jsonObj.get("Credentials").isJsonNull()) {
        PipeSourceManagedStreamingKafkaParametersCredentials.validateJsonElement(jsonObj.get("Credentials"));
      }
      // validate the optional field `MaximumBatchingWindowInSeconds`
      if (jsonObj.get("MaximumBatchingWindowInSeconds") != null && !jsonObj.get("MaximumBatchingWindowInSeconds").isJsonNull()) {
        Integer.validateJsonElement(jsonObj.get("MaximumBatchingWindowInSeconds"));
      }
      // validate the optional field `StartingPosition`
      if (jsonObj.get("StartingPosition") != null && !jsonObj.get("StartingPosition").isJsonNull()) {
        MSKStartPosition.validateJsonElement(jsonObj.get("StartingPosition"));
      }
      // validate the required field `TopicName`
      String.validateJsonElement(jsonObj.get("TopicName"));
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!PipeSourceManagedStreamingKafkaParameters.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'PipeSourceManagedStreamingKafkaParameters' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<PipeSourceManagedStreamingKafkaParameters> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(PipeSourceManagedStreamingKafkaParameters.class));

       return (TypeAdapter<T>) new TypeAdapter<PipeSourceManagedStreamingKafkaParameters>() {
           @Override
           public void write(JsonWriter out, PipeSourceManagedStreamingKafkaParameters value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public PipeSourceManagedStreamingKafkaParameters read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

  /**
   * Create an instance of PipeSourceManagedStreamingKafkaParameters given an JSON string
   *
   * @param jsonString JSON string
   * @return An instance of PipeSourceManagedStreamingKafkaParameters
   * @throws IOException if the JSON string is invalid with respect to PipeSourceManagedStreamingKafkaParameters
   */
  public static PipeSourceManagedStreamingKafkaParameters fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, PipeSourceManagedStreamingKafkaParameters.class);
  }

  /**
   * Convert an instance of PipeSourceManagedStreamingKafkaParameters to an JSON string
   *
   * @return JSON string
   */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

