/**
 * Amazon EC2 Container Service
 * <fullname>Amazon Elastic Container Service</fullname> <p>Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service. It makes it easy to run, stop, and manage Docker containers. You can host your cluster on a serverless infrastructure that's managed by Amazon ECS by launching your services or tasks on Fargate. For more control, you can host your tasks on a cluster of Amazon Elastic Compute Cloud (Amazon EC2) or External (on-premises) instances that you manage.</p> <p>Amazon ECS makes it easy to launch and stop container-based applications with simple API calls. This makes it easy to get the state of your cluster from a centralized service, and gives you access to many familiar Amazon EC2 features.</p> <p>You can use Amazon ECS to schedule the placement of containers across your cluster based on your resource needs, isolation policies, and availability requirements. With Amazon ECS, you don't need to operate your own cluster management and configuration management systems. You also don't need to worry about scaling your management infrastructure.</p>
 *
 * The version of the OpenAPI document: 2014-11-13
 * Contact: mike.ralphson@gmail.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * OAIInferenceAccelerator.h
 *
 * Details on an Elastic Inference accelerator. For more information, see &lt;a href&#x3D;\&quot;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-inference.html\&quot;&gt;Working with Amazon Elastic Inference on Amazon ECS&lt;/a&gt; in the &lt;i&gt;Amazon Elastic Container Service Developer Guide&lt;/i&gt;.
 */

#ifndef OAIInferenceAccelerator_H
#define OAIInferenceAccelerator_H

#include <QJsonObject>

#include <QString>

#include "OAIEnum.h"
#include "OAIObject.h"

namespace OpenAPI {

class OAIInferenceAccelerator : public OAIObject {
public:
    OAIInferenceAccelerator();
    OAIInferenceAccelerator(QString json);
    ~OAIInferenceAccelerator() override;

    QString asJson() const override;
    QJsonObject asJsonObject() const override;
    void fromJsonObject(QJsonObject json) override;
    void fromJson(QString jsonString) override;

    QString getDeviceName() const;
    void setDeviceName(const QString &device_name);
    bool is_device_name_Set() const;
    bool is_device_name_Valid() const;

    QString getDeviceType() const;
    void setDeviceType(const QString &device_type);
    bool is_device_type_Set() const;
    bool is_device_type_Valid() const;

    virtual bool isSet() const override;
    virtual bool isValid() const override;

private:
    void initializeModel();

    QString m_device_name;
    bool m_device_name_isSet;
    bool m_device_name_isValid;

    QString m_device_type;
    bool m_device_type_isSet;
    bool m_device_type_isValid;
};

} // namespace OpenAPI

Q_DECLARE_METATYPE(OpenAPI::OAIInferenceAccelerator)

#endif // OAIInferenceAccelerator_H
