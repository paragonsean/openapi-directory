/**
 * Dataflow Kit Web Scraper
 * Render Javascript driven pages, while we internally manage Headless Chrome and proxies for you.   - Build a custom web scraper with our Visual point-and-click toolkit. - Scrape the most popular Search engines result pages (SERP). - Convert web pages to PDF and capture screenshots. *** ### Authentication Dataflow Kit API require you to sign up for an API key in order to use the API.   The API key can be found in the [DFK Dashboard](https://account.dataflowkit.com) after _free registration_.  Pass a secret API Key to all API requests to the server as the `api_key` query parameter.  
 *
 * The version of the OpenAPI document: 1.3
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */


import ApiClient from "../ApiClient";
import Parserequest from '../model/Parserequest';

/**
* Parse service.
* @module api/ParseApi
* @version 1.3
*/
export default class ParseApi {

    /**
    * Constructs a new ParseApi. 
    * @alias module:api/ParseApi
    * @class
    * @param {module:ApiClient} [apiClient] Optional API client implementation to use,
    * default to {@link module:ApiClient#instance} if unspecified.
    */
    constructor(apiClient) {
        this.apiClient = apiClient || ApiClient.instance;
    }


    /**
     * Callback function to receive the result of the parse operation.
     * @callback module:api/ParseApi~parseCallback
     * @param {String} error Error message, if any.
     * @param {Object} data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * Extract structured data from web pages
     * Dataflow kit uses CSS selectors to find HTML elements in web pages for later data extraction.  Open [visual point-and-click toolkit](https://dataflowkit.com/dfk) and click desired elements on a page to specify extracting data.     Then you can send generated payload to `/parse` endpoint. We crawl web pages and extract data like text, links, or images for you following the specified rules.    Extracted data is returned in CSV, MS Excel, JSON, JSON(Lines) or XML format. 
     * @param {module:model/Parserequest} parserequest ### Field types and attributes    - **Text**. Extract human-readable text from the selected element and all its child elements. HTML tags are stripped, and only text returned.      - **Link**. Capture link `href` attribute and link text. Or specify a special _Path_ option for website navigation. When Path option is true, all other selectors ignored, and no results from the current page returned.      - **Image**. Image type extracts `src` (URL) and `alt` attributes of an image   *** ### Filters Filters are used to manipulate text data when extracting.  Here is the list of available filters   - **Trim** removes leading and trailing white spaces from the _field text or attribute_  - **Normal** leaves the case and capitalization of text/ attribute exactly as is.  - **UPPERCASE** makes all of the letters in the Field's text/ attribute uppercase.  - **lowercase** makes all of the letters in the Field's text/ attribute lowercase.  - **Capitalize** capitalizes the first letter of each word in the Field's text/ attribute  - **Concatinate** joins text array element into a single string  *** ### Regular Expressions  For more advanced text formatting regular expression can be used. Some useful examples are listed below   | Input text | Regex | Result | | ---------- | ----- | ------ | | price- 10.99â‚¬ | <code>[0-9]+\\.[0-9]+</code> | 10.99 | | phone- 0 (944) 244-18-22 | <code>\\w+</code> | 09442441822 |   *** ### Details. Chaining. The Link field type serves as a navigation link to a details page containing more data. A special _Path_ option is used for navigation only. When the Path option specified, no results from the current page returned. But grouped results from details pages will be pulled instead. You can use chaining functionality of Dataflow Kit scraper to retrieve all the detail page data at the same time. 
     * @param {module:api/ParseApi~parseCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link Object}
     */
    parse(parserequest, callback) {
      let postBody = parserequest;
      // verify the required parameter 'parserequest' is set
      if (parserequest === undefined || parserequest === null) {
        throw new Error("Missing the required parameter 'parserequest' when calling parse");
      }

      let pathParams = {
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['ApiKeyAuth'];
      let contentTypes = ['application/json'];
      let accepts = ['application/json', 'text/plain; charset=utf-8'];
      let returnType = Object;
      return this.apiClient.callApi(
        '/parse', 'POST',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }


}
