/**
 * Spotify Web API with fixes and improvements from sonallux
 * You can use Spotify's Web API to discover music and podcasts, manage your Spotify library, control audio playback, and much more. Browse our available Web API endpoints using the sidebar at left, or via the navigation bar on top of this page on smaller screens.  In order to make successful Web API requests your app will need a valid access token. One can be obtained through <a href=\"https://developer.spotify.com/documentation/general/guides/authorization-guide/\">OAuth 2.0</a>.  The base URI for all Web API requests is `https://api.spotify.com/v1`.  Need help? See our <a href=\"https://developer.spotify.com/documentation/web-api/guides/\">Web API guides</a> for more information, or visit the <a href=\"https://community.spotify.com/t5/Spotify-for-Developers/bd-p/Spotify_Developer\">Spotify for Developers community forum</a> to ask questions and connect with other developers. 
 *
 * The version of the OpenAPI document: 2023.2.27
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';

/**
 * The AudioAnalysisObjectTrack model module.
 * @module model/AudioAnalysisObjectTrack
 * @version 2023.2.27
 */
class AudioAnalysisObjectTrack {
    /**
     * Constructs a new <code>AudioAnalysisObjectTrack</code>.
     * @alias module:model/AudioAnalysisObjectTrack
     */
    constructor() { 
        
        AudioAnalysisObjectTrack.initialize(this);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj) { 
    }

    /**
     * Constructs a <code>AudioAnalysisObjectTrack</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/AudioAnalysisObjectTrack} obj Optional instance to populate.
     * @return {module:model/AudioAnalysisObjectTrack} The populated <code>AudioAnalysisObjectTrack</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new AudioAnalysisObjectTrack();

            if (data.hasOwnProperty('analysis_channels')) {
                obj['analysis_channels'] = ApiClient.convertToType(data['analysis_channels'], 'Number');
            }
            if (data.hasOwnProperty('analysis_sample_rate')) {
                obj['analysis_sample_rate'] = ApiClient.convertToType(data['analysis_sample_rate'], 'Number');
            }
            if (data.hasOwnProperty('code_version')) {
                obj['code_version'] = ApiClient.convertToType(data['code_version'], 'Number');
            }
            if (data.hasOwnProperty('codestring')) {
                obj['codestring'] = ApiClient.convertToType(data['codestring'], 'String');
            }
            if (data.hasOwnProperty('duration')) {
                obj['duration'] = ApiClient.convertToType(data['duration'], 'Number');
            }
            if (data.hasOwnProperty('echoprint_version')) {
                obj['echoprint_version'] = ApiClient.convertToType(data['echoprint_version'], 'Number');
            }
            if (data.hasOwnProperty('echoprintstring')) {
                obj['echoprintstring'] = ApiClient.convertToType(data['echoprintstring'], 'String');
            }
            if (data.hasOwnProperty('end_of_fade_in')) {
                obj['end_of_fade_in'] = ApiClient.convertToType(data['end_of_fade_in'], 'Number');
            }
            if (data.hasOwnProperty('key')) {
                obj['key'] = ApiClient.convertToType(data['key'], 'Number');
            }
            if (data.hasOwnProperty('key_confidence')) {
                obj['key_confidence'] = ApiClient.convertToType(data['key_confidence'], 'Number');
            }
            if (data.hasOwnProperty('loudness')) {
                obj['loudness'] = ApiClient.convertToType(data['loudness'], 'Number');
            }
            if (data.hasOwnProperty('mode')) {
                obj['mode'] = ApiClient.convertToType(data['mode'], 'Number');
            }
            if (data.hasOwnProperty('mode_confidence')) {
                obj['mode_confidence'] = ApiClient.convertToType(data['mode_confidence'], 'Number');
            }
            if (data.hasOwnProperty('num_samples')) {
                obj['num_samples'] = ApiClient.convertToType(data['num_samples'], 'Number');
            }
            if (data.hasOwnProperty('offset_seconds')) {
                obj['offset_seconds'] = ApiClient.convertToType(data['offset_seconds'], 'Number');
            }
            if (data.hasOwnProperty('rhythm_version')) {
                obj['rhythm_version'] = ApiClient.convertToType(data['rhythm_version'], 'Number');
            }
            if (data.hasOwnProperty('rhythmstring')) {
                obj['rhythmstring'] = ApiClient.convertToType(data['rhythmstring'], 'String');
            }
            if (data.hasOwnProperty('sample_md5')) {
                obj['sample_md5'] = ApiClient.convertToType(data['sample_md5'], 'String');
            }
            if (data.hasOwnProperty('start_of_fade_out')) {
                obj['start_of_fade_out'] = ApiClient.convertToType(data['start_of_fade_out'], 'Number');
            }
            if (data.hasOwnProperty('synch_version')) {
                obj['synch_version'] = ApiClient.convertToType(data['synch_version'], 'Number');
            }
            if (data.hasOwnProperty('synchstring')) {
                obj['synchstring'] = ApiClient.convertToType(data['synchstring'], 'String');
            }
            if (data.hasOwnProperty('tempo')) {
                obj['tempo'] = ApiClient.convertToType(data['tempo'], 'Number');
            }
            if (data.hasOwnProperty('tempo_confidence')) {
                obj['tempo_confidence'] = ApiClient.convertToType(data['tempo_confidence'], 'Number');
            }
            if (data.hasOwnProperty('time_signature')) {
                obj['time_signature'] = ApiClient.convertToType(data['time_signature'], 'Number');
            }
            if (data.hasOwnProperty('time_signature_confidence')) {
                obj['time_signature_confidence'] = ApiClient.convertToType(data['time_signature_confidence'], 'Number');
            }
            if (data.hasOwnProperty('window_seconds')) {
                obj['window_seconds'] = ApiClient.convertToType(data['window_seconds'], 'Number');
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>AudioAnalysisObjectTrack</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>AudioAnalysisObjectTrack</code>.
     */
    static validateJSON(data) {
        // ensure the json data is a string
        if (data['codestring'] && !(typeof data['codestring'] === 'string' || data['codestring'] instanceof String)) {
            throw new Error("Expected the field `codestring` to be a primitive type in the JSON string but got " + data['codestring']);
        }
        // ensure the json data is a string
        if (data['echoprintstring'] && !(typeof data['echoprintstring'] === 'string' || data['echoprintstring'] instanceof String)) {
            throw new Error("Expected the field `echoprintstring` to be a primitive type in the JSON string but got " + data['echoprintstring']);
        }
        // ensure the json data is a string
        if (data['rhythmstring'] && !(typeof data['rhythmstring'] === 'string' || data['rhythmstring'] instanceof String)) {
            throw new Error("Expected the field `rhythmstring` to be a primitive type in the JSON string but got " + data['rhythmstring']);
        }
        // ensure the json data is a string
        if (data['sample_md5'] && !(typeof data['sample_md5'] === 'string' || data['sample_md5'] instanceof String)) {
            throw new Error("Expected the field `sample_md5` to be a primitive type in the JSON string but got " + data['sample_md5']);
        }
        // ensure the json data is a string
        if (data['synchstring'] && !(typeof data['synchstring'] === 'string' || data['synchstring'] instanceof String)) {
            throw new Error("Expected the field `synchstring` to be a primitive type in the JSON string but got " + data['synchstring']);
        }

        return true;
    }


}



/**
 * The number of channels used for analysis. If 1, all channels are summed together to mono before analysis.
 * @member {Number} analysis_channels
 */
AudioAnalysisObjectTrack.prototype['analysis_channels'] = undefined;

/**
 * The sample rate used to decode and analyze this track. May differ from the actual sample rate of this track available on Spotify.
 * @member {Number} analysis_sample_rate
 */
AudioAnalysisObjectTrack.prototype['analysis_sample_rate'] = undefined;

/**
 * A version number for the Echo Nest Musical Fingerprint format used in the codestring field.
 * @member {Number} code_version
 */
AudioAnalysisObjectTrack.prototype['code_version'] = undefined;

/**
 * An [Echo Nest Musical Fingerprint (ENMFP)](https://academiccommons.columbia.edu/doi/10.7916/D8Q248M4) codestring for this track.
 * @member {String} codestring
 */
AudioAnalysisObjectTrack.prototype['codestring'] = undefined;

/**
 * Length of the track in seconds.
 * @member {Number} duration
 */
AudioAnalysisObjectTrack.prototype['duration'] = undefined;

/**
 * A version number for the EchoPrint format used in the echoprintstring field.
 * @member {Number} echoprint_version
 */
AudioAnalysisObjectTrack.prototype['echoprint_version'] = undefined;

/**
 * An [EchoPrint](https://github.com/spotify/echoprint-codegen) codestring for this track.
 * @member {String} echoprintstring
 */
AudioAnalysisObjectTrack.prototype['echoprintstring'] = undefined;

/**
 * The time, in seconds, at which the track's fade-in period ends. If the track has no fade-in, this will be 0.0.
 * @member {Number} end_of_fade_in
 */
AudioAnalysisObjectTrack.prototype['end_of_fade_in'] = undefined;

/**
 * The key the track is in. Integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class). E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1. 
 * @member {Number} key
 */
AudioAnalysisObjectTrack.prototype['key'] = undefined;

/**
 * The confidence, from 0.0 to 1.0, of the reliability of the `key`.
 * @member {Number} key_confidence
 */
AudioAnalysisObjectTrack.prototype['key_confidence'] = undefined;

/**
 * The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db. 
 * @member {Number} loudness
 */
AudioAnalysisObjectTrack.prototype['loudness'] = undefined;

/**
 * Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0. 
 * @member {Number} mode
 */
AudioAnalysisObjectTrack.prototype['mode'] = undefined;

/**
 * The confidence, from 0.0 to 1.0, of the reliability of the `mode`.
 * @member {Number} mode_confidence
 */
AudioAnalysisObjectTrack.prototype['mode_confidence'] = undefined;

/**
 * The exact number of audio samples analyzed from this track. See also `analysis_sample_rate`.
 * @member {Number} num_samples
 */
AudioAnalysisObjectTrack.prototype['num_samples'] = undefined;

/**
 * An offset to the start of the region of the track that was analyzed. (As the entire track is analyzed, this should always be 0.)
 * @member {Number} offset_seconds
 */
AudioAnalysisObjectTrack.prototype['offset_seconds'] = undefined;

/**
 * A version number for the Rhythmstring used in the rhythmstring field.
 * @member {Number} rhythm_version
 */
AudioAnalysisObjectTrack.prototype['rhythm_version'] = undefined;

/**
 * A Rhythmstring for this track. The format of this string is similar to the Synchstring.
 * @member {String} rhythmstring
 */
AudioAnalysisObjectTrack.prototype['rhythmstring'] = undefined;

/**
 * This field will always contain the empty string.
 * @member {String} sample_md5
 */
AudioAnalysisObjectTrack.prototype['sample_md5'] = undefined;

/**
 * The time, in seconds, at which the track's fade-out period starts. If the track has no fade-out, this should match the track's length.
 * @member {Number} start_of_fade_out
 */
AudioAnalysisObjectTrack.prototype['start_of_fade_out'] = undefined;

/**
 * A version number for the Synchstring used in the synchstring field.
 * @member {Number} synch_version
 */
AudioAnalysisObjectTrack.prototype['synch_version'] = undefined;

/**
 * A [Synchstring](https://github.com/echonest/synchdata) for this track.
 * @member {String} synchstring
 */
AudioAnalysisObjectTrack.prototype['synchstring'] = undefined;

/**
 * The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
 * @member {Number} tempo
 */
AudioAnalysisObjectTrack.prototype['tempo'] = undefined;

/**
 * The confidence, from 0.0 to 1.0, of the reliability of the `tempo`.
 * @member {Number} tempo_confidence
 */
AudioAnalysisObjectTrack.prototype['tempo_confidence'] = undefined;

/**
 * An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from 3 to 7 indicating time signatures of \"3/4\", to \"7/4\".
 * @member {Number} time_signature
 */
AudioAnalysisObjectTrack.prototype['time_signature'] = undefined;

/**
 * The confidence, from 0.0 to 1.0, of the reliability of the `time_signature`.
 * @member {Number} time_signature_confidence
 */
AudioAnalysisObjectTrack.prototype['time_signature_confidence'] = undefined;

/**
 * The length of the region of the track was analyzed, if a subset of the track was analyzed. (As the entire track is analyzed, this should always be 0.)
 * @member {Number} window_seconds
 */
AudioAnalysisObjectTrack.prototype['window_seconds'] = undefined;






export default AudioAnalysisObjectTrack;

